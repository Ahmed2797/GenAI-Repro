{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374ebff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9830877b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ahmed/project/ML_Chatbot'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "051d4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install unstructured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/miniconda3/envs/chatapp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=groq_api_key,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Hello, LangChain with Groq!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,DirectoryLoader\n",
    "\n",
    "loader = PyPDFLoader('project/data/MachineLearning.pdf')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 0, 'page_label': '1'}, page_content='The\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 1, 'page_label': '2'}, page_content='“All models are wrong, but some are useful.”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 2, 'page_label': '3'}, page_content='Preface\\nLet’s start by telling the truth: machines don’t learn. What a typical “learning machine”\\ndoes, is ﬁnding a mathematical formula, which, when applied to a collection of inputs (called\\n“training data”), produces the desired outputs. This mathematical formula also generates the\\ncorrect outputs for most other inputs (distinct from the training data) on the condition that\\nthose inputs come from the same or a similar statistical distribution as the one the training\\ndata was drawn from.\\nWhy isn’t that learning? Because if you slightly distort the inputs, the output is very likely\\nto become completely wrong. It’s not how learning in animals works. If you learned to play\\na video game by looking straight at the screen, you would still be a good player if someone\\nrotates the screen slightly. A machine learning algorithm, if it was trained by “looking”\\nstraight at the screen, unless it was also trained to recognize rotation, will fail to play the\\ngame on a rotated screen.\\nSo why the name “machine learning” then? The reason, as is often the case, is marketing:\\nArthur Samuel, an American pioneer in the ﬁeld of computer gaming and artiﬁcial intelligence,\\ncoined the term in 1959 while at IBM. Similarly to how in the 2010s IBM tried to market\\nthe term “cognitive computing” to stand out from competition, in the 1960s, IBM used the\\nnew cool term “machine learning” to attract both clients and talented employees.\\nAs you can see, just like artiﬁcial intelligence is not intelligence, machine learning is not\\nlearning. However, machine learning is a universally recognized term that usually refers\\nto the science and engineering of building machines capable of doing various useful things\\nwithout being explicitly programmed to do so. So, the word “learning” in the term is used\\nby analogy with the learning in animals rather than literally.\\nWho This Book is For\\nThis book contains only those parts of the vast body of material on machine learning developed\\nsince the 1960s that have proven to have a signiﬁcant practical value. A beginner in machine\\nlearning will ﬁnd in this book just enough details to get a comfortable level of understanding\\nof the ﬁeld and start asking the right questions.\\nPractitioners with experience can use this book as a collection of directions for further\\nself-improvement. The book also comes in handy when brainstorming at the beginning of a\\nproject, when you try to answer the question whether a given technical or business problem\\nis “machine-learnable” and, if yes, which techniques you should try to solve it.\\nHow to Use This Book\\nIf you are about to start learning machine learning, you should read this book from the\\nbeginning to the end. (It’s just a hundred pages, not a big deal.) If you are interested\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 3, 'page_label': '4'}, page_content='in a speciﬁc topic covered in the book and want to know more, most sections have a QR\\ncode. By scanning one of those QR codes with your phone, you will get a link to a page on\\nthe book’s companion wiki theMLbook.com with additional materials: recommended reads,\\nvideos, Q&As, code snippets, tutorials, and other bonuses.\\nThe book’s wiki is continuously updated with contributions from the book’s author himself\\nas well as volunteers from all over the world. So this book, like a good wine, keeps getting\\nbetter after you buy it.\\nScan the QR code below with your phone to get to the book’s wiki:\\nSome sections don’t have a QR code, but they still most likely have a wiki page. You can\\nﬁnd it by submitting the section’s title to the wiki’s search engine.\\nShould You Buy This Book?\\nThis book is distributed on the “read ﬁrst, buy later” principle. I ﬁrmly believe that paying\\nfor the content before consuming it is buying a pig in a poke. You can see and try a car in a\\ndealership before you buy it. You can try on a shirt or a dress in a department store. You\\nhave to be able to read a book before paying for it.\\nThe read ﬁrst, buy laterprinciple implies that you can freely download the book, read it and\\nshare it with your friends and colleagues. If you liked the book, only then you have to buy it.\\nNow you are all set. Enjoy your reading!\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 4, 'page_label': '5'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 5, 'page_label': '6'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 6, 'page_label': '7'}, page_content='1 Introduction\\n1.1 What is Machine Learning\\nMachine learning is a subﬁeld of computer science that is concerned with building algorithms\\nwhich, to be useful, rely on a collection of examples of some phenomenon. These examples\\ncan come from nature, be handcrafted by humans or generated by another algorithm.\\nMachine learning can also be deﬁned as the process of solving a practical problem by 1)\\ngathering a dataset, and 2) algorithmically building a statistical model based on that dataset.\\nThat statistical model is assumed to be used somehow to solve the practical problem.\\nTo save keystrokes, I use the terms “learning” and “machine learning” interchangeably.\\n1.2 Types of Learning\\nLearning can be supervised, semi-supervised, unsupervised and reinforcement.\\n1.2.1 Supervised Learning\\nIn supervised learning1,t h edataset is the collection oflabeled examples{(xi,y i)}N\\ni=1.\\nEach elementxi among N is called afeature vector. A feature vector is a vector in which\\neach dimension j =1 ,...,D contains a value that describes the example somehow. That\\nvalue is called afeature and is denoted asx(j). For instance, if each examplex in our\\ncollection represents a person, then the ﬁrst feature,x(1), could contain height in cm, the\\nsecond feature,x(2), could contain weight in kg,x(3) could contain gender, and so on. For all\\nexamples in the dataset, the feature at positionj in the feature vector always contains the\\nsame kind of information. It means that ifx(2)\\ni contains weight in kg in some examplexi,\\nthen x(2)\\nk will also contain weight in kg in every examplexk, k =1 ,...,N .T h elabel yi can\\nbe either an element belonging to a ﬁnite set ofclasses {1, 2,...,C }, or a real number, or a\\nmore complex structure, like a vector, a matrix, a tree, or a graph. Unless otherwise stated,\\nin this bookyi is either one of a ﬁnite set of classes or a real number. You can see a class as\\na category to which an example belongs. For instance, if your examples are email messages\\nand your problem is spam detection, then you have two classes{spam, not_spam}.\\nThe goal of asupervised learning algorithmis to use the dataset to produce amodel\\nthat takes a feature vectorx as input and outputs information that allows deducing the label\\nfor this feature vector. For instance, the model created using the dataset of people could\\ntake as input a feature vector describing a person and output a probability that the person\\nhas cancer.\\n1In this book, if a term isin bold,t h a tm e a n st h a tt h i st e r mc a nb ef o u n di nt h ei n d e xa tt h ee n do ft h e\\nbook.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 7, 'page_label': '8'}, page_content='1.2.2 Unsupervised Learning\\nIn unsupervised learning, the dataset is a collection ofunlabeled examples {xi}N\\ni=1.\\nAgain, x is a feature vector, and the goal of anunsupervised learning algorithm is\\nto create a model that takes a feature vectorx as input and either transforms it into\\nanother vector or into a value that can be used to solve a practical problem. For example,\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\nfeatures than the inputx;i n outlier detection, the output is a real number that indicates\\nhow x is di\\x00erent from a “typical” example in the dataset.\\n1.2.3 Semi-Supervised Learning\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\nexamples. The goal of asemi-supervised learning algorithmis the same as the goal of\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\nhelp the learning algorithm to ﬁnd (we might say “produce” or “compute”) a better model2.\\n1.2.4 Reinforcement Learning\\nReinforcement learning is a subﬁeld of machine learning where the machine “lives” in an\\nenvironment and is capable of perceiving thestate of that environment as a vector of\\nfeatures. The machine can executeactions in every state. Di\\x00erent actions bring di\\x00erent\\nrewards and could also move the machine to another state of the environment. The goal\\nof a reinforcement learning algorithm is to learn apolicy. A policy is a functionf (similar\\nto the model in supervised learning) that takes the feature vector of a state as input and\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\nexpected average reward.\\nReinforcement learning solves a particular kind of problems where\\ndecision making is sequential, and the goal is long-term, such as game\\nplaying, robotics, resource management, or logistics. In this book, I\\nput emphasis on one-shot decision making where input examples are\\nindependent of one another and the predictions made in the past. I\\nleave reinforcement learning out of the scope of this book.\\n2It could look counter-intuitive that learning could beneﬁt from adding more unlabeled examples. It seems\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\ninformation about your problem: a larger sample reﬂects better the probability distribution the data we\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 8, 'page_label': '9'}, page_content='1.3 How Supervised Learning Works\\nIn this section, I brieﬂy explain how supervised learning works so that you have the picture\\nof the whole process before we go into detail. I decided to use supervised learning as an\\nexample because it’s the type of machine learning most frequently used in practice.\\nThe supervised learning process starts with gathering the data. The data for supervised\\nlearning is a collection of pairs (input, output). Input could be anything, for example, email\\nmessages, pictures, or sensor measurements. Outputs are usually real numbers, or labels (e.g.\\n“spam”, “not_spam”, “cat”, “dog”, “mouse”, etc). In some cases, outputs are vectors (e.g.,\\nfour coordinates of the rectangle around a person on the picture), sequences (e.g. [“adjective”,\\n“adjective”, “noun”] for the input “big beautiful car”), or have some other structure.\\nLet’s say the problem that you want to solve using supervised learning is spam detection.\\nYou gather the data, for example, 10,000 email messages, each with a label either “spam” or\\n“not_spam” (you could add those labels manually or pay someone to do that for us). Now,\\nyou have to convert each email message into a feature vector.\\nThe data analyst decides, based on their experience, how to convert a real-world entity, such\\nas an email message, into a feature vector. One common way to convert a text into a feature\\nvector, calledbag of words, is to take a dictionary of English words (let’s say it contains\\n20,000 alphabetically sorted words) and stipulate that in our feature vector:\\n• the ﬁrst feature is equal to1 if the email message contains the word “a”; otherwise,\\nthis feature is0;\\n• the second feature is equal to1 if the email message contains the word “aaron”; otherwise,\\nthis feature equals0;\\n• ...\\n• the feature at position 20,000 is equal to1 if the email message contains the word\\n“zulu”; otherwise, this feature is equal to0.\\nYou repeat the above procedure for every email message in our collection, which gives\\nus 10,000 feature vectors (each vector having the dimensionality of 20,000) and a label\\n(“spam”/“not_spam”).\\nNow you have a machine-readable input data, but the output labels are still in the form of\\nhuman-readable text. Some learning algorithms require transforming labels into numbers.\\nFor example, some algorithms require numbers like0 (to represent the label “not_spam”)\\nand 1 (to represent the label “spam”). The algorithm I use to illustrate supervised learning is\\ncalled Support Vector Machine(SVM). This algorithm requires that the positive label (in\\nour case it’s “spam”) has the numeric value of+1 (one), and the negative label (“not_spam”)\\nhas the value of≠1 (minus one).\\nAt this point, you have adataset and a learning algorithm, so you are ready to apply\\nthe learning algorithm to the dataset to get themodel.\\nSVM sees every feature vector as a point in a high-dimensional space (in our case, space\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 9, 'page_label': '10'}, page_content='is 20,000-dimensional). The algorithm puts all feature vectors on an imaginary 20,000-\\ndimensional plot and draws an imaginary 20,000-dimensional line (ahyperplane) that separates\\nexamples with positive labels from examples with negative labels. In machine learning, the\\nboundary separating the examples of di\\x00erent classes is called thedecision boundary.\\nThe equation of the hyperplane is given by twoparameters, a real-valued vectorw of the\\nsame dimensionality as our input feature vectorx, and a real numberb like this:\\nwx ≠ b =0 ,\\nwhere the expressionwx means w(1)x(1) + w(2)x(2) + ... + w(D)x(D), andD is the number\\nof dimensions of the feature vectorx.\\n(If some equations aren’t clear to you right now, in Chapter 2 we revisit the math and\\nstatistical concepts necessary to understand them. For the moment, try to get an intuition of\\nwhat’s happening here. It all becomes more clear after you read the next chapter.)\\nNow, the predicted label for some input feature vectorx is given like this:\\ny = sign(wx ≠ b),\\nwhere sign is a mathematical operator that takes any value as input and returns+1 if the\\ninput is a positive number or≠1 if the input is a negative number.\\nThe goal of the learning algorithm — SVM in this case — is to leverage the dataset and ﬁnd\\nthe optimal valueswú and bú for parametersw and b. Once the learning algorithm identiﬁes\\nthese optimal values, themodel f(x) is then deﬁned as:\\nf(x) = sign(wúx ≠ bú)\\nTherefore, to predict whether an email message is spam or not spam using an SVM model,\\nyou have to take a text of the message, convert it into a feature vector, then multiply this\\nvector bywú, subtractbú and take the sign of the result. This will give us the prediction (+1\\nmeans “spam”,≠1 means “not_spam”).\\nNow, how does the machine ﬁndwú and bú? It solves an optimization problem. Machines\\nare good at optimizing functions under constraints.\\nSo what are the constraints we want to satisfy here? First of all, we want the model to predict\\nthe labels of our 10,000 examples correctly. Remember that each examplei =1 ,..., 10000 is\\ngiven by a pair(xi,y i),w h e r exi is the feature vector of examplei and yi is its label that\\ntakes values either≠1 or +1. So the constraints are naturally:\\n• wxi ≠ b Ø 1 if yi =+ 1, and\\n• wxi ≠ b Æ≠ 1 if yi = ≠1\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 10, 'page_label': '11'}, page_content='x(2)\\nx(1)\\nwx\\xa0—\\xa0b\\xa0=\\xa00wx\\xa0—\\xa0b\\xa0=\\xa01\\nwx\\xa0—\\xa0b\\xa0=\\xa0—1\\nb\\xa0||w||\\xa0\\n2\\xa0||w||\\xa0\\nFigure 1: An example of an SVM model for two-dimensional feature vectors.\\nWe would also prefer that the hyperplane separates positive examples from negative ones with\\nthe largestmargin. The margin is the distance between the closest examples of two classes,\\nas deﬁned by the decision boundary. A large margin contributes to a bettergeneralization,\\nthat is how well the model will classify new examples in the future. To achieve that, we need\\nto minimize the Euclidean norm ofw denoted byÎwÎ and given by\\nÒqD\\nj=1(w(j))2.\\nSo, the optimization problem that we want the machine to solve looks like this:\\nMinimize ÎwÎ subject to yi(wxi ≠ b) Ø 1 for i =1 ,. . . ,N. The expressionyi(wxi ≠ b) Ø 1\\nis just a compact way to write the above two constraints.\\nThe solution of this optimization problem, given bywú and bú, is called thestatistical\\nmodel, or, simply, themodel. The process of building the model is calledtraining.\\nFor two-dimensional feature vectors, the problem and the solution can be visualized as shown\\nin ﬁg. 1. The blue and orange circles represent, respectively, positive and negative examples,\\nand the line given bywx ≠ b =0 is the decision boundary.\\nWhy, by minimizing the norm ofw, do we ﬁnd the highest margin between the two classes?\\nGeometrically, the equationswx ≠ b =1 and wx ≠ b = ≠1 deﬁne two parallel hyperplanes,\\nas you see in ﬁg. 1. The distance between these hyperplanes is given by2\\nÎwÎ , so the smaller\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 11, 'page_label': '12'}, page_content='the normÎwÎ, the larger the distance between these two hyperplanes.\\nThat’s how Support Vector Machines work. This particular version of the algorithm builds\\nthe so-calledlinear model. It’s called linear because the decision boundary is a straight line\\n(or a plane, or a hyperplane). SVM can also incorporatekernels that can make the decision\\nboundary arbitrarily non-linear. In some cases, it could be impossible to perfectly separate\\nthe two groups of points because of noise in the data, errors of labeling, oroutliers (examples\\nvery di\\x00erent from a “typical” example in the dataset). Another version of SVM can also\\nincorporate a penalty hyperparameter for misclassiﬁcation of training examples of speciﬁc\\nclasses. We study the SVM algorithm in more detail in Chapter 3.\\nAt this point, you should retain the following: any classiﬁcation learning algorithm that\\nbuilds a model implicitly or explicitly creates a decision boundary. The decision boundary\\ncan be straight, or curved, or it can have a complex form, or it can be a superposition of\\nsome geometrical ﬁgures. The form of the decision boundary determines theaccuracy of\\nthe model (that is the ratio of examples whose labels are predicted correctly). The form of\\nthe decision boundary, the way it is algorithmically or mathematically computed based on\\nthe training data, di\\x00erentiates one learning algorithm from another.\\nIn practice, there are two other essential di\\x00erentiators of learning algorithms to consider:\\nspeed of model building and prediction processing time. In many practical cases, you would\\nprefer a learning algorithm that builds a less accurate model fast. Additionally, you might\\nprefer a less accurate model that is much quicker at making predictions.\\n1.4 Why the Model Works on New Data\\nWhy is a machine-learned model capable of predicting correctly the labels of new, previously\\nunseen examples? To understand that, look at the plot in ﬁg. 1. If two classes are separable\\nfrom one another by a decision boundary, then, obviously, examples that belong to each class\\nare located in two di\\x00erent subspaces which the decision boundary creates.\\nIf the examples used for training were selected randomly, independently of one another, and\\nfollowing the same procedure, then, statistically, it ismore likely that the new negative\\nexample will be located on the plot somewhere not too far from other negative examples.\\nThe same concerns the new positive example: it willlikely come from the surroundings of\\nother positive examples. In such a case, our decision boundary will still,with high probability,\\nseparate well new positive and negative examples from one another. For other,less likely\\nsituations, our model will make errors, but because such situations are less likely, the number\\nof errors will likely be smaller than the number of correct predictions.\\nIntuitively, the larger is the set of training examples, the more unlikely that the new examples\\nwill be dissimilar to (and lie on the plot far from) the examples used for training. To minimize\\nthe probability of making errors on new examples, the SVM algorithm, by looking for the\\nlargest margin, explicitly tries to draw the decision boundary in such a way that it lies as far\\nas possible from examples of both classes.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 12, 'page_label': '13'}, page_content='The reader interested in knowing more about thelearnability and un-\\nderstanding the close relationship between the model error, the size of\\nthe training set, the form of the mathematical equation that deﬁnes\\nthe model, and the time it takes to build the model is encouraged to\\nread about thePAC learning. The PAC (for “probably approximately\\ncorrect”) learning theory helps to analyze whether and under what\\nconditions a learning algorithm will probably output an approximately\\ncorrect classiﬁer.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 13, 'page_label': '14'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 14, 'page_label': '15'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 15, 'page_label': '16'}, page_content='2 Notation and Deﬁnitions\\n2.1 Notation\\nLet’s start by revisiting the mathematical notation we all learned at school, but some likely\\nforgot right after the prom.\\n2.1.1 Scalars, Vectors, and Sets\\nA scalar is a simple numerical value, like15 or ≠3.25. Variables or constants that take scalar\\nvalues are denoted by an italic letter, likex or a.\\nFigure 1: Three vectors visualized as directions and as points.\\nA vector is an ordered list of scalar values, called attributes. We denote a vector as a bold\\ncharacter, for example,x or w. Vectors can be visualized as arrows that point to some\\ndirections as well as points in a multi-dimensional space. Illustrations of three two-dimensional\\nvectors, a =[ 2, 3], b =[ ≠2, 5], andc =[ 1, 0] is given in ﬁg. 1. We denote an attribute of a\\nvector as an italic value with an index, like this:w(j) or x(j).T h ei n d e xj denotes a speciﬁc\\ndimension of the vector, the position of an attribute in the list. For instance, in the vectora\\nshown in red in ﬁg. 1,a(1) =2 and a(2) =3 .\\nThe notationx(j) should not be confused with the power operator, like thisx2 (squared) or\\nx3 (cubed). If we want to apply a power operator, say square, to an indexed attribute of a\\nvector, we write like this:(x(j))2.\\nA variable can have two or more indices, like this:x(j)\\ni or like thisx(k)\\ni,j . For example, in\\nneural networks, we denote asx(j)\\nl,u the input featurej of unitu in layerl.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 16, 'page_label': '17'}, page_content='A set is an unordered collection of unique elements. We denote a set as a calligraphic\\ncapital character, for example,S. A set of numbers can be ﬁnite (include a ﬁxed amount\\nof values). In this case, it is denoted using accolades, for example,{1, 3, 18, 23, 235} or\\n{x1,x 2,x 3,x 4,...,x n}. A set can be inﬁnite and include all values in some interval. If a set\\nincludes all values betweena and b,i n c l u d i n ga and b, it is denoted using brackets as[a, b].\\nIf the set doesn’t include the valuesa and b, such a set is denoted using parentheses like this:\\n(a, b). For example, the set[0, 1] includes such values as0, 0.0001, 0.25, 0.784, 0.9995, and\\n1.0. A special set denotedR includes all numbers from minus inﬁnity to plus inﬁnity.\\nWhen an elementx belongs to a setS,w ew r i t ex œS . We can obtain a new setS3 as\\nan intersection of two setsS1 and S2. In this case, we writeS3 ΩS 1 ﬂS 2. For example\\n{1, 3, 5, 8}ﬂ{ 1, 8, 4} gives the new set{1, 8}.\\nWe can obtain a new setS3 as a union of two sets S1 and S2. In this case, we write\\nS3 ΩS 1 ﬁS 2. For example{1, 3, 5, 8}ﬁ{ 1, 8, 4} gives the new set{1, 3, 4, 5, 8}.\\n2.1.2 Capital Sigma Notation\\nThe summation over a collectionX = {x1,x 2,...,x n≠1,x n} or over the attributes of a vector\\nx =[ x(1),x (2),...,x (m≠1),x (m)] is denoted like this:\\nnÿ\\ni=1\\nxi\\ndef\\n= x1 + x2 + ... + xn≠1 + xn, or else:\\nmÿ\\nj=1\\nx(j) def\\n= x(1) + x(2) + ... + x(m≠1) + x(m).\\nThe notation\\ndef\\n= means “is deﬁned as” .\\n2.1.3 Capital Pi Notation\\nA notation analogous to capital sigma is thecapital pi notation. It denotes a product of\\nelements in a collection or attributes of a vector:\\nnŸ\\ni=1\\nxi\\ndef\\n= x1 · x2 · ... · xn≠1 · xn,\\nwhere a · b means a multiplied byb. Where possible, we omit· to simplify the notation, soab\\nalso meansa multiplied byb.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 17, 'page_label': '18'}, page_content='2.1.4 Operations on Sets\\nA derived set creation operator looks like this:SÕ Ω{ x2 | x œS ,x> 3}. This notation means\\nthat we create a new setSÕ by putting into itx squared such that thatx is inS, andx is\\ngreater than3.\\nThe cardinality operator|S| returns the number of elements in setS.\\n2.1.5 Operations on Vectors\\nThe sum of two vectorsx + z is deﬁned as the vector[x(1) + z(1),x (2) + z(2),...,x (m) + z(m)].\\nThe di\\x00erence of two vectorsx ≠z is deﬁned as the vector[x(1) ≠z(1),x (2) ≠z(2),...,x (m) ≠\\nz(m)].\\nA vector multiplied by a scalar is a vector. For examplexc\\ndef\\n=[ cx(1),c x(2),...,c x (m)].\\nA dot-product of two vectors is a scalar. For example,wx\\ndef\\n= qm\\ni=1 w(i)x(i). In some books,\\nthe dot-product is denoted asw · x. The two vectors must be of the same dimensionality.\\nOtherwise, the dot-product is undeﬁned.\\nThe multiplication of a matrixW by a vectorx gives another vector as a result. Let our\\nmatrix be,\\nW =\\n5w(1,1) w(1,2) w(1,3)\\nw(2,1) w(2,2) w(2,3)\\n6\\n.\\nWhen vectors participate in operations on matrices, a vector is by default represented as a\\nmatrix with one column. When the vector is on the right of the matrix, it remains a column\\nvector. We can only multiply a matrix by vector if the vector has the same number of rows\\nas the number of columns in the matrix. Let our vector bex\\ndef\\n= [x(1),x (2),x (3)].T h e nWx\\nis a two-dimensional vector deﬁned as,\\nWx =\\n5w(1,1) w(1,2) w(1,3)\\nw(2,1) w(2,2) w(2,3)\\n6S\\nU\\nx(1)\\nx(2)\\nx(3)\\nT\\nV\\ndef\\n=\\n5w(1,1)x(1) + w(1,2)x(2) + w(1,3)x(3)\\nw(2,1)x(1) + w(2,2)x(2) + w(2,3)x(3)\\n6\\n=\\n5w(1)x\\nw(2)x\\n6\\nIf our matrix had, say, ﬁve rows, the result of the above product would be a ﬁve-dimensional\\nvector.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 18, 'page_label': '19'}, page_content='When the vector is on the left side of the matrix in the multiplication, then it has to be\\ntransposed before we multiply it by the matrix. The transpose of the vectorx denoted asx€\\nmakes a row vector out of a column vector. Let’s say,\\nx =\\n5x(1)\\nx(2)\\n6\\n,\\nthen,\\nx€ def\\n=\\nË\\nx(1),x (2)\\nÈ\\n.\\nThe multiplication of the vectorx by the matrixW is given byx€W,\\nx€W =\\nË\\nx(1),x (2)\\nÈ5w(1,1) w(1,2) w(1,3)\\nw(2,1) w(2,2) w(2,3)\\n6\\ndef\\n=\\n#\\nw(1,1)x(1) + w(2,1)x(2),w (1,2)x(1) + w(2,2)x(2),w (1,3)x(1) + w(2,3)x(2)$\\nAs you can see, we can only multiply a vector by a matrix if the vector has the same number\\nof dimensions as the number of rows in the matrix.\\n2.1.6 Functions\\nA function is a relation that associates each elementx of a setX ,t h edomain of the function,\\nto a single elementy of another setY,t h ecodomain of the function. A function usually has a\\nname. If the function is calledf, this relation is denotedy = f(x) (read f of x), the element\\nx is the argument or input of the function, andy is the value of the function or the output.\\nThe symbol that is used for representing the input is the variable of the function (we often\\nsay thatf is a function of the variablex).\\nWe say thatf(x) has a local minimum at x = c if f(x) Ø f(c) for every x in some open\\ninterval aroundx = c. An interval is a set of real numbers with the property that any number\\nthat lies between two numbers in the set is also included in the set. Anopen interval does\\nnot include its endpoints and is denoted using parentheses. For example,(0, 1) means greater\\nthan 0 and less than1. The minimal value among all the local minima is called theglobal\\nminimum. See illustration in ﬁg. 2.\\nA vector function, denoted asy = f(x) is a function that returns a vectory. It can have a\\nvector or a scalar argument.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 19, 'page_label': '20'}, page_content='global  minimum\\nlocal  minimum\\n6\\n4\\n2\\n0\\n–2 \\n–4 \\n–6 \\nf(x)\\nFigure 2: A local and a global minima of a function.\\n2.1.7 Max and Arg Max\\nGiven a set of valuesA = {a1,a 2,...,a n}, the operator,\\nmax\\naœA\\nf(a)\\nreturns the highest valuef(a) for all elements in the setA. On the other hand, the operator,\\narg max\\naœA\\nf(a)\\nreturns the element of the setA that maximizesf(a).\\nSometimes, when the set is implicit or inﬁnite, we can writemaxa f(a) or arg max\\na\\nf(a).\\nOperators min and arg minoperate in a similar manner.\\n2.1.8 Assignment Operator\\nThe expressiona Ω f(x) means that the variablea gets the new value: the result off(x).\\nWe say that the variablea gets assigned a new value. Similarly,a Ω [a1,a 2] means that the\\ntwo-dimensional vectora gets the value[a1,a 2].\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 20, 'page_label': '21'}, page_content='2.1.9 Derivative and Gradient\\nA derivative fÕ of a functionf is a function or a value that describes how fastf grows (or\\ndecreases). If the derivative is a constant value, like5 or ≠3, then the function grows (or\\ndecreases) constantly at any pointx of its domain. If the derivativefÕ is a function, then the\\nfunction f can grow at a di\\x00erent pace in di\\x00erent regions of its domain. If the derivativefÕ\\nis positive at some pointx, then the functionf grows at this point. If the derivative off is\\nnegative at somex, then the function decreases at this point. The derivative of zero atx\\nmeans that the function’s slope atx is horizontal.\\nThe process of ﬁnding a derivative is calleddi\\x00erentiation.\\nDerivatives for basic functions are known. For example iff(x)= x2,t h e nfÕ(x)=2 x;i f\\nf(x)=2 x then fÕ(x)=2 ;i ff(x)=2 then fÕ(x)=0 (the derivative of any functionf(x)= c,\\nwhere c is a constant value, is zero).\\nIf the function we want to di\\x00erentiate is not basic, we can ﬁnd its derivative using the\\nchain rule. For example ifF (x)= f(g(x)),w h e r ef and g are some functions, thenF Õ(x)=\\nfÕ(g(x))gÕ(x). For example ifF (x)=( 5x + 1)2 then g(x)=5 x +1 and f(g(x)) = (g(x))2.\\nBy applying the chain rule, we ﬁndF Õ(x) = 2(5x + 1)gÕ(x) = 2(5x + 1)5 = 50x + 10.\\nGradient is the generalization of derivative for functions that take several inputs (or one\\ninput in the form of a vector or some other complex structure). A gradient of a function\\nis a vector ofpartial derivatives. You can look at ﬁnding a partial derivative of a function\\nas the process of ﬁnding the derivative by focusing on one of the function’s inputs and by\\nconsidering all other inputs as constant values.\\nFor example, if our function is deﬁned asf([x(1),x (2)]) =ax(1) + bx(2) + c, then the partial\\nderivative of functionf with respect tox(1), denoted as ˆf\\nˆx(1) , is given by,\\nˆf\\nˆx(1) = a +0+0= a,\\nwhere a is the derivative of the functionax(1); the two zeroes are respectively derivatives of\\nbx(2) and c, becausex(2) is considered constant when we compute the derivative with respect\\nto x(1), and the derivative of any constant is zero.\\nSimilarly, the partial derivative of functionf with respect tox(2), ˆf\\nˆx(2) , is given by,\\nˆf\\nˆx(2) =0+ b +0= b.\\nThe gradient of functionf, denoted asÒf is given by the vector[ ˆf\\nˆx(1) , ˆf\\nˆx(2) ].\\nThe chain rule works with partial derivatives too, as I illustrate in Chapter 4.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 21, 'page_label': '22'}, page_content='(a)\\n (b)\\nFigure 3: A probability mass function and a probability density function.\\n2.2 Random Variable\\nA random variable, usually written as an italic capital letter, likeX, is a variable whose\\npossible values are numerical outcomes of a random phenomenon. There are two types of\\nrandom variables: discrete and continuous.\\nA discrete random variabletakes on only a countable number of distinct values such asred,\\nyellow, blue or 1, 2, 3, ... .\\nThe probability distributionof a discrete random variable is described by a list of probabilities\\nassociated with each of its possible values. This list of probabilities is calledprobability mass\\nfunction (pmf). For example:Pr(X = red)=0 .3, Pr(X = yellow)=0 .45, Pr(X = blue)=\\n0.25. Each probability in a probability mass function is a value greater than or equal to0.\\nThe sum of probabilities equals1 (ﬁg. 3a).\\nA continuous random variabletakes an inﬁnite number of possible values in some interval.\\nExamples include height, weight, and time. Because the number of values of a continuous\\nrandom variableX is inﬁnite, the probabilityPr(X = c) for anyc is 0. Therefore, instead\\nof the list of probabilities, the probability distribution of a continuous random variable (a\\ncontinuous probability distribution) is described by aprobability density function(pdf). The\\npdf is a function whose codomain is nonnegative and the area under the curve is equal to1\\n(ﬁg. 3b).\\nLet a discrete random variableX have k possible values {xi}k\\ni=1.T h eexpectation of X\\ndenoted asE[X] is given by,\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 22, 'page_label': '23'}, page_content='E[X]\\ndef\\n=\\nkÿ\\ni=1\\nxi Pr(X = xi)= x1 Pr(X = x1)+ x2 Pr(X = x2)+ ··· + xk Pr(X = xk), (1)\\nwhere Pr(X = xi) is the probability thatX has the valuexi according to the pmf. The\\nexpectation of a random variable is also called themean, average or expected valueand is\\nfrequently denoted with the letterµ. The expectation is one of the most importantstatistics\\nof a random variable. Another important statistic is thestandard deviation. For a discrete\\nrandom variable, the standard deviation usually denoted as‡ is given by:\\n‡\\ndef\\n=\\n\\uf8ff\\nE[(X ≠ µ)2]=\\n\\uf8ff\\nPr(X = x1)(x1 ≠ µ)2 +P r (X = x2)(x2 ≠ µ)2 + ··· +P r (X = xk)(xk ≠ µ)2,\\nwhere µ = E[X].\\nThe expectation of a continuous random variableX is given by,\\nE[X]\\ndef\\n=\\n⁄\\nR\\nxfX(x) dx, (2)\\nwhere fX is the pdf of the variableX and\\ns\\nR is theintegral of functionxfX.\\nIntegral is an equivalent of the summation over all values of the function when the function\\nhas a continuous domain. It equals the area under the curve of the function. The property of\\nthe pdf that the area under its curve is1 mathematically means that\\ns\\nR fX(x) dx =1 .\\nMost of the time we don’t knowfX, but we can observe some values ofX. In machine\\nlearning, we call these valuesexamples, and the collection of these examples is called a\\nsample or adataset.\\n2.3 Unbiased Estimators\\nBecause fX is usually unknown, but we have a sampleSX = {xi}N\\ni=1, we often content\\nourselves not with the true values of statistics of the probability distribution, such as\\nexpectation, but with theirunbiased estimators.\\nWe say thatˆ◊(SX) is an unbiased estimator of some statistic◊ calculated using a sampleSX\\ndrawn from an unknown probability distribution ifˆ◊(SX) has the following property:\\nE\\nË\\nˆ◊(SX)\\nÈ\\n= ◊,\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 23, 'page_label': '24'}, page_content='where ˆ◊ is asample statistic, obtained using a sampleSX and not the real statistic◊ that\\ncan be obtained only knowingX; the expectation is taken over all possible samples drawn\\nfrom X. Intuitively, this means that if you can have an unlimited number of such samples\\nas SX, and you compute some unbiased estimator, such asˆµ, using each sample, then the\\naverage of all theseˆµ equals the real statisticµ that you would get computed onX.\\nIt can be shown that an unbiased estimator of an unknownE[X] (given by either eq. 1 or\\neq. 2) is given by1\\nN\\nqN\\ni=1 xi (called in statistics thesample mean).\\n2.4 Bayes’ Rule\\nThe conditional probabilityPr(X = x|Y = y) is the probability of the random variableX to\\nhave a speciﬁc valuex given that another random variableY has a speciﬁc value ofy.T h e\\nBayes’ Rule(also known as theBayes’ Theorem) stipulates that:\\nPr(X = x|Y = y)= Pr(Y = y|X = x)P r (X = x)\\nPr(Y = y) .\\n2.5 Parameter Estimation\\nBayes’ Rule comes in handy when we have a model ofX’s distribution, and this modelf◊ is a\\nfunction that has some parameters in the form of a vector◊. An example of such a function\\ncould be the Gaussian function that has two parameters,µ and ‡, and is deﬁned as:\\nf◊(x)= 1Ô\\n2ﬁ‡2 e≠(x≠µ)2\\n2‡2 ,\\nwhere ◊\\ndef\\n=[ µ, ‡].\\nThis function has all the properties of a pdf. Therefore, we can use it as a model of an\\nunknown distribution ofX. We can update the values of parameters in the vector◊ from the\\ndata using the Bayes’ Rule:\\nPr(◊ = ˆ◊|X = x) Ω Pr(X = x|◊ = ˆ◊)P r (◊ = ˆ◊)\\nPr(X = x) = Pr(X = x|◊ = ˆ◊)P r (◊ = ˆ◊)q\\n˜◊ Pr(X = x|◊ = ˜◊) . (3)\\nwhere Pr(X = x|◊ = ˆ◊)\\ndef\\n= fˆ◊.\\nIf we have a sampleS of X and the set of possible values for◊ is ﬁnite, we can easily estimate\\nPr(◊ = ˆ◊) by applying Bayes’ Rule iteratively, one examplex œS at a time. The initial value\\nPr(◊ = ˆ◊) can be guessed such thatq\\nˆ◊ Pr(◊ = ˆ◊)=1 . This guess of the probabilities for\\ndi\\x00erent ˆ◊ is called the prior.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 24, 'page_label': '25'}, page_content='First, we compute Pr(◊ = ˆ◊|X = x1) for all possible values ˆ◊. Then, before updating\\nPr(◊ = ˆ◊|X = x) once again, this time forx = x2 œS using eq. 3, we replace the prior\\nPr(◊ = ˆ◊) in eq. 3 by the new estimatePr(◊ = ˆ◊) Ω 1\\nN\\nq\\nxœS Pr(◊ = ˆ◊|X = x).\\nThe best value of the parameters◊ú given one example is obtained using the principle of\\nmaximum-likelihood:\\n◊ú = arg max\\n◊\\nNŸ\\ni=1\\nPr(◊ = ˆ◊|X = xi). (4)\\nIf the set of possible values for◊ isn’t ﬁnite, then we need to optimize eq. 4 directly using a\\nnumerical optimization routine, such as gradient descent, which we consider in Chapter 4.\\nUsually, we optimize the natural logarithm of the right-hand side expression in eq. 4 because\\nthe logarithm of a product becomes the sum of logarithms and it’s easier for the machine to\\nwork with the sum than with a product1.\\n2.6 Classiﬁcation vs. Regression\\nClassiﬁcation is a problem of automatically assigning alabel to anunlabeled example.\\nSpam detection is a famous example of classiﬁcation.\\nIn machine learning, the classiﬁcation problem is solved by a classiﬁcation learning algorithm\\nthat takes a collection oflabeled examplesas inputs and produces amodel that can take\\nan unlabeled example as input and either directly output a label or output a number that\\ncan be used by the data analyst to deduce the label easily. An example of such a number is\\na probability.\\nIn a classiﬁcation problem, a label is a member of a ﬁnite set ofclasses. If the size of\\nthe set of classes is two (“sick”/“healthy”, “spam”/“not_spam”), we talk aboutbinary\\nclassiﬁcation (also calledbinomial in some books).\\nMulticlass classiﬁcation(also calledmultinomial) is a classiﬁcation problem with three\\nor more classes2.\\nWhile some learning algorithms naturally allow for more than two classes, others are by nature\\nbinary classiﬁcation algorithms. There are strategies allowing to turn a binary classiﬁcation\\nlearning algorithm into a multiclass one. I talk about one of them in Chapter 7.\\nRegression is a problem of predicting a real-valued label (often called atarget) given an\\nunlabeled example. Estimating house price valuation based on house features, such as area,\\nthe number of bedrooms, location and so on is a famous example of regression.\\n1Multiplication of many numbers can give either a very small result or a very large one. It often results in\\nthe problem of numerical overﬂow when the machine cannot store such extreme numbers in memory.\\n2There’s still one label per example though.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 12'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 25, 'page_label': '26'}, page_content='The regression problem is solved by a regression learning algorithm that takes a collection\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\ninput and output a target.\\n2.7 Model-Based vs. Instance-Based Learning\\nMost supervised learning algorithms are model-based. We have already seen one such\\nalgorithm: SVM. Model-based learning algorithms use the training data to create amodel\\nthat hasparameters learned from the training data. In SVM, the two parameters we saw\\nwere wú and bú. After the model was built, the training data can be discarded.\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\nalgorithm frequently used in practice isk-Nearest Neighbors(kNN). In classiﬁcation, to\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\noften in this close neighborhood.\\n2.8 Shallow vs. Deep Learning\\nA shallow learning algorithm learns the parameters of the model directly from the features\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\nexceptions are neural network learning algorithms, speciﬁcally those that build neural\\nnetworks with more than onelayer between input and output. Such neural networks are\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\ncontrary to shallow learning, most model parameters are learned not directly from the features\\nof the training examples, but from the outputs of the preceding layers.\\nDon’t worry if you don’t understand what that means right now. We look at neural networks\\nmore closely in Chapter 6.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 13'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 26, 'page_label': '27'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 27, 'page_label': '28'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 28, 'page_label': '29'}, page_content='3 Fundamental Algorithms\\nIn this chapter, I describe ﬁve algorithms which are not just the most known but also either\\nvery e\\x00ective on their own or are used as building blocks for the most e\\x00ective learning\\nalgorithms out there.\\n3.1 Linear Regression\\nLinear regression is a popular regression learning algorithm that learns a model which is a\\nlinear combination of features of the input example.\\n3.1.1 Problem Statement\\nWe have a collection of labeled examples{(xi,y i)}N\\ni=1,w h e r eN is the size of the collection,\\nxi is the D-dimensional feature vector of examplei =1 ,...,N , yi is a real-valued1 target\\nand every featurex(j)\\ni , j =1 ,...,D , is also a real number.\\nWe want to build a modelfw,b(x) as a linear combination of features of examplex:\\nfw,b(x)= wx + b, (1)\\nwhere w is aD-dimensional vector of parameters andb is a real number. The notationfw,b\\nmeans that the modelf is parametrized by two values:w and b.\\nWe will use the model to predict the unknowny for a givenx like this: y Ω fw,b(x).T w o\\nmodels parametrized by two di\\x00erent pairs(w,b ) will likely produce two di\\x00erent predictions\\nwhen applied to the same example. We want to ﬁnd the optimal values(wú,b ú). Obviously,\\nthe optimal values of parameters deﬁne the model that makes the most accurate predictions.\\nYou could have noticed that the form of our linear model in eq. 1 is very similar to the form\\nof the SVM model. The only di\\x00erence is the missingsign operator. The two models are\\nindeed similar. However, the hyperplane in the SVM plays the role of the decision boundary:\\nit’s used to separate two groups of examples from one another. As such, it has to be as far\\nfrom each group as possible.\\nOn the other hand, the hyperplane in linear regression is chosen to be as close to all training\\nexamples as possible.\\nYou can see why this latter requirement is essential by looking at the illustration in ﬁg. 1. It\\ndisplays the regression line (in light-blue) for one-dimensional examples (dark-blue dots). We\\ncan use this line to predict the value of the targetynew for a new unlabeled input example\\nxnew. If our examples areD-dimensional feature vectors (forD> 1), the only di\\x00erence\\n1To say thatyi is real-valued, we writeyi œ R,w h e r eR denotes the set of all real numbers, an inﬁnite set\\nof numbers from minus inﬁnity to plus inﬁnity.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 29, 'page_label': '30'}, page_content='Figure 1: Linear Regression for one-dimensional examples.\\nwith the one-dimensional case is that the regression model is not a line but a plane (for two\\ndimensions) or a hyperplane (forD> 2).\\nNow you see why it’s essential to have the requirement that the regression hyperplane lies as\\nclose to the training examples as possible: if the blue line in ﬁg. 1 was far from the blue dots,\\nthe predictionynew would have fewer chances to be correct.\\n3.1.2 Solution\\nTo get this latter requirement satisﬁed, the optimization procedure which we use to ﬁnd the\\noptimal values forwú and bú tries to minimize the following expression:\\n1\\nN\\nÿ\\ni=1...N\\n(fw,b(xi) ≠ yi)2. (2)\\nIn mathematics, the expression we minimize or maximize is called an objective function, or,\\nsimply, an objective. The expression(f(xi) ≠ yi)2 in the above objective is called theloss\\nfunction. It’s a measure of penalty for misclassiﬁcation of examplei. This particular choice\\nof the loss function is calledsquared error loss. All model-based learning algorithms have\\na loss function and what we do to ﬁnd the best model is we try to minimize the objective\\nknown as thecost function. In linear regression, the cost function is given by the average\\nloss, also called theempirical risk. The average loss, or empirical risk, for a model, is the\\naverage of all penalties obtained by applying the model to the training data.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 30, 'page_label': '31'}, page_content='Why is the loss in linear regression a quadratic function? Why couldn’t we get the absolute\\nvalue of the di\\x00erence between the true targetyi and the predicted valuef(xi) and use that\\nas a penalty? We could. Moreover, we also could use a cube instead of a square.\\nNow you probably start realizing how many seemingly arbitrary decisions are made when we\\ndesign a machine learning algorithm: we decided to use the linear combination of features to\\npredict the target. However, we could use a square or some other polynomial to combine the\\nvalues of features. We could also use some other loss function that makes sense: the absolute\\ndi\\x00erence betweenf(xi) and yi makes sense, the cube of the di\\x00erence too; thebinary loss\\n(1 when f(xi) and yi are di\\x00erent and0 when they are the same) also makes sense, right?\\nIf we made di\\x00erent decisions about the form of the model, the form of the loss function,\\nand about the choice of the algorithm that minimizes the average loss to ﬁnd the best values\\nof parameters, we would end up inventing a di\\x00erent machine learning algorithm. Sounds\\neasy, doesn’t it? However, do not rush to invent a new learning algorithm. The fact that it’s\\ndi\\x00erent doesn’t mean that it will work better in practice.\\nPeople invent new learning algorithms for one of the two main reasons:\\n1. The new algorithm solves a speciﬁc practical problem better than the existing algorithms.\\n2. The new algorithm has better theoretical guarantees on the quality of the model it\\nproduces.\\nOne practical justiﬁcation of the choice of the linear form for the model is that it’s simple.\\nWhy use a complex model when you can use a simple one? Another consideration is that\\nlinear models rarely overﬁt.Overﬁtting is the property of a model such that the model\\npredicts very well labels of the examples used during training but frequently makes errors\\nwhen applied to examples that weren’t seen by the learning algorithm during training.\\nAn example of overﬁtting in regression is shown in ﬁg. 2. The data used to build the red\\nregression line is the same as in ﬁg. 1. The di\\x00erence is that this time, this is the polynomial\\nregression with a polynomial of degree10. The regression line predicts almost perfectly the\\ntargets almost all training examples, but will likely make signiﬁcant errors on new data, as\\nyou can see in ﬁg. 1 forxnew. We talk more about overﬁtting and how to avoid it Chapter 5.\\nNow you know why linear regression can be useful: it doesn’t overﬁt much. But what\\nabout the squared loss? Why did we decide that it should be squared? In 1705, the French\\nmathematician Adrien-Marie Legendre, who ﬁrst published the sum of squares method for\\ngauging the quality of the model stated that squaring the error before summing isconvenient.\\nWhy did he say that? The absolute value is not convenient, because it doesn’t have a\\ncontinuous derivative, which makes the function not smooth. Functions that are not smooth\\ncreate unnecessary di\\x00culties when employing linear algebra to ﬁnd closed form solutions\\nto optimization problems. Closed form solutions to ﬁnding an optimum of a function are\\nsimple algebraic expressions and are often preferable to using complex numerical optimization\\nmethods, such asgradient descent(used, among others, to train neural networks).\\nIntuitively, squared penalties are also advantageous because they exaggerate the di\\x00erence\\nbetween the true target and the predicted one according to the value of this di\\x00erence. We\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 31, 'page_label': '32'}, page_content='y\\nx\\nnew\\nnew\\nFigure 2: Overﬁtting.\\nmight also use the powers 3 or 4, but their derivatives are more complicated to work with.\\nFinally, why do we care about the derivative of the average loss? Remember from algebra\\nthat if we can calculate the gradient of the function in eq. 2, we can then set this gradient to\\nzero2 and ﬁnd the solution to a system of equations that gives us the optimal valueswú and\\nbú. You can spend several minutes and check it yourself.\\n3.2 Logistic Regression\\nThe ﬁrst thing to say is that logistic regression is not a regression, but a classiﬁcation learning\\nalgorithm. The name comes from statistics and is due to the fact that the mathematical\\nformulation of logistic regression is similar to that of linear regression.\\nI explain logistic regression on the case of binary classiﬁcation. However, it can naturally be\\nextended to multiclass classiﬁcation.\\n3.2.1 Problem Statement\\nIn logistic regression, we still want to modelyi as a linear function ofxi,h o w e v e r ,w i t ha\\nbinary yi this is not straightforward. The linear combination of features such aswxi + b is a\\nfunction that spans from minus inﬁnity to plus inﬁnity, whileyi has only two possible values.\\n2To ﬁnd the minimum or the maximum of a function, we set the gradient to zero because the value of the\\ngradient at extrema of a function is always zero. In 2D, the gradient at an extremum is a horizontal line.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 32, 'page_label': '33'}, page_content='Figure 3: Standard logistic function.\\nAt the time where the absence of computers required scientists to perform manual calculations,\\nthey were eager to ﬁnd a linear classiﬁcation model. They ﬁgured out that if we deﬁne a\\nnegative label as0 and the positive label as1, we would just need to ﬁnd a simple continuous\\nfunction whose codomain is(0, 1). In such a case, if the value returned by the model for\\ninput x is closer to0, then we assign a negative label tox; otherwise, the example is labeled\\nas positive. One function that has such a property is thestandard logistic function(also\\nknown as thesigmoid function):\\nf(x)= 1\\n1+ e≠x ,\\nwhere e is the base of the natural logarithm (also calledEuler’s number; ex is also known as\\nthe exp(x) function in Excel and many programming languages). Its graph is depicted in ﬁg.\\n3.\\nBy looking at the graph of the standard logistic function, we can see how well it ﬁts our\\nclassiﬁcation purpose: if we optimize the values ofx and b appropriately, we could interpret\\nthe output off(x) as the probability ofyi being positive. For example, if it’s higher than or\\nequal to the threshold0.5 we would say that the class ofx is positive; otherwise, it’s negative.\\nIn practice, the choice of the threshold could be di\\x00erent depending on the problem. We\\nreturn to this discussion in Chapter 5 when we talk about model performance assessment.\\nSo our logistic regression model looks like this:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 33, 'page_label': '34'}, page_content='fw,b(x)\\ndef\\n= 1\\n1+ e≠(wx+b) . (3)\\nYou can see the familiar termwx + b from linear regression. Now, how do we ﬁnd the best\\nvalues wú and bú for our model? In linear regression, we minimized the empirical risk which\\nwas deﬁned as the average squared error loss, also known as themean squared erroror\\nMSE.\\n3.2.2 Solution\\nIn logistic regression, instead of using a squared loss and trying to minimize the empirical\\nrisk, we maximize thelikelihood of our training set according to the model. In statistics, the\\nlikelihood function deﬁnes how likely the observation (an example) is according to our model.\\nFor instance, assume that we have a labeled example(xi,y i) in our training data. Assume\\nalso that we have found (guessed) some speciﬁc valuesˆwand ˆb of our parameters. If we now\\napply our modelfˆw,ˆb to xi using eq. 3 we will get some value0 <p< 1 as output. Ifyi is\\nthe positive class, the likelihood ofyi being the positive class, according to our model, is\\ngiven byp. Similarly, ifyi is the negative class, the likelihood of it being the negative class is\\ngiven by1 ≠ p.\\nThe optimization criterion in logistic regression is calledmaximum likelihood. Instead of\\nminimizing the average loss, like in linear regression, we now maximize the likelihood of the\\ntraining data according to our model:\\nLw,b\\ndef\\n=\\nŸ\\ni=1...N\\nfw,b(xi)yi (1 ≠ fw,b(xi))(1≠yi). (4)\\nThe expressionfw,b(x)yi (1 ≠fw,b(x))(1≠yi) may look scary but it’s just a fancy mathematical\\nway of saying: “fw,b(x) when yi =1 and (1 ≠ fw,b(x)) otherwise” . Indeed, ifyi =1 ,t h e n\\n(1 ≠ fw,b(x))(1≠yi) equals 1 because (1 ≠ yi)=0 and we know that anything power0 equals\\n1. On the other hand, ifyi =0 ,t h e nfw,b(x)yi equals 1 for the same reason.\\nYou may have noticed that we used the product operatorr in the objective function instead\\nof the sum operatorq which was used in linear regression. It’s because the likelihood of\\nobserving N labels forN examples is the product of likelihoods of each observation (assuming\\nthat all observations are independent of one another, which is the case). You can draw\\na parallel with the multiplication of probabilities of outcomes in a series of independent\\nexperiments in the probability theory.\\nBecause of theexp function used in the model, in practice, it’s more convenient to maximize\\nthe log-likelihood instead of likelihood. The log-likelihood is deﬁned like follows:\\nLogLw,b\\ndef\\n=l n (L(w,b(x)) =\\nNÿ\\ni=1\\nyi ln fw,b(x)+( 1 ≠ yi)l n( 1≠ fw,b(x)).\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 34, 'page_label': '35'}, page_content='Because ln is astrictly increasing function, maximizing this function is the same as maximizing\\nits argument, and the solution to this new optimization problem is the same as the solution\\nto the original problem.\\nContrary to linear regression, there’s no closed form solution to the above optimization\\nproblem. A typical numerical optimization procedure used in such cases isgradient descent.\\nI talk about it in the next chapter.\\n3.3 Decision Tree Learning\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\nnode of the graph, a speciﬁc featurej of the feature vector is examined. If the value of the\\nfeature is below a speciﬁc threshold, then the left branch is followed; otherwise, the right\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\nthe example belongs.\\nAs the title of the section suggests, a decision tree can be learned from data.\\n3.3.1 Problem Statement\\nLike previously, we have a collection of labeled examples; labels belong to the set{0, 1}.W e\\nwant to build a decision tree that would allow us to predict the class of an example given a\\nfeature vector.\\n3.3.2 Solution\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\nconsider just one, calledID3.\\nThe optimization criterion, in this case, is the average log-likelihood:\\n1\\nN\\nNÿ\\ni=1\\nyi ln fID3(xi)+( 1 ≠ yi)l n( 1≠ fID3(xi)), (5)\\nwhere fID3 is a decision tree.\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\nlearning algorithm which builds aparametric modelfwú,bú by ﬁnding anoptimal solution\\nto the optimization criterion, the ID3 algorithm optimizes itapproximately by constructing a\\nnon-parametric modelfID3(x)\\ndef\\n=P r (y =1 |x).\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 35, 'page_label': '36'}, page_content='S={(x1,\\xa0y1),\\xa0(x2,\\xa0y2),\\xa0(x3,\\xa0y3),(x4,\\xa0y4),\\xa0(x5,\\xa0y5),\\xa0(x6,\\xa0y6),(x7,\\xa0y7),\\xa0(x8,\\xa0y8),\\xa0(x9,\\xa0y9),(x10,\\xa0y10),\\xa0(x11,\\xa0y11),\\xa0(x12,\\xa0y12)}\\nx\\nPr(y\\xa0=\\xa01|x)\\xa0=\\xa0(y1+y2+y3+y4+y5\\xa0+y6+y7+y8+y9+y10+y11+y12)/12\\nPr(y\\xa0=\\xa01|x)\\n(a)\\nx\\nPr(y\\xa0=\\xa01|x)\\xa0=\\xa0(y1+y2+y4\\xa0+y6+y7+y8+y9)/7\\nPr(y\\xa0=\\xa01|x)\\nx(3)\\xa0<\\xa018.3?\\nS\\xad\\xa0=\\xa0{(x1,\\xa0y1),\\xa0(x2,\\xa0y2),(x4,\\xa0y4),\\xa0(x6,\\xa0y6),\\xa0(x7,\\xa0y7),(x8,\\xa0y8),\\xa0(x9,\\xa0y9)}\\xa0\\nPr(y\\xa0=\\xa01|x)\\xa0=(y3+y5+y10+y11+y12)/5\\nPr(y\\xa0=\\xa01|x)\\nS+\\xa0=\\xa0{(x3,\\xa0y3),\\xa0(x5,\\xa0y5),\\xa0(x10,\\xa0y10),(x11,\\xa0y11),\\xa0(x12,\\xa0y12)}\\xa0\\nYes No\\n(b)\\nFigure 4: An illustration of a decision tree building algorithm. The setS contains 12 labeled\\nexamples. (a) In the beginning, the decision tree only contains the start node; it makes the\\nsame prediction for any input. (b) The decision tree after the ﬁrst split; it tests whether\\nfeature 3 is less than18.3 and, depending on the result, the prediction is made in one of the\\ntwo leaf nodes.\\nThe ID3 learning algorithm works as follows. LetS denote a set of labeled examples. In the\\nbeginning, the decision tree only has a start node that contains all examples:S\\ndef\\n= {(xi,y i)}N\\ni=1.\\nStart with a constant modelfS\\nID3:\\nfS\\nID3 = 1\\n|S|\\nÿ\\n(x,y)œS\\ny. (6)\\nThe prediction given by the above model,fS\\nID3(x), would be the same for any inputx.T h e\\ncorresponding decision tree is shown in ﬁg 4a.\\nThen we search through all featuresj =1 ,...,D and all thresholdst, and split the setS\\ninto two subsets:S≠\\ndef\\n= {(x,y ) | (x,y ) œS ,x (j) <t } and S+ = {(x,y ) | (x,y ) œ S,x (j) Ø t}.\\nThe two new subsets would go to two new leaf nodes, and we evaluate, for all possible pairs\\n(j, t) how good the split with piecesS≠ and S+ is. Finally, we pick the best such values(j, t),\\nsplit S into S+ and S≠, form two new leaf nodes, and continue recursively onS+ and S≠ (or\\nquit if no split produces a model that’s su\\x00ciently better than the current one). A decision\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 36, 'page_label': '37'}, page_content='tree after one split is illustrated in ﬁg 4b.\\nNow you should wonder what do the words “evaluate how good the split is” mean. In ID3, the\\ngoodness of a split is estimated by using the criterion calledentropy. Entropy is a measure of\\nuncertainty about a random variable. It reaches its maximum when all values of the random\\nvariables are equiprobable. Entropy reaches its minimum when the random variable can have\\nonly one value. The entropy of a set of examplesS is given by:\\nH(S)= ≠fS\\nID3 ln fS\\nID3 ≠ (1 ≠ fS\\nID3)l n ( 1≠ fS\\nID3).\\nWhen we split a set of examples by a certain featurej and a thresholdt, the entropy of a\\nsplit, H(S≠, S+), is simply a weighted sum of two entropies:\\nH(S≠, S+)= |S≠|\\n|S| H(S≠)+ |S+|\\n|S| H(S+). (7)\\nSo, in ID3, at each step, at each leaf node, we ﬁnd a split that minimizes the entropy given\\nby eq. 7 or we stop at this leaf node.\\nThe algorithm stops at a leaf node in any of the below situations:\\n• All examples in the leaf node are classiﬁed correctly by the one-piece model (eq. 6).\\n• We cannot ﬁnd an attribute to split upon.\\n• The split reduces the entropy less than some‘ (the value for which has to be found\\nexperimentally3).\\n• The tree reaches some maximum depthd (also has to be found experimentally).\\nBecause in ID3, the decision to split the dataset on each iteration is local (doesn’t depend\\non future splits), the algorithm doesn’t guarantee an optimal solution. The model can be\\nimproved by using techniques likebacktracking during the search for the optimal decision\\ntree at the cost of possibly taking longer to build a model.\\nThe entropy-based split criterion intuitively makes sense: entropy\\nreaches its minimum of0 when all examples inS have the same label;\\non the other hand, the entropy is at its maximum of1 when exactly\\none-half of examples inS is labeled with1, making such a leaf useless\\nfor classiﬁcation. The only remaining question is how this algorithm\\napproximately maximizes the average log-likelihood criterion. I leave it\\nfor further reading.\\n3In Chapter 5, we will see how to do that when we talk about hyperparameter tuning.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 37, 'page_label': '38'}, page_content='3.4 Support Vector Machine\\nWe already considered SVM in the introduction, so this section only ﬁlls a couple of blanks.\\nTwo critical questions need to be answered:\\n1. What if there’s noise in the data and no hyperplane can perfectly separate positive\\nexamples from negative ones?\\n2. What if the data cannot be separated using a plane, but could be separated by a\\nhigher-order polynomial?\\nFigure 5: Linearly non-separable cases. Left: the presence of noise. Right: inherent\\nnonlinearity.\\nYou can see both situations depicted in ﬁg 5. In the left case, the data could be separated by\\na straight line if not for the noise (outliers or examples with wrong labels). In the right case,\\nthe decision boundary is a circle and not a straight line.\\nRemember that in SVM, we want to satisfy the following constraints:\\na) wxi ≠ b Ø 1 if yi =+ 1, and\\nb) wxi ≠ b Æ≠ 1 if yi = ≠1\\nWe also want to minimizeÎwÎ so that the hyperplane was equally distant from the closest\\nexamples of each class. MinimizingÎwÎ is equivalent to minimizing1\\n2 ||w||2, and the use of\\nthis term makes it possible to perform quadratic programming optimization later on. The\\noptimization problem for SVM, therefore, looks like this:\\nmin 1\\n2||w||2, such thatyi(xiw ≠ b) ≠ 1 Ø 0,i =1 ,...,N. (8)\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 12'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 38, 'page_label': '39'}, page_content='3.4.1 Dealing with Noise\\nTo extend SVM to cases in which the data is not linearly separable, we introduce thehinge\\nloss function: max (0, 1 ≠ yi(wxi ≠ b)).\\nThe hinge loss function is zero if the constraints a) and b) are satisﬁed, in other words, ifwxi\\nlies on the correct side of the decision boundary. For data on the wrong side of the decision\\nboundary, the function’s value is proportional to the distance from the decision boundary.\\nWe then wish to minimize the following cost function,\\nCÎwÎ2 + 1\\nN\\nNÿ\\ni=1\\nmax (0, 1 ≠ yi(wxi ≠ b)) ,\\nwhere the hyperparameter C determines the tradeo\\x00 between increasing the size of the\\ndecision boundary and ensuring that eachxi lies on the correct side of the decision boundary.\\nThe value ofC is usually chosen experimentally, just like ID3’s hyperparameters‘ and d.\\nSVMs that optimize hinge loss are calledsoft-margin SVMs, while the original formulation is\\nreferred to as ahard-margin SVM.\\nAs you can see, for su\\x00ciently high values ofC, the second term in the cost function will\\nbecome negligible, so the SVM algorithm will try to ﬁnd the highest margin by completely\\nignoring misclassiﬁcation. As we decrease the value ofC, making classiﬁcation errors is\\nbecoming more costly, so the SVM algorithm will try to make fewer mistakes by sacriﬁcing\\nthe margin size. As we have already discussed, a larger margin is better for generalization.\\nTherefore, C regulates the tradeo\\x00 between classifying the training data well (minimizing\\nempirical risk) and classifying future examples well (generalization).\\n3.4.2 Dealing with Inherent Non-Linearity\\nSVM can be adapted to work with datasets that cannot be separated by a hyperplane in\\nits original space. However, if we manage to transform the original space into a space of\\nhigher dimensionality, we could hope that the examples will become linearly separable in this\\ntransformed space. In SVMs, using a function toimplicitly transform the original space into\\na higher dimensional space during the cost function optimization is called thekernel trick.\\nThe e\\x00ect of applying the kernel trick is illustrated in ﬁg. 6. As you can see, it’s possible\\nto transform a two-dimensional non-linearly-separable data into a linearly-separable three-\\ndimensional data using a speciﬁc mapping„ : x ‘æ „(x),w h e r e„(x) is a vector of higher\\ndimensionality than x. For the example of 2D data in ﬁg. 5 (right), the mapping„ for\\nexample x =[ q, p] that projects this example into a 3D space (ﬁg. 6) would look like this\\n„([q, p])\\ndef\\n= (q2,\\nÔ\\n2qp, p2),w h e r eq2 means q squared. You see now that the data becomes\\nlinearly separable in the transformed space.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 13'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 39, 'page_label': '40'}, page_content='Figure 6: The data from ﬁg. 5 (right) becomes linearly separable after a transformation into\\na three-dimensional space.\\nHowever, we don’t know a priori which mapping„ would work for our data. If we ﬁrst\\ntransform all our input examples using some mapping into very high dimensional vectors and\\nthen apply SVM to this data, and we try all possible mapping functions, the computation\\ncould become very ine\\x00cient, and we would never solve our classiﬁcation problem.\\nFortunately, scientists ﬁgured out how to usekernel functions (or, simply, kernels)t o\\ne\\x00ciently work in higher-dimensional spaceswithout doing this transformation explicitly.T o\\nunderstand how kernels work, we have to see ﬁrst how the optimization algorithm for SVM\\nﬁnds the optimal values forw and b.\\nThe method traditionally used to solve the optimization problem in eq. 8 is themethod of\\nLagrange multipliers. Instead of solving the original problem from eq. 8, it is convenient to\\nsolve an equivalent problem formulated like this:\\nmax\\n–1...–N\\nNÿ\\ni=1\\n–i ≠ 1\\n2\\nNÿ\\ni=1\\nNÿ\\nk=1\\nyi–i(xixk)yk–k subject to\\nNÿ\\ni=1\\n–iyi =0 and –i Ø 0,i =1 ,...,N,\\nwhere –i are called Lagrange multipliers. When formulated like this, the optimization\\nproblem becomes a convex quadratic optimization problem, e\\x00ciently solvable by quadratic\\nprogramming algorithms.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 14'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 40, 'page_label': '41'}, page_content='Now, you could have noticed that in the above formulation, there is a termxixk, and this is\\nthe only place where the feature vectors are used. If we want to transform our vector space\\ninto higher dimensional space, we need to transformxi into „(xi) and xj into „(xj) and\\nthen multiply„(xi) and „(xj). It would be very costly to do so.\\nOn the other hand, we are only interested in the result of the dot-productxixk, which, as\\nwe know, is a real number. We don’t care how this number was obtained as long as it’s\\ncorrect. By using the kernel trick, we can get rid of a costly transformation of original\\nfeature vectors into higher-dimensional vectors and avoid computing their dot-product. We\\nreplace that by a simple operation on the original feature vectors that gives the same\\nresult. For example, instead of transforming(q1,p 1) into (q2\\n1,\\nÔ\\n2q1p1,p 2\\n1) and (q2,p 2) into\\n(q2\\n2,\\nÔ\\n2q2p2,p 2\\n2) and then computing the dot-product of(q2\\n1,\\nÔ\\n2q1p1,p 2\\n1) and (q2\\n2,\\nÔ\\n2q2p2,p 2\\n2)\\nto obtain(q2\\n1q2\\n2 +2 q1q2p1p2 + p2\\n1p2\\n2) we could ﬁnd the dot-product between(q1,p 1) and (q2,p 2)\\nto get(q1q2 +p1p2) and then square it to get exactly the same result(q2\\n1q2\\n2 +2q1q2p1p2 +p2\\n1p2\\n2).\\nThat was an example of the kernel trick, and we used the quadratic kernelk(xi, xk)\\ndef\\n= (xixk)2.\\nMultiple kernel functions exist, the most widely used of which is theRBF kernel:\\nk(x, xÕ)=e x p\\n3\\n≠Îx ≠ xÕÎ2\\n2‡2\\n4\\n,\\nwhere Îx ≠ xÕÎ2 is the squared Euclidean distance between two feature vectors. The\\nEuclidean distance is given by the following equation:\\nd(xi, xk)\\ndef\\n=\\nÚ1\\nx(1)\\ni ≠ x(1)\\nk\\n22\\n+\\n1\\nx(2)\\ni ≠ x(2)\\nk\\n22\\n+ ··· +\\n1\\nx(N)\\ni ≠ x(N)\\nk\\n22\\n=\\nˆııÙ\\nDÿ\\nj=1\\n1\\nx(j)\\ni ≠ x(j)\\nk\\n22\\n.\\nIt can be shown that the feature space of the RBF (for “radial basis function”) kernel has\\nan inﬁnite number of dimensions. By varying the hyperparameter‡, the data analyst can\\nchoose between getting a smooth or curvy decision boundary in the original space.\\n3.5 k-Nearest Neighbors\\nk-Nearest Neighbors(kNN) is a non-parametric learning algorithm. Contrary to other\\nlearning algorithms that allow discarding the training data after the model is built, kNN\\nkeeps all training examples in memory. Once a new, previously unseen examplex comes in,\\nthe kNN algorithm ﬁndsk training examples closest tox and returns the majority label (in\\ncase of classiﬁcation) or the average label (in case of regression).\\nThe closeness of two points is given by a distance function. For example, Euclidean distance\\nseen above is frequently used in practice. Another popular choice of the distance function is\\nthe negativecosine similarity. Cosine similarity deﬁned as,\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 15'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 41, 'page_label': '42'}, page_content='s(xi, xk)\\ndef\\n= cos(\\\\(xi, xk)) =\\nqD\\nj=1 x(j)\\ni x(j)\\nkÚ\\nqD\\nj=1\\n1\\nx(j)\\ni\\n22\\nÚ\\nqD\\nj=1\\n1\\nx(j)\\nk\\n22\\n,\\nis a measure of similarity of the directions of two vectors. If the angle between two vectors\\nis 0 degrees, then two vectors point to the same direction, and cosine similarity is equal to\\n1. If the vectors are orthogonal, the cosine similarity is0. For vectors pointing in opposite\\ndirections, the cosine similarity is≠1. If we want to use cosine similarity as a distance metric,\\nwe need to multiply it by≠1. Other popular distance metrics include Chebychev distance,\\nMahalanobis distance, and Hamming distance. The choice of the distance metric, as well as\\nthe value fork, are the choices the analyst makes before running the algorithm. So these\\nare hyperparameters. The distance metric could also be learned from data (as opposed to\\nguessing it). We talk about that in Chapter 10.\\nNow you know how the model building algorithm works and how the prediction is made. A\\nreasonable question is what is the cost function here? Surprisingly, this question has not\\nbeen well studied in the literature, despite the algorithm’s popularity since the earlier 1960s.\\nThe only attempt to analyze the cost function of kNN I’m aware of was undertaken by Li\\nand Yang in 20034. Below, I outline their considerations.\\nFor simplicity, let’s make our derivation under the assumptions of binary classiﬁcation\\n(y œ{ 0, 1}) with cosine similarity andnormalized feature vectors5. Under these assumptions,\\nkNN does a locally linear classiﬁcation with the vector of coe\\x00cients,\\nwx =\\nÿ\\n(xÕ,yÕ)œRk(x)\\nyÕxÕ, (9)\\nwhere Rk(x) is the set ofk nearest neighbors to the input examplex. The above equation\\nsays that we take the sum of all nearest neighbor feature vectors to some input vectorx\\nby ignoring those that have label0. The classiﬁcation decision is obtained by deﬁning a\\nthreshold on the dot-productwxx which, in the case of normalized feature vectors, is equal\\nto the cosine similarity betweenwx and x.\\nNow, deﬁning the cost function like this:\\nL = ≠\\nÿ\\n(xÕ,yÕ)œRk(x)\\nyÕxÕwx + 1\\n2||w||2\\nand setting the ﬁrst order derivative of the right-hand side to zero yields the formula for the\\ncoe\\x00cient vector in eq. 9.\\n4F. Li and Y. Yang, “A loss function analysis for classiﬁcation methods in text categorization,” in ICML\\n2003, pp. 472–479, 2003.\\n5We discuss normalization later; for the moment assume that all features of feature vectors were squeezed\\ninto the range[0, 1].\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 16'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 42, 'page_label': '43'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 43, 'page_label': '44'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 44, 'page_label': '45'}, page_content='4 Anatomy of a Learning Algorithm\\n4.1 Building Blocks of a Learning Algorithm\\nYou may have noticed by reading the previous chapter that each learning algorithm we saw\\nconsisted of three parts:\\n1) a loss function;\\n2) an optimization criterion based on the loss function (a cost function, for example); and\\n3) an optimization routine that leverages training data to ﬁnd a solution to the optimization\\ncriterion.\\nThese are the building blocks of any learning algorithm. You saw in the previous chapter\\nthat some algorithms were designed to explicitly optimize a speciﬁc criterion (both linear and\\nlogistic regressions, SVM). Some others, including decision tree learning and kNN, optimize\\nthe criterion implicitly. Decision tree learning and kNN are among the oldest machine\\nlearning algorithms and were invented experimentally based on intuition, without a speciﬁc\\nglobal optimization criterion in mind, and (like it often happens in scientiﬁc history) the\\noptimization criteria were developed later to explain why those algorithms work.\\nBy reading modern literature on machine learning, you often encounter references togradient\\ndescent or stochastic gradient descent. These are two most frequently used optimization\\nalgorithms used in cases where the optimization criterion is di\\x00erentiable.\\nGradient descent is an iterative optimization algorithm for ﬁnding the minimum of a function.\\nTo ﬁnd alocal minimum of a function using gradient descent, one starts at some random\\npoint and takes steps proportional to the negative of the gradient (or approximate gradient)\\nof the function at the current point.\\nGradient descent can be used to ﬁnd optimal parameters for linear and logistic regression,\\nSVM and also neural networks which we consider later. For many models, such as logistic\\nregression or SVM, the optimization criterion isconvex. Convex functions have only one\\nminimum, which is global. Optimization criteria for neural networks are not convex, but in\\npractice even ﬁnding a local minimum su\\x00ces.\\nLet’s see how gradient descent works.\\n4.2 Gradient Descent\\nIn this section, I demonstrate how gradient descent ﬁnds the solution to a linear regression\\nproblem1. I illustrate my description with Python source code as well as with plots that\\nshow how the solution improves after some iterations of the gradient descent algorithm.\\n1As you know, linear regression has a closed form solution. That means that gradient descent is not\\nneeded to solve this speciﬁc type of problem. However, for illustration purposes, linear regression is a perfect\\nproblem to explain gradient descent.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 45, 'page_label': '46'}, page_content='I use a dataset with only one feature. However, the optimization criterion will have two\\nparameters: w and b. The extension to multi-dimensional training data is straightforward:\\nyou have variablesw(1), w(2), and b for two-dimensional data,w(1), w(2), w(3), and b for\\nthree-dimensional data and so on.\\nFigure 1: The original data. The Y-axis corresponds to the sales in units (the quantity we\\nwant to predict), the X-axis corresponds to our feature: the spendings on radio ads in M$.\\nTo give a practical example, I use the real dataset with the following columns: the Spendings\\nof various companies on radio advertising each year and their annual Sales in terms of units\\nsold. We want to build a regression model that we can use to predict units sold based on\\nhow much a company spends on radio advertising. Each row in the dataset represents one\\nspeciﬁc company:\\nCompany Spendings, M$ Sales, Units\\n1 37.8 22.1\\n2 39.3 10.4\\n3 45.9 9.3\\n4 41.3 18.5\\n.. .. ..\\nWe have data for 200 companies, so we have 200 training examples. Fig. 1 shows all examples\\non a 2D plot.\\nRemember that the linear regression model looks like this:f(x)= wx + b. We don’t know\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 46, 'page_label': '47'}, page_content='what the optimal values forw and b are and we want to learn them from data. To do that,\\nwe look for such values forw and b that minimize the mean squared error:\\nl = 1\\nN\\nNÿ\\ni=1\\n(yi ≠(wxi + b))2.\\nGradient descent starts with calculating the partial derivative for every parameter:\\nˆl\\nˆw = 1\\nN\\nNÿ\\ni=1\\n≠2xi(yi ≠(wxi + b));\\nˆl\\nˆb = 1\\nN\\nNÿ\\ni=1\\n≠2(yi ≠(wxi + b)).\\n(1)\\nTo ﬁnd the partial derivative of the term(yi ≠ (wx + b))2 with respect tow we applied the\\nchain rule. Here, we have the chainf = f2(f1) where f1 = yi ≠(wx + b) and f2 = f2\\n1 .T o ﬁ n d\\na partial derivative off with respect tow we have to ﬁrst ﬁnd the partial derivative off with\\nrespect to f2 which is equal to2(yi ≠ (wx + b)) (from calculus, we know that the derivative\\nˆf\\nˆx x2 =2 x) and then we have to multiply it by the partial derivative ofyi ≠(wx + b) with\\nrespect tow which is equal to≠x. So overall ˆl\\nˆw = 1\\nN\\nqN\\ni=1 ≠2xi(yi ≠(wxi + b)). In a similar\\nway, the partial derivative ofl with respect tob, ˆl\\nˆb , was calculated.\\nWe initialize2 w0 =0 and b0 =0 and then iterate through our training examples, each\\nexample having the form of(xi,y i)=( Spendingsi,Sa l e si). For each training example, we\\nupdate w and b using our partial derivatives. The learning rate– controls the size of an\\nupdate:\\nwi Ω –≠2xi(yi ≠(wi≠1xi + bi≠1))\\nN ;\\nbi Ω –≠2(yi ≠(wi≠1xi + bi≠1))\\nN ,\\n(2)\\nwhere wi and bi denote the values ofw and b after using the example(xi,y i) for the update.\\nOne pass through all training examples is called anepoch. Typically, we need multiple\\nepochs until we start seeing that the values forw and b don’t change much; then we stop.\\n2In complex models, such as neural networks, which have thousands of parameters, the initialization of\\nparameters may signiﬁcantly a\\x00ect the solution found using gradient descent. There are di\\x00erent initialization\\nmethods (at random, with all zeroes, with small values around zero, and others) and it is an important choice\\nthe data analyst has to make.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 47, 'page_label': '48'}, page_content='It’s hard to imagine a machine learning engineer who doesn’t use Python. So, if you waited\\nfor the right moment to start learning Python, this is that moment. Below we show how to\\nprogram gradient descent in Python.\\nThe function that updates the parametersw and b during one epoch is shown below:\\ndef update_w_and_b(spendings, sales, w, b, alpha):\\ndl_dw = 0.0\\ndl_db = 0.0\\nN = len(spendings)\\nfor i in range(N):\\ndl_dw += -2*spendings[i]*(sales[i] - (w*spendings[i] + b))\\ndl_db += -2*(sales[i] - (w*spendings[i] + b))\\n# update w and b\\nw = w - (1/float(N))*dl_dw*alpha\\nb = b - (1/float(N))*dl_db*alpha\\nreturn w, b\\nThe function that loops over multiple epochs is shown below:\\ndef train(spendings, sales, w, b, alpha, epochs):\\nfor e in range(epochs):\\nw, b = update_w_and_b(spendings, sales, w, b, alpha)\\n# log the progress\\nif e % 400 == 0:\\nprint(\"epoch:\", e, \"loss: \", avg_loss(spendings, sales, w, b))\\nreturn w, b\\nThe function avg_loss in the above code snippet is a function that computes the mean\\nsquared error. It is deﬁned as:\\ndef avg_loss(spendings, sales, w, b):\\nN = len(spendings)\\ntotal_error = 0.0\\nfor i in range(N):\\ntotal_error += (sales[i] - (w*spendings[i] + b))**2\\nreturn total_error / float(N)\\nIf we run thetrain function for– =0 .001, w =0 .0, b =0 .0, and 15000 epochs, we will see\\nthe following output (shown partially):\\nepoch: 0 loss: 92.32078294903626\\nepoch: 400 loss: 33.79131790081576\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 48, 'page_label': '49'}, page_content='epoch: 800 loss: 27.9918542960729\\nepoch: 1200 loss: 24.33481690722147\\nepoch: 1600 loss: 22.028754937538633\\n...\\nepoch: 2800 loss: 19.07940244306619\\nEpoch 0\\n Epoch 400\\n Epoch 800\\nEpoch 1200\\n Epoch 1600\\n Epoch 3000\\nFigure 2: The evolution of the regression line through gradient descent epochs.\\nYou can see that the average loss decreases as thetrain function loops through epochs. Fig.\\n2 shows the evolution of the regression line through epochs.\\nFinally, once we have found the optimal values of parametersw and b, the only missing piece\\nis a function that makes predictions:\\ndef predict(x, w, b):\\nreturn w*x + b\\nTry to execute the following code:\\nw, b = train(x, y, 0.0, 0.0, 0.001, 15000)\\nx_new = 23.0\\ny_new = predict(x_new, w, b)\\nprint(y_new)\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 49, 'page_label': '50'}, page_content='The output is13.97.\\nThe gradient descent algorithm is sensitive to the choice of the step–. It is also slow for large\\ndatasets. Fortunately, several signiﬁcant improvements to this algorithm have been proposed.\\nStochastic gradient descent(SGD) is a version of the algorithm that speeds up the\\ncomputation by approximating the gradient using smaller batches (subsets) of the training\\ndata. SGD itself has various “upgrades” .Adagrad is a version of SGD that scales– for\\neach parameter according to the history of gradients. As a result,– is reduced for very large\\ngradients and vice-versa.Momentum is a method that helps accelerate SGD by orienting\\nthe gradient descent in the relevant direction and reducing oscillations. In neural network\\ntraining, variants of SGD such asRMSprop and Adam, are most frequently used.\\nNotice that gradient descent and its variants are not machine learning algorithms. They are\\nsolvers of minimization problems in which the function to minimize has a gradient in most\\npoints of its domain.\\n4.3 How Machine Learning Engineers Work\\nUnless you are a research scientist or work for a huge corporation with a large R&D budget,\\nyou usually don’t implement machine learning algorithms yourself. You don’t implement\\ngradient descent or some other solver either. You use libraries, most of which are open\\nsource. A library is a collection of algorithms and supporting tools implemented with stability\\nand e\\x00ciency in mind. The most frequently used in practice open-source machine learning\\nlibrary isscikit-learn. It’s written in Python and C. Here’s how you do linear regression in\\nscikit-learn:\\ndef train(x, y):\\nfrom sklearn.linear_model import LinearRegression\\nmodel = LinearRegression().fit(x,y)\\nreturn model\\nmodel = train(x,y)\\nx_new = 23.0\\ny_new = model.predict(x_new)\\nprint(y_new)\\nThe output will, again, be13.97. Easy, right? You can replace LinearRegression with some\\nother type of regression learning algorithm without modifying anything else. It just works.\\nThe same can be said about classiﬁcation. You can easily replaceLogisticRegressionalgorithm\\nwith SVC algorithm (this is scikit-learn’s name for the Support Vector Machine algorithm),\\nDecisionTreeClassiﬁer, NearestNeighbors or many other classiﬁcation learning algorithms\\nimplemented in scikit-learn.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 50, 'page_label': '51'}, page_content='4.4 Learning Algorithms’ Particularities\\nHere we outline some practical particularities that can di\\x00erentiate one learning algorithm\\nfrom another. You already know that di\\x00erent learning algorithms can have di\\x00erent\\nhyperparameters (C in SVM,‘ and d in ID3). Solvers such as gradient descent can also have\\nhyperparameters, like– for example.\\nSome algorithms, like decision tree learning, can accept categorical features. For example, if\\nyou have a feature “color” that can take values “red”, “yellow”, or “green”, you can keep\\nthis feature as is. SVM, logistic and linear regression, as well as kNN (with cosine similarity\\nor Euclidean distance metrics), expect numerical values for all features. All algorithms\\nimplemented in scikit-learn expect numerical features. I show in the next chapter how to\\nconvert categorical features into numerical ones.\\nSome algorithms, like SVM, allow the data analyst to provide weightings for each class.\\nThese weightings inﬂuence how the decision boundary is drawn. If the weight of some class\\nis high, the learning algorithm tries to not make errors in predicting training examples of\\nthis class (typically, for the cost of making an error elsewhere). That could be important if\\ninstances of some class are in the minority in your training data, but you would like to avoid\\nmisclassifying examples of that class as much as possible.\\nSome classiﬁcation models, like SVM and kNN, given a feature vector only output the class.\\nOthers, like logistic regression or decision trees, can also return the score between0 and 1\\nwhich can be interpreted as either how conﬁdent the model is about the prediction or as the\\nprobability that the input example belongs to a certain class3.\\nSome classiﬁcation algorithms (like decision tree learning, logistic regression, or SVM) build the\\nmodel using the whole dataset at once. If you have got additional labeled examples, you have\\nto rebuild the model from scratch. Other algorithms (such as Naïve Bayes, multilayer percep-\\ntron, SGDClassiﬁer/SGDRegressor, PassiveAggressiveClassiﬁer/PassiveAggressiveRegressor\\nin scikit-learn) can be trained iteratively, one batch at a time. Once new training examples\\nare available, you can update the model using only the new data.\\nFinally, some algorithms, like decision tree learning, SVM, and kNN can be used for both clas-\\nsiﬁcation and regression, while others can only solve one type of problem: either classiﬁcation\\nor regression, but not both.\\nUsually, each library provides the documentation that explains what kind of problem each\\nalgorithm solves, what input values are allowed and what kind of output the model produces.\\nThe documentation also provides information on hyperparameters.\\n3If it’s really necessary, the score for SVM and kNN predictions could be synthetically created using some\\nsimple techniques.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 51, 'page_label': '52'}, page_content=\"Andriy Burkov's\"),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 52, 'page_label': '53'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 53, 'page_label': '54'}, page_content='5 Basic Practice\\nUntil now, I only mentioned in passing some problems a data analyst can encounter when\\nworking on a machine learning problem: feature engineering, overﬁtting, and hyperparameter\\ntuning. In this chapter, we talk about these and other challenges that have to be addressed\\nbefore you can typemodel = LogisticRegresion().ﬁt(x,y)in scikit-learn.\\n5.1 Feature Engineering\\nWhen a product manager tells you “We need to be able to predict whether a particular\\ncustomer will stay with us. Here are the logs of customers’ interactions with our product for\\nﬁve years. ” you cannot just grab the data, load it into a library and get a prediction. You\\nneed to build adataset ﬁrst.\\nRemember from the ﬁrst chapter that the dataset is the collection oflabeled examples\\n{(xi,y i)}N\\ni=1. Each elementxi among N is called afeature vector. A feature vector is a\\nvector in which each dimensionj =1 ,...,D contains a value that describes the example\\nsomehow. That value is called afeature and is denoted asx(j).\\nThe problem of transforming raw data into a dataset is calledfeature engineering. For\\nmost practical problems, feature engineering is a labor-intensive process that demands from\\nthe data analyst a lot of creativity and, preferably, domain knowledge.\\nFor example, to transform the logs of user interaction with a computer system, one could\\ncreate features that contain information about the user and various statistics extracted from\\nthe logs. For each user, one feature would contain the price of the subscription; other features\\nwould contain the frequency of connections per day, week and year. Another feature would\\ncontain the average session duration in seconds or the average response time for one request,\\nand so on. Everything measurable can be used as a feature. The role of the data analyst is to\\ncreate informative features: those would allow the learning algorithm to build a model that\\npredicts well labels of the data used for training. Highly informative features are also called\\nfeatures with highpredictive power. For example, the average duration of a user’s session\\nhas high predictive power for the problem of predicting whether the user will keep using the\\napplication in the future.\\nWe say that a model has alow biaswhen it predicts well the training data. That is, the\\nmodel makes few mistakes when we try to predict labels of the examples used to build the\\nmodel.\\n5.1.1 One-Hot Encoding\\nSome learning algorithms only work with numerical feature vectors. When some feature in\\nyour dataset is categorical, like “colors” or “days of the week,” you can transform such a\\ncategorical feature into several binary ones.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 54, 'page_label': '55'}, page_content='If your example has a categorical feature “colors” and this feature has three possible values:\\n“red,” “yellow,” “green,” you can transform this feature into a vector of three numerical\\nvalues:\\nred =[ 1, 0, 0]\\nyellow =[ 0, 1, 0]\\ngreen =[ 0, 0, 1]\\n(1)\\nBy doing so, you increase the dimensionality of your feature vectors. You should not transform\\nred into1,y e l l o wi n t o2, and green into3 to avoid increasing the dimensionality because that\\nwould imply that there’s an order among the values in this category and this speciﬁc order is\\nimportant for the decision making. If the order of a feature’s values is not important, using\\nordered numbers as values is likely to confuse the learning algorithm,1 because the algorithm\\nwill try to ﬁnd a regularity where there’s no one, which may potentially lead to overﬁtting.\\n5.1.2 Binning\\nAn opposite situation, occurring less frequently in practice, is when you have a numerical\\nfeature but you want to convert it into a categorical one.Binning (also calledbucketing)\\nis the process of converting a continuous feature into multiple binary features called bins or\\nbuckets, typically based on value range. For example, instead of representing age as a single\\nreal-valued feature, the analyst could chop ranges of age into discrete bins: all ages between\\n0 and 5 years-old could be put into one bin,6 to 10 years-old could be in the second bin,11\\nto 15 years-old could be in the third bin, and so on.\\nFor example, suppose in our featurej = 18represents age. By applying binning, we replace\\nthis feature with the corresponding bins. Let the three new bins, “age_bin1”, “age_bin2”\\nand “age_bin3” be added with indexesj = 123, j = 124and j = 125respectively. Now if\\nx(18)\\ni =7 for some examplexi, then we set featurex(124)\\ni to 1;i f x(18)\\ni = 13,t h e nw es e t\\nfeature x(125)\\ni to 1, and so on.\\nIn some cases, a carefully designed binning can help the learning algorithm to learn using\\nfewer examples. It happens because we give a “hint” to the learning algorithm that if the\\nvalue of a feature falls within a speciﬁc range, the exact value of the feature doesn’t matter.\\n1When the ordering of values of some categorical variable matters, we can replace those values by numbers\\nby keeping only one variable. For example, if our variable represents the quality of an article, and the\\nvalues are{poor, decent, good, excellent},t h e nw ec o u l dr e p l a c et h o s ec a t e g o r i e sb yn u m b e r s ,f o re x a m p l e ,\\n{1, 2, 3, 4}.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 55, 'page_label': '56'}, page_content='5.1.3 Normalization\\nNormalization is the process of converting an actual range of values which a numerical\\nfeature can take, into a standard range of values, typically in the interval[≠1, 1] or [0, 1].\\nFor example, suppose the natural range of a particular feature is350 to 1450. By subtracting\\n350 from every value of the feature, and dividing the result by1100, one can normalize those\\nvalues into the range[0, 1].\\nMore generally, the normalization formula looks like this:\\n¯x(j) = x(j) ≠ min(j)\\nmax(j) ≠ min(j) ,\\nwhere min(j) and max(j) are, respectively, the minimum and the maximum value of the\\nfeature j in the dataset.\\nWhy do we normalize? Normalizing the data is not a strict requirement. However, in practice,\\nit can lead to an increased speed of learning. Remember the gradient descent example from\\nthe previous chapter. Imagine you have a two-dimensional feature vector. When you update\\nthe parameters ofw(1) and w(2), you use partial derivatives of the average squared error with\\nrespect to w(1) and w(2).I f x(1) is in the range[0, 1000] and x(2) the range[0, 0.0001],t h e n\\nthe derivative with respect to a larger feature will dominate the update.\\nAdditionally, it’s useful to ensure that our inputs are roughly in the same relatively small\\nrange to avoid problems which computers have when working with very small or very big\\nnumbers (known as numerical overﬂow).\\n5.1.4 Standardization\\nStandardization (or z-score normalization) is the procedure during which the feature\\nvalues are rescaled so that they have the properties of astandard normal distributionwith\\nµ =0 and ‡ =1 ,w h e r eµ is the mean (the average value of the feature, averaged over all\\nexamples in the dataset) and‡ is the standard deviation from the mean.\\nStandard scores (or z-scores) of features are calculated as follows:\\nˆx(j) = x(j) ≠ µ(j)\\n‡(j) .\\nYou may ask when you should use normalization and when standardization. There’s no\\ndeﬁnitive answer to this question. Usually, if your dataset is not too big and you have time,\\nyou can try both and see which one performs better for your task.\\nIf you don’t have time to run multiple experiments, as a rule of thumb:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 56, 'page_label': '57'}, page_content='• unsupervised learning algorithms, in practice, more often beneﬁt from standardization\\nthan from normalization;\\n• standardization is also preferred for a feature if the values this feature takes are\\ndistributed close to a normal distribution (so-called bell curve);\\n• again, standardization is preferred for a feature if it can sometimes have extremely high\\nor low values (outliers); this is because normalization will “squeeze” the normal values\\ninto a very small range;\\n• in all other cases, normalization is preferable.\\nModern implementations of the learning algorithms, which you can ﬁnd in popular libraries,\\nare robust to features lying in di\\x00erent ranges. Feature rescaling is usually beneﬁcial to most\\nlearning algorithms, but in many cases, the model will still be good when trained from the\\noriginal features.\\n5.1.5 Dealing with Missing Features\\nIn some cases, the data comes to the analyst in the form of a dataset with features already\\ndeﬁned. In some examples, values of some features can be missing. That often happens when\\nthe dataset was handcrafted, and the person working on it forgot to ﬁll some values or didn’t\\nget them measured at all.\\nThe typical approaches of dealing with missing values for a feature include:\\n• Removing the examples with missing features from the dataset. That can be done if\\nyour dataset is big enough so you can sacriﬁce some training examples.\\n• Using a learning algorithm that can deal with missing feature values (depends on the\\nlibrary and a speciﬁc implementation of the algorithm).\\n• Using a data imputation technique.\\n5.1.6 Data Imputation Techniques\\nOne technique consists in replacing the missing value of a feature by an average value of this\\nfeature in the dataset:\\nˆx(j) = 1\\nN x(j).\\nAnother technique is to replace the missing value by the same value outside the normal range\\nof values. For example, if the normal range is[0, 1], then you can set the missing value equal\\nto 2 or ≠1. The idea is that the learning algorithm will learn what is it better to do when the\\nfeature has a value signiﬁcantly di\\x00erent from other values. Alternatively, you can replace the\\nmissing value by a value in the middle of the range. For example, if the range for a feature is\\n[≠1, 1], you can set the missing value to be equal to0. Here, the idea is that if we use the\\nvalue in the middle of the range to replace missing features, such value will not signiﬁcantly\\na\\x00ect the prediction.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 57, 'page_label': '58'}, page_content='A more advanced technique is to use the missing value as the target variable for a regression\\nproblem. You can use all remaining features[x(1)\\ni ,x (2)\\ni ,...,x (j≠1)\\ni ,x (j+1)\\ni ,...,x (D)\\ni ] to form\\na feature vectorˆxi,s e tˆyi = x(j),w h e r ej is the feature with a missing value. Now we can\\nbuild a regression model to predictˆy from the feature vectorsˆx. Of course, to build training\\nexamples (ˆx, ˆy), you only use those examples from the original dataset, in which the value of\\nfeature j is present.\\nFinally, if you have a signiﬁcantly large dataset and just a few features with missing values,\\nyou can increase the dimensionality of your feature vectors by adding a binary indicator\\nfeature for each feature with missing values. Let’s say featurej = 12in yourD-dimensional\\ndataset has missing values. For each feature vectorx, you then add the featurej = D +1\\nwhich is equal to1 if the value of feature12 is present inx and 0 otherwise. The missing\\nfeature value then can be replaced by0 or any number of your choice.\\nAt prediction time, if your example is not complete, you should use the same data imputation\\ntechnique to ﬁll the missing features as the technique you used to complete the training data.\\nBefore you start working on the learning problem, you cannot tell which data imputation\\ntechnique will work the best. Try several techniques, build several models and select the one\\nthat works the best.\\n5.2 Learning Algorithm Selection\\nChoosing a machine learning algorithm can be a di\\x00cult task. If you have much time, you\\ncan try all of them. However, usually the time you have to solve a problem is limited. You\\ncan ask yourself several questions before starting to work on the problem. Depending on\\nyour answers, you can shortlist some algorithms and try them on your data.\\n• Explainability\\nDoes your model have to be explainable to a non-technical audience? Most very accurate\\nlearning algorithms are so-called “black boxes. ” They learn models that make very few errors,\\nbut why a model made a speciﬁc prediction could be very hard to understand and even\\nharder to explain. Examples of such models are neural networks or ensemble models.\\nOn the other hand, kNN, linear regression, or decision tree learning algorithms produce\\nmodels that are not always the most accurate, however, the way they make their prediction\\nis very straightforward.\\n• In-memory vs. out-of-memory\\nCan your dataset be fully loaded into the RAM of your server or personal computer? If\\nyes, then you can choose from a wide variety of algorithms. Otherwise, you would prefer\\nincremental learning algorithms that can improve the model by adding more data\\ngradually.\\n• Number of features and examples\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 58, 'page_label': '59'}, page_content='How many training examples do you have in your dataset? How many features does each\\nexample have? Some algorithms, includingneural networksand gradient boosting(we\\nconsider both later), can handle a huge number of examples and millions of features. Others,\\nlike SVM, can be very modest in their capacity.\\n• Categorical vs. numerical features\\nIs your data composed of categorical only, or numerical only features, or a mix of both?\\nDepending on your answer, some algorithms cannot handle your dataset directly, and you\\nwould need to convert your categorical features into numerical ones by using some techniques\\nlike one-hot encoding.\\n• Nonlinearity of the data\\nIs your data linearly separable or can it be modeled using a linear model? If yes, SVM with\\nthe linear kernel, logistic regression or linear regression can be a good choice. Otherwise,\\ndeep neural networks or ensemble algorithms, discussed in Chapters 6 and 7, might work\\nbetter for your data.\\n• Training speed\\nHow much time is a learning algorithm allowed to use to build a model? Neural networks\\nare known to be slow to train. Simple algorithms like logistic and linear regression as well\\nas decision tree learning are much faster. Some specialized libraries contain very e\\x00cient\\nimplementations of some algorithms; you may prefer to do research online to ﬁnd such\\nlibraries. Some algorithms, such as random forests, beneﬁt from the availability of multiple\\nCPU cores, so their model building time can be signiﬁcantly reduced on a machine with\\ndozens of CPU cores.\\n• Prediction speed\\nHow fast does the model have to be when generating predictions? Will your model be used in\\nproduction where very high throughput is required? Some algorithms, like SVMs, linear and\\nlogistic regression, or some types of neural networks, are extremely fast at the prediction time.\\nSome others, like kNN, ensemble algorithms, and very deep or recurrent neural networks,\\ncan be slower2.\\nIf you don’t want to guess the best algorithm for your data, a popular way to choose one is\\nby testing it on thevalidation set. We talk about that below.\\nAlternatively, if you use scikit-learn, you could try their algorithm selection diagram shown\\nin ﬁg. 1.\\n2The prediction speeds of kNN and ensemble methods implemented in the modern libraries are still very\\nfast. Don’t be afraid of using these algorithms in your practice.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 59, 'page_label': '60'}, page_content='Figure 1: Machine learning algorithm selection diagram for scikit-learn.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 60, 'page_label': '61'}, page_content='5.3 Three Sets\\nUntil now, I used the expressions “dataset” and “training set” interchangeably. However, in\\npractice data analysts work with three sets of labeled examples:\\n1) training set,\\n2) validation set, and\\n3) test set.\\nOnce you have got your annotated dataset, the ﬁrst thing you do is you shu\\x00e the examples\\nand split the dataset into three subsets: training, validation, and test. The training set is\\nusually the biggest one, and you use it to build the model. The validation and test sets are\\nroughly the same sizes, much smaller than the size of the training set. The learning algorithm\\ncannot use examples from these two subsets to build a model. That is why those two sets are\\noften calledhold-out sets.\\nThere’s no optimal proportion to split the dataset into these three subsets. In the past, the\\nrule of thumb was to use 70% of the dataset for training, 15% for validation and 15% for\\ntesting. However, in the age of big data, datasets often have millions of examples. In such\\ncases, it could be reasonable to keep 95% for training and 2.5%/2.5% for validation/testing.\\nYou may wonder, what is the reason to have three sets and not one. The answer is simple:\\nwhen we build a model, what we do not want is for the model to only do well at predicting\\nlabels of examples the learning algorithms has already seen. A trivial algorithm that simply\\nmemorizes all training examples and then uses the memory to “predict” their labels will make\\nno mistakes when asked to predict the labels of the training examples, but such an algorithm\\nwould be useless in practice. What we really want is that our model predicts well examples\\nthat the learning algorithm didn’t see. So we want good performance on a hold-out set.\\nWhy do we need two hold-out sets and not one? We use the validation set to 1) choose the\\nlearning algorithm and 2) ﬁnd the best values of hyperparameters. We use the test set to\\nassess the model before delivering it to the client or putting it in production.\\n5.4 Underﬁtting and Overﬁtting\\nI mentioned above the notion ofbias. I said that a model has a low bias if it predicts well\\nthe labels of the training data. If the model makes many mistakes on the training data,\\nwe say that the model has ahigh bias or that the modelunderﬁts. So, underﬁtting is the\\ninability of the model to predict well the labels of the data it was trained on. There could be\\nseveral reasons for underﬁtting, the most important of which are:\\n• your model is too simple for the data (for example a linear model can often underﬁt);\\n• the features you engineered are not informative enough.\\nThe ﬁrst reason is easy to illustrate in the case of one-dimensional regression: the dataset can\\nresemble a curved line, but our model is a straight line. The second reason can be illustrated\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 61, 'page_label': '62'}, page_content='Underﬁtting\\n Good ﬁt\\n Overﬁtting\\nFigure 2: Examples of underﬁtting (linear model), good ﬁt (quadratic model), and overﬁtting\\n(polynomial of degree 15).\\nlike this: let’s say you want to predict whether a patient has cancer, and the features you\\nhave are height, blood pressure, and heart rate. These three features are clearly not good\\npredictors for cancer so our model will not be able to learn a meaningful relationship between\\nthese features and the label.\\nThe solution to the problem of underﬁtting is to try a more complex model or to engineer\\nfeatures with higher predictive power.\\nOverﬁtting is another problem a model can exhibit. The model that overﬁts predicts very\\nwell the training data but poorly the data from at least one of the two hold-out sets. I already\\ngave an illustration of overﬁtting in Chapter 3. Several reasons can lead to overﬁtting, the\\nmost important of which are:\\n• your model is too complex for the data (for example a very tall decision tree or a very\\ndeep or wide neural network often overﬁt);\\n• you have too many features but a small number of training examples.\\nIn the literature, you can ﬁnd another name for the problem of overﬁtting: the problem of\\nhigh variance. This term comes from statistics. The variance is an error of the model due to\\nits sensitivity to small ﬂuctuations in the training set. It means that if your training data\\nwas sampled di\\x00erently, the learning would result in a signiﬁcantly di\\x00erent model. Which\\nis why the model that overﬁts performs poorly on the test data: test and training data are\\nsampled from the dataset independently of one another.\\nSeveral solutions to the problem of overﬁtting are possible:\\n1. Try a simpler model (linear instead of polynomial regression, or SVM with a linear\\nkernel instead of RBF, a neural network with fewer layers/units).\\n2. Reduce the dimensionality of examples in the dataset (for example, by using one of the\\ndimensionality reduction techniques discussed in Chapter 9).\\n3. Add more training data, if possible.\\n4. Regularize the model.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 62, 'page_label': '63'}, page_content='Figure 2 illustrates a one-dimensional dataset for which a regression model underﬁts, ﬁts well\\nand overﬁts the data.\\nRegularization is the most widely used approach to prevent overﬁtting.\\n5.5 Regularization\\nEven the simplest model, such as linear, can overﬁt the data. That usually happens when the\\ndata is high-dimensional, but the number of training examples is relatively low. In fact, when\\nfeature vectors are very high-dimensional, the linear learning algorithm can build a model\\nthat assigns non-zero values to most dimensionsw(j) in the parameter vectorw,t r y i n gt o\\nﬁnd very complex relationships between all available features to predict labels of training\\nexamples perfectly.\\nSuch a complex model will most likely predict poorly the labels of the hold-out examples.\\nThis is because by trying to perfectly predict labels of all training examples, the model will\\nalso learn the idiosyncrasies of the training set: the noise in the values of features of the\\ntraining examples, the sampling imperfection due to the small dataset size, and other artifacts\\nextrinsic to the decision problem in hand but present in the training set.\\nRegularization is an umbrella-term that encompasses methods that force the learning\\nalgorithm to build a less complex model. In practice, that often leads to slightly higher\\nbias but signiﬁcantly reduces the variance. This problem is known in the literature as the\\nbias-variance tradeo\\x00.\\nThe two most widely used types of regularization are calledL1 regularization and L2\\nregularization. The idea is quite simple. To create a regularized model, we modify the\\nobjective function by adding a penalizing term whose value is higher when the model is more\\ncomplex.\\nFor simplicity, I illustrate regularization using the example of linear regression. The same\\nprinciple can be applied to a wide variety of models.\\nRecall the linear regression objective we want to minimize:\\nmin\\nw,b\\n1\\nN\\nNÿ\\ni=1\\n(fw,b(xi) ≠ yi)2. (2)\\nAn L1-regularized objective looks like this:\\nmin\\nw,b\\nC|w| + 1\\nN\\nNÿ\\ni=1\\n(fw,b(xi) ≠ yi)2, (3)\\nwhere |w|\\ndef\\n= qD\\nj=1 |w(j)| and C is a hyperparameter that controls the importance of regular-\\nization. If we setC to zero, the model becomes a standard non-regularized linear regression\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 12'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 63, 'page_label': '64'}, page_content='model. On the other hand, if we set toC to a high value, the learning algorithm will try to\\nset mostw(j) to a very small value or zero to minimize the objective, the model will become\\nvery simple which can lead to underﬁtting. Your role as the data analyst is to ﬁnd such\\na value of the hyperparameterC that doesn’t increase the bias too much but reduces the\\noverﬁtting to a level reasonable for the problem in hand. In the next section, I will show how\\nto do that.\\nAn L2-regularized objective will look like this:\\nmin\\nw,b\\nCÎwÎ2 + 1\\nN\\nNÿ\\ni=1\\n(fw,b(xi) ≠ yi)2, where ÎwÎ2 def\\n=\\nDÿ\\nj=1\\n(w(j))2. (4)\\nIn practice, L1 regularization produces asparse model, a model that has most of its\\nparameters (in case of linear models, most ofw(j)) equal to zero (provided the hyperparameter\\nC is large enough). So L1 makesfeature selectionby deciding which features are essential\\nfor prediction and which are not. That can be useful in case you want to increase model\\nexplainability. However, if your only goal is to maximize the performance of the model on\\nthe hold-out data, then L2 usually gives better results. L2 also has the advantage of being\\ndi\\x00erentiable, so gradient descent can be used for optimizing the objective function.\\nL1 and L2 regularization methods are also combined in what is calledelastic net regular-\\nization with L1 and L2 regularizations being special cases. You can ﬁnd in the literature\\nthe nameridge regularization for L2 andlasso for L1.\\nIn addition to being widely used with linear models, L1 and L2 regularization are also\\nfrequently used with neural networks and many other types of models, which directly\\nminimize an objective function.\\nNeural networks also beneﬁt from two other regularization techniques:dropout and batch-\\nnormalization. There are also non-mathematical methods that have a regularization e\\x00ect:\\ndata augmentationand early stopping. We talk about these techniques in Chapter 8.\\n5.6 Model Performance Assessment\\nOnce you have a model which our learning algorithm has built using the training set, how\\ncan you say how good the model is? You use the test set to assess the model.\\nThe test set contains the examples that the learning algorithm has never seen before, so if\\nour model performs well on predicting the labels of the examples from the test set, we say\\nthat our modelgeneralizes well or, simply, that it’s good.\\nTo be more rigorous, machine learning specialists use various formal metrics and tools to\\nassess the model performance. For regression, the assessment of the model is quite simple. A\\nwell-ﬁtting regression model results in predicted values close to the observed data values. The\\nmean model, which always predicts the average of the labels in the training data, generally\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 13'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 64, 'page_label': '65'}, page_content='would be used if there were no informative features. The ﬁt of a regression model being\\nassessed should, therefore, be better than the ﬁt of the mean model. If this is the case, then\\nthe next step is to compare the performances of the model on the training and the test data.\\nTo do that, we compute the mean squared error3 (MSE) for the training, and, separately,\\nfor the test data. If the MSE of the model on the test data issubstantially higher than\\nthe MSE obtained on the training data, this is a sign of overﬁtting. Regularization or a\\nbetter hyperparameter tuning could solve the problem. The meaning of “substantially higher”\\ndepends on the problem in hand and has to be decided by the data analyst jointly with the\\ndecision maker/product owner who ordered the model.\\nFor classiﬁcation, things are a little bit more complicated. The most widely used metrics and\\ntools to assess the classiﬁcation model are:\\n• confusion matrix,\\n• accuracy,\\n• cost-sensitive accuracy,\\n• precision/recall, and\\n• area under the ROC curve.\\nTo simplify the illustration, I use a binary classiﬁcation problem. Where necessary, I show\\nhow to extend the approach to the multiclass case.\\n5.6.1 Confusion Matrix\\nThe confusion matrixis a table that summarizes how successful the classiﬁcation model\\nis at predicting examples belonging to various classes. One axis of the confusion matrix\\nis the label that the model predicted, and the other axis is the actual label. In a binary\\nclassiﬁcation problem, there are two classes. Let’s say, the model predicts two classes: “spam”\\nand “not_spam”:\\nspam (predicted) not spam (predicted)\\nspam (actual) 23 (TP) 1 (FN)\\nnot spam (actual) 12 (FP) 556 (TN)\\nThe above confusion matrix shows that of the 24 examples that actually were spam, the\\nmodel correctly classiﬁed23 as spam. In this case, we say that we have23 true positives\\nor TP =23. The model incorrectly classiﬁed1 example as not spam. In this case, we have1\\nfalse negative, or FN =1. Similarly, of568 examples that actually were not spam,556 were\\ncorrectly classiﬁed (556 true negativesor TN =556), and12 were incorrectly classiﬁed (12\\nfalse positives,F P= 12).\\nThe confusion matrix for multiclass classiﬁcation has as many rows and columns as there are\\n3Or any other type of loss function you used to build your optimization problem.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 14'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 65, 'page_label': '66'}, page_content='di\\x00erent classes. It can help you to determine mistake patterns. For example, a confusion\\nmatrix could reveal that a model trained to recognize di\\x00erent species of animals tends to\\nmistakenly predict “cat” instead of “panther,” or “mouse” instead of “rat. ” In this case, you\\ncan decide to add more labeled examples of these species to help the learning algorithm to\\n“see” the di\\x00erence between them. Alternatively, you can decide to add additional features\\nthe learning algorithm can use to build a model that would better distinguish between these\\nspecies.\\nConfusion matrices can be used to calculate two important performance metrics:precision\\nand recall.\\n5.6.2 Precision/Recall\\nThe two most frequently used metrics to assess the model areprecision and recall. Precision\\nis the ratio of correct positive predictions to the overall number of positive predictions:\\nPrecision = TP\\nTP + FP.\\nRecall is the ratio of correct positive predictions to the overall number of positive examples\\nin the test set:\\nRecall = TP\\nTP + FN.\\nTo understand the meaning and importance of precision and recall for the model assessment it\\nis often useful to think about the prediction problem as the problem of research of documents\\nin the database using a query. The precision is the proportion of relevant documents in the\\nlist of all returned documents. The recall is the ratio of the relevant documents returned\\nby the search engine to the total number of the relevant documents that could have been\\nreturned.\\nIn the case of the spam detection problem, we want to have high precision (we want to avoid\\nmaking mistakes by detecting that a legitimate message is spam) and we are ready to tolerate\\nlower recall (we tolerate some spam messages in our inbox).\\nAlmost always, in practice, we have to choose between a high precision or a high recall. It’s\\nusually impossible to have both. We can achieve either of the two by various means:\\n• by assigning a higher weighting to messages with spam (the SVM algorithm accepts\\nweightings of classes as input);\\n• by tuning hyperparameters such that the precision or recall on the validation set are\\nmaximized;\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 15'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 66, 'page_label': '67'}, page_content='• by varying the decision threshold for algorithms that return probabilities of classes;\\nfor instance, if we use logistic regression or decision tree, to increase precision (at the\\ncost of a lower recall), we can decide that the prediction will be positive only if the\\nprobability returned by the model is higher than0.9.\\nEven if precision and recall are deﬁned for the binary classiﬁcation case, you can always use\\nit to assess a multiclass classiﬁcation model. To do that, ﬁrst select a class for which you\\nwant to assess these metrics. Then you consider all examples of the selected class as positives\\nand all examples of the remaining classes as negatives.\\n5.6.3 Accuracy\\nAccuracy is given by the number of correctly classiﬁed examples divided by the total number\\nof classiﬁed examples. In terms of the confusion matrix, it is given by:\\nAccuracy = TP + TN\\nTP + TN + FP + FN. (5)\\nAccuracy is a useful metric when errors in predicting all classes are equally important. In\\ncase of the spam/not spam, this may not be the case. For example, you would tolerate false\\npositives less than false negatives. A false positive in spam detection is the situation in which\\nyour friend sends you an email, but the model labels it as spam and doesn’t show you. On\\nthe other hand, the false negative is less of a problem: if your model doesn’t detect a small\\npercentage of spam messages, it’s not a big deal.\\n5.6.4 Cost-Sensitive Accuracy\\nFor dealing with the situation in which di\\x00erent classes have di\\x00erent importance, a useful\\nmetric iscost-sensitive accuracy. To compute a cost-sensitive accuracy, you ﬁrst assign a\\ncost (a positive number) to both types of mistakes: FP and FN. You then compute the counts\\nTP, TN, FP, FN as usual and multiply the counts for FP and FN by the corresponding cost\\nbefore calculating the accuracy using eq. 5.\\n5.6.5 Area under the ROC Curve (AUC)\\nThe ROC curve (ROC stands for “receiver operating characteristic,” the term comes from\\nradar engineering) is a commonly used method to assess the performance of classiﬁcation\\nmodels. ROC curves use a combination the true positive rate (the proportion of positive\\nexamples predicted correctly, deﬁned exactly asrecall) and false positive rate (the proportion\\nof negative examples predicted incorrectly) to build up a summary picture of the classiﬁcation\\nperformance.\\nThe true positive rate and the false positive rate are respectively deﬁned as,\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 16'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 67, 'page_label': '68'}, page_content='TPR = TP\\n(TP + FN) and FPR = FP\\n(FP + TN).\\nROC curves can only be used to assess classiﬁers that return some conﬁdence score (or a\\nprobability) of prediction. For example, logistic regression, neural networks, and decision\\ntrees (and ensemble models based on decision trees) can be assessed using ROC curves.\\nTo draw a ROC curve, we ﬁrst discretize the range of the conﬁdence score. If this range for\\nour model is[0, 1], then we can discretize it like this:[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1].\\nThen, we use each discrete value as the prediction threshold and predict the labels of examples\\nin our dataset using our model and this threshold. For example, if we want to compute TPR\\nand FPR for the threshold equal to0.7, we apply the model to each example, get the score,\\nand, if the score if higher than or equal to0.7, we predict the positive class; otherwise, we\\npredict the negative class.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 17'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 68, 'page_label': '69'}, page_content='0 1\\n1\\nAUC\\xa0=\\xa00.4\\nFalse\\xa0positive\\xa0rate\\nTrue\\xa0positive\\xa0rate\\n0 1\\n1\\nAUC\\xa0=\\xa00.5\\nFalse\\xa0positive\\xa0rate\\nTrue\\xa0positive\\xa0rate\\n0 1\\n1\\nAUC\\xa0=\\xa00.6\\nFalse\\xa0positive\\xa0rate\\nTrue\\xa0positive\\xa0rate\\n0 1\\n1\\nAUC\\xa0=\\xa00.85\\nFalse\\xa0positive\\xa0rate\\nTrue\\xa0positive\\xa0rate\\nFigure 3: Area under the ROC curve.\\nLook at the illustration in Figure 3. It’s easy to see that if the threshold is0, all our\\npredictions will be positive, so both TPR and FPR will be1 (the upper right corner). On\\nthe other hand, if the threshold is1, then no positive prediction will be made, both TPR\\nand FPR will be0 which corresponds to the lower left corner.\\nThe higher thearea under the ROC curve(AUC), the better the classiﬁer. A classiﬁer\\nwith an AUC higher than0.5 is better than a random classiﬁer. If AUC is lower than0.5,\\nthen something is wrong with your model. A perfect classiﬁer would have an AUC of1.\\nUsually, if our model behaves well, we obtain a good classiﬁer by selecting the value of the\\nthreshold that gives TPR close to1 while keeping FPR near0.\\nROC curves are widely used because they are relatively simple to understand, they capture\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 18'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 69, 'page_label': '70'}, page_content='more than one aspect of the classiﬁcation (by taking both false positives and false negatives\\ninto account) and allow visually and with low e\\x00ort comparing the performance of di\\x00erent\\nmodels.\\n5.7 Hyperparameter Tuning\\nWhen I presented learning algorithms, I mentioned that you as a data analyst have to select\\ngood values for the algorithm’s hyperparameters, such as‘ and d for ID3,C for SVM, or–\\nfor gradient descent. But what does that exactly mean? Which value is the best and how to\\nﬁnd it? In this section, I answer these essential questions.\\nAs you already know, hyperparameters aren’t optimized by the learning algorithm itself. The\\ndata analyst has to “tune” hyperparameters by experimentally ﬁnding the best combination\\nof values, one per hyperparameter.\\nOne typical way to do that, when you have enough data to have a decent validation set (in\\nwhich each class is represented by at least a couple of dozen examples) and the number of\\nhyperparameters and their range is not too large is to usegrid search.\\nGrid search is the most simple hyperparameter tuning strategy. Let’s say you train an SVM\\nand you have two hyperparameters to tune: the penalty parameterC (a positive real number)\\nand the kernel (either “linear” or “rbf”).\\nIf it’s the ﬁrst time you are working with this dataset, you don’t know what is the possible\\nrange of values forC. The most common trick is to use a logarithmic scale. For example, for\\nC you can try the following values: [0.001, 0.01, 0.1, 1.0, 10, 100, 1000]. In this case you have\\n14 combinations of hyperparameters to try: [(0.001, “linear”), (0.01, “linear”), (0.1, “linear”),\\n(1.0, “linear”), (10, “linear”), (100, “linear”), (1000, “linear”), (0.001, “rbf”), (0.01, “rbf”),\\n(0.1, “rbf”), (1.0, “rbf”), (10, “rbf”), (100, “rbf”), (1000, “rbf”)].\\nYou use the training set and train 14 models, one for each combination of hyperparameters.\\nThen you assess the performance of each model on the validation data using one of the\\nmetrics we discussed in the previous section (or some other metric that matters to you).\\nFinally, you keep the model that performs the best according to the metric.\\nOnce you have found the best pair of hyperparameters, you can try to explore the values\\nclose to the best ones in some region around them. Sometimes, this can result in an even\\nbetter model.\\nFinally, you assess the selected model using the test set.\\nAs you could notice, trying all combinations of hyperparameters, especially if there are\\nmore than a couple of them, could be time-consuming, especially for large datasets. There\\nare more e\\x00cient techniques, such asrandom search and Bayesian hyperparameter\\noptimization.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 19'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 70, 'page_label': '71'}, page_content='Random search di\\x00ers from grid search in that you no longer provide a discrete set of\\nvalues to explore for each hyperparameter; instead, you provide a statistical distribution for\\neach hyperparameter from which values are randomly sampled and set the total number of\\ncombinations you want to try.\\nBayesian techniques di\\x00er from random or grid search in that they use past evaluation results\\nto choose the next values to evaluate. The idea is to limit expensive optimization of the\\nobjective function by choosing the next hyperparameter values based on those that have done\\nwell in the past.\\nThere are alsogradient-based techniques, evolutionary optimiza-\\ntion techniques, and other algorithmic hyperparameter tuning tech-\\nniques. Most modern machine learning libraries implement one or more\\nsuch techniques. There are also hyperparameter tuning libraries that can\\nhelp you to tune hyperparameters of virtually any learning algorithm,\\nincluding ones you programmed yourself.\\n5.7.1 Cross-Validation\\nWhen you don’t have a decent validation set to tune your hyperparameters on, the common\\ntechnique that can help you is calledcross-validation. When you have few training examples,\\nit could be prohibitive to have both validation and test set. You would prefer to use more\\ndata to train the model. In such a case, you only split your data into a training and a test\\nset. Then you use cross-validation to on the training set to simulate a validation set.\\nCross-validation works like follows. First, you ﬁx the values of the hyperparameters you want\\nto evaluate. Then you split your training set into several subsets of the same size. Each\\nsubset is called afold. Typically, ﬁve-fold cross-validation is used in practice. With ﬁve-fold\\ncross-validation, you randomly split your training data into ﬁve folds:{F1,F 2,...,F 5}. Each\\nFk, k =1 ,..., 5 contains 20% of your training data. Then you train ﬁve models as follows.\\nTo train the ﬁrst model,f1, you use all examples from foldsF2, F3, F4, andF5 as the training\\nset and the examples fromF1 as the validation set. To train the second model,f2, you\\nuse the examples from foldsF1, F 3, F4, andF5 to train and the examples fromF2 as the\\nvalidation set. You continue building models iteratively like this and compute the value of\\nthe metric of interest on each validation set, fromF1 to F5. Then you average the ﬁve values\\nof the metric to get the ﬁnal value.\\nYou can use grid search with cross-validation to ﬁnd the best values of hyperparameters for\\nyour model. Once you have found these values, you use the entire training set to build the\\nmodel with these best values of hyperparameters you have found via cross-validation. Finally,\\nyou assess the model using the test set.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 20'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 71, 'page_label': '72'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 72, 'page_label': '73'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 73, 'page_label': '74'}, page_content='6 Neural Networks and Deep Learning\\nFirst of all, you already know what a neural network is, and you already know how to build\\nsuch a model. Yes, it’s logistic regression! As a matter of fact, the logistic regression model,\\nor rather its generalization for multiclass classiﬁcation, called the softmax regression model,\\nis a standard unit in a neural network.\\n6.1 Neural Networks\\nIf you understood linear regression, logistic regression, and gradient descent, understanding\\nneural networks would not be a problem.\\nA neural network (NN), just like a regression or an SVM model, is a mathematical function:\\ny = fNN (x).\\nThe functionfNN has a particular form: it’s anested function. You have probably already\\nheard of neural networklayers. So, for a 3-layer neural network that returns a scalar,fNN\\nlooks like this:\\ny = fNN (x)= f3(f2(f1(x))).\\nIn the above equation,f2, f3 are vector functions of the following form:\\nfl(z)\\ndef\\n= gl(Wlz + bl), (1)\\nwhere l is called the layer index and can span from1 to any number of layers. The function\\ngl is called anactivation function. It is a ﬁxed, usually nonlinear function chosen by the\\ndata analyst before the learning is started. The parametersWl (a matrix) andbl (a vector)\\nfor each layer are learned using the familiar gradient descent by optimizing, depending on the\\ntask, a particular cost function (such as MSE). Compare eq. 1 with the equation for logistic\\nregression, where you replacegl by the sigmoid function, and you will not see any di\\x00erence.\\nThe functionf1 is a scalar function for the regression task, but can also be a vector function\\ndepending on your problem.\\nYou may probably wonder why a matrixWl is used and not a vectorwl. The reason is\\nthat gl is a vector function. Each rowwl,u (u for unit) of the matrixWl is a vector of\\nthe same dimensionality asz. Let al,u = wl,uz + bl,u. The output of fl(z) is a vector\\n[gl(al,1),g l(al,2),...,g l(al,sizel )],w h e r egl is some scalar function1, andsizel is the number of\\nunits in layerl. To make it more concrete, let’s consider one architecture of neural networks\\ncalled multilayer perceptronand often referred to as avanilla neural network.\\n1As c a l a rf u n c t i o no u t p u t sas c a l a r ,t h a ti sas i m p l en u m b e ra n dn o tav e c t o r .\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 74, 'page_label': '75'}, page_content='6.1.1 Multilayer Perceptron Example\\nWe have a closer look at one particular conﬁguration of neural networks calledfeed-forward\\nneural networks (FFNN), and more speciﬁcally the architecture called amultilayer\\nperceptron (MLP). As an illustration, we consider an MLP with three layers. Our network\\ntakes a two-dimensional feature vector as input and outputs a number. This FFNN can be a\\nregression or a classiﬁcation model, depending on the activation function used in the third,\\noutput layer.\\nOur MLP is depicted in ﬁg. 1. The neural network is represented graphically as a connected\\ncombination ofunits logically organized into one or morelayers. Each unit is represented by\\neither a circle or a rectangle. The inbound arrow represents an input of a unit and indicates\\nwhere this input came from. The outbound arrow indicates the output of a unit.\\nThe output of each unit is the result of the mathematical operation written inside the circle\\nor a rectangle. Circle units don’t do anything with the input; they just send their input\\ndirectly to the output.\\nThe following happens in each rectangle unit. Firstly, all inputs of the unit are joined together\\nto form an input vector. Then the unit applies a linear transformation to the input vector,\\nexactly like linear regression model does with its input feature vector. Finally, the unit\\napplies an activation functiong to the result of the linear transformation and obtains the\\noutput value, a real number. In a vanilla FFNN, the output value of a unit of some layer\\nbecomes an input value of each of the units of the subsequent layer.\\nIn ﬁg. 1, the activation functiongl has one index:l, the index of the layer the unit belongs to.\\nUsually, all units of a layer use the same activation function, but it’s not strictly necessary.\\nEach layer can have a di\\x00erent number of units. Each unit has its own parameterswl,u\\nand bl,u,w h e r eu is the index of the unit, andl is the index of the layer. The vectoryl≠1\\nin each unit is deﬁned as[y(1)\\nl≠1,y (2)\\nl≠1,y (3)\\nl≠1,y (4)\\nl≠1]. The vectorx in the ﬁrst layer is deﬁned as\\n[x(1),...,x (D)].\\nAs you can see in ﬁg. 1, in multilayer perceptron all outputs of one layer are connected to\\neach input of the succeeding layer. This architecture is calledfully-connected. A neural\\nnetwork can containfully-connected layers. Those are the layers whose units receive as\\ninputs the outputs of each of the units of the previous layer.\\n6.1.2 Feed-Forward Neural Network Architecture\\nIf we want to solve a regression or a classiﬁcation problem discussed in previous chapters, the\\nlast (the rightmost) layer of a neural network usually contains only one unit. If the activation\\nfunction glast of the last unit is linear, then the neural network is a regression model. If the\\nglast is a logistic function, the neural network is a binary classiﬁcation model.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 75, 'page_label': '76'}, page_content='x(1)\\nx(2)\\ny1(1)\\xa0←\\xa0g1(w1,1x\\xa0+\\xa0b1,1)\\nx(1)\\nx(2)\\ny1(2)\\xa0←\\xa0g1(w1,2x\\xa0+\\xa0b1,2)\\ny1(3)\\xa0←\\xa0g1(w1,3x\\xa0+\\xa0b1,3)\\ny1(4)\\xa0←\\xa0g1(w1,4x\\xa0+\\xa0b1,4)\\ny2(1)\\xa0←\\xa0g2(w2,1y1\\xa0+\\xa0b2,1)\\ny2(2)\\xa0←\\xa0g2(w2,2y1\\xa0+\\xa0b2,2)\\ny2(3)\\xa0←\\xa0g2(w2,3y1\\xa0+\\xa0b2,3)\\ny2(4)\\xa0←\\xa0g2(w2,4y1\\xa0+\\xa0b2,4)\\ny\\xa0←\\xa0g3(w3,1y2\\xa0+\\xa0b3,1) y\\nlayer\\xa03\\xa0(f3)\\xa0layer\\xa02\\xa0(f2)\\xa0layer\\xa01\\xa0(f1)\\xa0\\ny1(1)\\ny1(4)\\ny2(4)\\ny2(3)\\ny2(2)\\ny2(1)\\nFigure 1: A multilayer perceptron with two-dimensional input, two layers with four units and one output layer with one\\nunit.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 76, 'page_label': '77'}, page_content='The data analyst is free to choose any mathematical function asgl,u, assuming it’s di\\x00eren-\\ntiable2. The latter property is essential for gradient descent, which is used to ﬁnd the values\\nof the parameterswl,u and bl,u for all l and u. The primary purpose of having nonlinear\\ncomponents in the functionfNN is to allow the neural network to approximate nonlinear\\nfunctions. Without nonlinearities,fNN would be linear, no matter how many layers it has.\\nThe reason is thatWlz + bl is a linear function and a linear function of a linear function is\\nalso a linear function.\\nPopular choices of activation functions are the logistic function, already known to you, as well\\nas TanH and ReLU. The former is the hyperbolic tangent function, similar to the logistic\\nfunction but ranging from≠1 to 1 (without reaching them). The latter is the rectiﬁed linear\\nunit function, which equals to zero when its inputz is negative and toz otherwise:\\ntanh(z)= ez ≠ e≠z\\nez + e≠z ,\\nrelu(z)=\\nI\\n0 if z< 0\\nz otherwise .\\nAs I said above,Wl in the expressionWlz + bl, is a matrix, whilebl is a vector. That looks\\ndi\\x00erent from linear regression’swz+ b. In matrixWl, each rowu corresponds to a vector of\\nparameters wl,u. The dimensionality of the vectorwl,u equals to the number of units in the\\nlayer l ≠ 1. The operation Wlz results in a vectoral\\ndef\\n= [wl,1z, wl,2z,..., wl,sizel z].T h e n\\nthe sumal + bl gives asizel-dimensional vectorcl. Finally, the functiongl(cl) produces the\\nvector yl\\ndef\\n=[ y(1)\\nl ,y (2)\\nl ,...,y (sizel)\\nl ] as output.\\n6.2 Deep Learning\\nDeep learning refers to training neural networks with more than two non-output layers. In the\\npast, it became more di\\x00cult to train such networks as the number of layers grew. The two\\nbiggest challenges were referred to as the problems ofexploding gradientand vanishing\\ngradient as gradient descent was used to train the network parameters.\\nWhile the problem of exploding gradient was easier to deal with by applying simple techniques\\nlike gradient clipping and L1 or L2 regularization, the problem of vanishing gradient\\nremained intractable for decades.\\nWhat is vanishing gradient and why does it arise? To update the values of parameters in\\nneural networks the algorithm calledbackpropagation is typically used. Backpropagation\\nis an e\\x00cient algorithm for computing gradients on neural networks using the chain rule. In\\nChapter 4, we have already seen how the chain rule is used to calculate partial derivatives of\\n2The function has to be di\\x00erentiable across its whole domain or in the majority of the points of its\\ndomain. For example, ReLU is not di\\x00erentiable at0.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 77, 'page_label': '78'}, page_content='a complex function. During gradient descent, the neural network’s parameters receive an\\nupdate proportional to the partial derivative of the cost function with respect to the current\\nparameter in each iteration of training. The problem is that in some cases, the gradient will\\nbe vanishingly small, e\\x00ectively preventing some parameters from changing their value. In\\nthe worst case, this may completely stop the neural network from further training.\\nTraditional activation functions, such as the hyperbolic tangent function I mentioned above,\\nhave gradients in the range(0, 1), and backpropagation computes gradients by the chain rule.\\nThat has the e\\x00ect of multiplyingn of these small numbers to compute gradients of the earlier\\n(leftmost) layers in ann-layer network, meaning that the gradient decreases exponentially\\nwith n. That results in the e\\x00ect that the earlier layers train very slowly, if at all.\\nHowever, the modern implementations of neural network learning algorithms allow you to\\ne\\x00ectively train very deep neural networks (up to hundreds of layers). The ReLU activation\\nfunction su\\x00ers much less from the problem of vanishing gradient. Also,long short-term\\nmemory (LSTM) networks, which we consider below, as well as such techniques asskip\\nconnections used in residual neural networksallow you to train even deeper neural\\nnetworks, with thousands of layers.\\nTherefore, today, since the problems of vanishing and exploding gradient are mostly solved\\n(or their e\\x00ect diminished) to a great extent, the term “deep learning” refers to training\\nneural networks using the modern algorithmic and mathematical toolkit independently of\\nhow deep the neural network is. In practice, many business problems can be solved with\\nneural networks having 2-3 layers between the input and output layers. The layers that are\\nneither input nor output are often calledhidden layers.\\n6.2.1 Convolutional Neural Network\\nYou may have noticed that the number of parameters an MLP can have grows very fast as you\\nmake your network bigger. More speciﬁcally, as you add one layer, you addsizel(sizel≠1 + 1)\\nparameters (our matrixWl plus the vectorbl). That means that if you add another 1000-unit\\nlayer to an existing neural network, then you add more than 1 million additional parameters\\nto your model. Optimizing such big models is a very computationally intensive problem.\\nWhen our training examples are images, the input is very high-dimensional. If you want\\nto learn to classify images using an MLP, the optimization problem is likely to become\\nintractable.\\nA convolutional neural network(CNN) is a special kind of FFNN that signiﬁcantly\\nreduces the number of parameters in a deep neural network with many units without losing\\ntoo much in the quality of the model. CNNs have found applications in image and text\\nprocessing where they beat many previously established benchmarks.\\nBecause CNNs were invented with image processing in mind, I explain them on the image\\nclassiﬁcation example.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 78, 'page_label': '79'}, page_content='You may have noticed that in images, pixels that are close to one another usually represent\\nthe same type of information: sky, water, leaves, fur, bricks, and so on. The exception from\\nthe rule are the edges: the parts of an image where two di\\x00erent objects “touch” one another.\\nSo, if we can train the neural network to recognize regions of the same information as well\\nas the edges, then this knowledge would allow the neural network to predict the object\\nrepresented in the image. For example, if the neural network detected multiple skin regions\\nand edges that look like parts of an oval with skin-like tone on the inside and bluish tone on\\nthe outside, then it is very likely that there’s a face on the sky background. If our goal is to\\ndetect people on pictures, the neural network will most likely succeed in predicting a person\\nin this picture.\\nHaving in mind that the most important information in the image is local, we can split the\\nimage into square patches using a moving window approach3. We can then train multiple\\nsmaller regression models at once, each small regression model receiving a square patch as\\ninput. The goal of each small regression model is to learn to detect a speciﬁc kind of pattern\\nin the input patch. For example, one small regression model will learn to detect the sky;\\nanother one will detect the grass, the third one will detect edges of a building, and so on.\\nIn CNNs, a small regression model looks like the one in ﬁg. 1, but it only has the layer1 and\\ndoesn’t have layers2 and 3. To detect some pattern, a small regression model has to learn\\nthe parameters of a matrixF (for “ﬁlter”) of sizep ◊ p,w h e r ep is the size of a patch. Let’s\\nassume, for simplicity, that the input image is back and white, with1 representing black and\\n0 representing white pixels. Assume also that our patches are3 by 3 pixels (p =3 ). Some\\npatch could then look like the following matrixP (for “patch”):\\nP =\\nS\\nU\\n010\\n111\\n010\\nT\\nV.\\nThe above patch represents a pattern that looks like a cross. The small regression model that\\nwill detect such patterns (and only them) would need to learn a3 by 3 parameter matrixF\\nwhere parameters at positions corresponding to the1s in the input patch would be positive\\nnumbers, while the parameters in positions corresponding to0s would be close to zero. If\\nwe calculate the dot-product between matricesP and F and then sum all values from the\\nresulting vector, the value we obtain is higher the more similarF is to P . For instance,\\nassume thatF looks like this:\\nF =\\nS\\nU\\n023\\n241\\n030\\nT\\nV.\\nThen,\\nP · F =[ 0· 0+2 · 1+0 · 0, 2 · 1+4 · 1+3 · 1, 3 · 0+1 · 1+0 · 1] = [2, 9, 1].\\n3Consider this as if you looked at a dollar bill in a microscope. To see the whole bill you have to gradually\\nmove your bill from left to right and from top to bottom. At each moment in time, you see only a part of the\\nbill of ﬁxed dimensions. This approach is calledmoving window.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 79, 'page_label': '80'}, page_content='Then the sum of all elements of the above vector is2 + 9 + 1 = 12. This operation — the dot\\nproduct between a patch and a ﬁlter and then summing the values — is calledconvolution.\\nIf our input patchP had a di\\x00erent patten, for example, that of a letter T,\\nP =\\nS\\nU\\n111\\n010\\n010\\nT\\nV,\\nthen the convolution would give a lower result:0+9+0=9 . So, you can see the more\\nthe patch “looks” like the ﬁlter, the higher the value of the convolution operation is. For\\nconvenience, there’s also a bias parameterb associated with each ﬁlterF which is added to\\nthe result of a convolution before applying the nonlinearity.\\nOne layer of a CNN consists of multiple convolution ﬁlters (each with its own bias parameter),\\njust like one layer in a vanilla FFNN consists of multiple units. Each ﬁlter of the ﬁrst\\n(leftmost) layer slides — orconvolves — across the input image, left to right, top to bottom,\\nand convolution is computed at each iteration.\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n-1 2 \\n4 -2 \\nImage Filter \\n4 \\nOutput\\xa0before\\xa0nonlinearity \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n-1 2 \\n4 -2 4 -1 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n-1 2 \\n4 -2 4 -1 7 \\nConv\\xa01\\nConv\\xa02\\nConv\\xa03\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n-1 2 \\n4 -2 4 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n-1 2 \\n4 -2 4 -1 \\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n1\\n0 \\n0 \\n0 \\n0 0 \\n0 \\n0 0 \\n-1 2 \\n4 -2 4 -1 7 \\n-1 7 \\n7 \\n2 Conv\\xa04\\n2 7 \\n2 7 0 \\nConv\\xa05\\nConv\\xa06\\n1\\nBias\\n1\\n1\\n1\\n1\\n1\\nFigure 2: A ﬁlter convolving across an image.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 80, 'page_label': '81'}, page_content='An illustration of the process is given in ﬁg. 2 where 6 steps of a ﬁlter convolving across an\\nimage are shown.\\nThe numbers in the ﬁlter matrix, for each ﬁlterF in each layer, as well as the value of\\nthe bias termb, are found by the gradient descent with backpropagation, based on data by\\nminimizing the cost function.\\nA nonlinearity is applied to the sum of the convolution and the bias term. Typically, the\\nReLU activation function is used in all hidden layers. The activation function of the output\\nlayer depends on the task.\\nSince we can havesizel ﬁlters in each layerl, the output of the convolution layerl would\\nconsist ofsizel matrices, one for each ﬁlter.\\nIf the CNN has one convolution layer following another convolution layer, then the subsequent\\nlayer l +1 treats the output of the preceding layerl as a collection ofsizel image matrices.\\nSuch a collection is called avolume. Each ﬁlter of layerl +1 convolves the whole volume. The\\nconvolution of a patch of a volume is simply the sum of convolutions of the corresponding\\npatches of individual matrices the volume consists of.\\n3\\n4\\n2\\n-2\\n2\\n0\\n4\\n2\\n1 \\n5 \\n0 \\n-1 1 \\n1 \\n-2 1 \\n-2 3 \\n5 -1 \\nFilter \\n-3 \\nOutput\\xa0before\\xa0nonlinearity 2\\n-3\\n-1\\n0\\n2\\n0\\n-2\\n-5\\n-3 \\n1 \\n2 \\n2 1 \\n1 \\n3 -1 1\\n2\\n1\\n-3\\n0\\n-1\\n2\\n-2\\n4 \\n0 \\n3 \\n1 1 \\n-1 \\n1 -1 \\n-2\\nBias\\nVolume\\nFigure 3: Convolution of a volume consisting of three matrices.\\nAn example of a convolution of a patch of a volume consisting of three matrices is shown in\\nﬁg. 3. The value of the convolution,≠3, was obtained as(≠2 · 3+3 · 1+5 · 4+ ≠1 · 1) +\\n(≠2 · 2+3 · (≠1) + 5· (≠3) +≠1 · 1) + (≠2 · 1+3 · (≠1) + 5· 2+ ≠1 · (≠1)) + (≠2).\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 81, 'page_label': '82'}, page_content='In computer vision, CNNs often get volumes as input, since an image is usually represented\\nby three channels: R, G, and B, each channel being a monochrome picture.\\nBy now, you should have a good high-level understanding of the CNN\\narchitecture. We didn’t discuss some essential features of CNNs though,\\nsuch as strides, padding, and pooling. Strides and padding are two\\nimportant hyperparameters of the convolution ﬁlter and the sliding\\nwindow, while pooling is a technique that works very well in practice\\nby reducing the number of parameters of a CNN even more.\\n6.2.2 Recurrent Neural Network\\nRecurrent neural networks(RNNs) are used to label, classify, or generate sequences. A\\nsequence is a matrix, each row of which is a feature vector and the order of rows matters.\\nLabeling a sequence means predicting a class to each feature vector in a sequence. Classifying\\na sequence means predicting a class for the entire sequence. Generating a sequence means\\nto output another sequence (of a possibly di\\x00erent length) somehow relevant to the input\\nsequence.\\nRNNs are often used in text processing because sentences and texts are naturally sequences\\nof either words/punctuation marks or sequences of characters. For the same reason, recurrent\\nneural networks are also used in speech processing.\\nA recurrent neural network is not feed-forward, because it contains loops. The idea is that\\neach unitu of recurrent layerl has a real-valuedstate hl,u. The state can be seen as the\\nmemory of the unit. In RNN, each unitu in each recurrent layerl receives two inputs: a\\nvector of outputs from the previous layerl ≠1 and the vector of states from this same layerl\\nfrom the previous time step.\\nTo illustrate the idea, let’s consider the ﬁrst and the second recurrent layers of an RNN. The\\nﬁrst (leftmost) layer receives a feature vector as input. The second layer receives the output\\nof the ﬁrst layer as input.\\nThis situation is schematically depicted in ﬁg. 4. As I said above, each training example is\\na matrix in which each row is a feature vector. For simplicity, let’s illustrate this matrix\\nas a sequence of vectorsX =[ x1, x2,..., xt≠1, xt, xt+1,..., xlengthX],w h e r elengthX is the\\nlength of the input sequence. If our input exampleX is a text sentence, then feature vector\\nxt for eacht =1 ,...,l e n g t hX represents a word in the sentence at positiont.\\nAs depicted in ﬁg. 4, in an RNN, the input example is “read” by the neural network one\\nfeature vector at a timestep. The indext denotes a timestep. To update the stateht\\nl,u at each\\ntimestep t in each unitu of each layerl we ﬁrst calculate a linear combination of the input\\nfeature vector with the state vectorht≠1\\nl,u of this same layer from the previous timestep,t ≠1.\\nThe linear combination of two vectors is calculated using two parameter vectorswl,u, ul,u\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 82, 'page_label': '83'}, page_content='xt\\xa0←\\xa0[x(1),t,x(2),t]x(2),t\\nht\\xad11,1\\nht\\xad1l,2\\nht1,1\\nht1,1\\xa0←\\xa0g1(w1,1xt\\xa0+\\xa0u1,1ht\\xad11\\xa0+\\xa0b1,1)\\nyt1\\xa0←\\xa0g2(V1ht1\\xa0+\\xa0c1)\\nx(1),t\\nx(2),t\\nht\\xad11,1\\nht\\xad11,2\\nht1,2\\nht1,2\\xa0←\\xa0g1(w1,2xt\\xa0+\\xa0u1,2ht\\xad11\\xa0+\\xa0b1,2)\\nx(1),t\\nxt\\xa0←\\xa0[x(1),t,x(2),t]\\nlayer\\xa01\\nht1\\xa0←\\xa0[ht1,1,ht1,2]\\nht\\xad12,1\\nht\\xad12,2\\nht2,1\\nht2,1\\xa0←\\xa0g1(w2,1h1t\\xa0+\\xa0u2,1ht\\xad12\\xa0+\\xa0b2,1)\\nht\\xad12,1\\nht\\xad12,2\\nht2,2\\nlayer\\xa02\\nht1\\xa0←\\xa0[ht1,1,ht1,2] yt2\\xa0←\\xa0g2(V2ht2\\xa0+\\xa0c2)ht2\\xa0←[ht2,1,ht2,2]\\nyt1 yt2\\nht1\\xa0←\\xa0[ht1,1,ht1,2]\\nht2,1\\xa0←\\xa0g1(w2,2ht1\\xa0+\\xa0u2,2ht\\xad12\\xa0+\\xa0b2,2)\\nFigure 4: The ﬁrst two layers of an RNN. The input feature vector is two-dimensional; each layer has two units.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 12'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 83, 'page_label': '84'}, page_content='and a parameterbl,u. The value ofht\\nl,u is then obtained by applying an activation function\\ng1 to the result of the linear combination. A typical choice for functiong1 is tanh.T h e\\noutput yt\\nl is typically a vector calculated for the whole layerl at once. To obtainyt\\nl,w eu s e\\nan activation functiong2 that takes a vector as input and returns a di\\x00erent vector of the\\nsame dimensionality. The functiong2 is applied to a linear combination of the state vector\\nvalues ht\\nl,u calculated using a parameter matrixVl and a parameter vectorcl,u. A typical\\nchoice forg2 is thesoftmax function:\\n‡(z)\\ndef\\n=[ ‡(1),...,‡ (D)], where ‡(j) def\\n= exp\\n!\\nz(j)\"\\nqD\\nk=1 exp\\n!\\nz(k)\".\\nThe softmax function is a generalization of the sigmoid function to multidimensional data. It\\nhas the property thatqD\\nj=1 ‡(j) =1 and ‡(j) > 0 for allj.\\nThe dimensionality ofVl is chosen by the data analyst such that multiplication of matrixVl\\nby the vectorht\\nl results in a vector of the same dimensionality as that of the vectorcl.T h i s\\nchoice depends on the dimensionality for the output labely in your training data. (Until\\nnow we only saw one-dimensional labels, but we will see in the future chapters that labels\\ncan be multidimensional as well.)\\nThe values ofwl,u, ul,u, bl,u, Vl,u, andcl,u are computed from the training data using gradient\\ndescent with backpropagation. To train RNN models, a special version of backpropagation is\\nused calledbackpropagation through time.\\nBoth tanh and softmax su\\x00er from the vanishing gradient problem. Even if our RNN has just\\none or two recurrent layers, because of the sequential nature of the input, backpropagation\\nhas to “unfold” the network over time. From the point of view of the gradient calculation, in\\npractice this means that the longer is the input sequence, the deeper is the unfolded network.\\nAnother problem RNNs have is that of handling long-term dependencies. As the length of\\nthe input sequence grows, the feature vectors from the beginning of the sequence tend to\\nbe “forgotten,” because the state of each unit, which serves as network’s memory, becomes\\nsigniﬁcantly a\\x00ected by the feature vectors read more recently. Therefore, in text or speech\\nprocessing, the cause-e\\x00ect link between distant words in a long sentence can be lost.\\nThe most e\\x00ective recurrent neural network models used in practice aregated RNNs.T h e s e\\ninclude thelong short-term memory(LSTM) networks and networks based on thegated\\nrecurrent unit(GRU).\\nThe beauty of using gated units in RNNs is that such networks can store information in their\\nunits for future use, much like bits in a computer’s memory. The di\\x00erence with the real\\nmemory is that reading, writing, and erasure of information stored in each unit is controlled\\nby activation functions that take values in the range(0, 1). The trained neural network can\\n“read” the input sequence of feature vectors and decide at some early time stept to keep\\nspeciﬁc information about the feature vectors. That information about the earlier feature\\nvectors can later be used by the model to process the feature vectors from near the end of\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 13'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 84, 'page_label': '85'}, page_content='the input sequence. For example, if the input text starts with the wordshe, a language\\nprocessing RNN model could decide to store the information about the gender to interpret\\ncorrectly the wordher seen later in the sentence.\\nUnits make decisions about what information to store, and when to allow reads, writes, and\\nerasures. These decisions are learned from data and implemented through the concept of\\ngates. There are several architectures of gated units. The simplest one (working well in\\npractice) is called theminimal gated GRUand is composed of a memory cell, and a forget\\ngate.\\nLet’s look at the math of a GRU unit on an example of the ﬁrst layer of the RNN (the one\\nthat takes the sequence of feature vectors as input). A minimal gated GRU unitu in layer\\nl takes two inputs: the vector of the memory cell values from all units in the same layer\\nfrom the previous timestep,ht≠1\\nl , and a feature vectorxt. It then uses these two vectors like\\nfollows (all operations in the below sequence are executed in the unit one after another):\\n˜ht\\nl,u Ω g1(wl,uxt + ul,uht≠1\\nl + bl,u),\\n\\x00t\\nl,u Ω g2(ml,uxt + ol,uht≠1 + al,u),\\nht\\nl,u Ω \\x00t\\nl,u˜ht\\nl +( 1≠ \\x00t\\nl,u)ht≠1\\nl ,\\nht\\nl Ω [ht\\nl,1,...,h t\\nl,sizel ]\\nyt\\nl Ω g3(Vlht\\nl + cl,u),\\nwhere g1 is the tanh activation function,g2 is called the gate function and is implemented as\\nthe sigmoid function. The sigmoid function takes values in the range of(0, 1). If the gate\\n\\x00l,u is close to0, then the memory cell keeps its value from the previous time step,ht≠1\\nl .O n\\nthe other hand, if the gate\\x00l,u is close to1, the value of the memory cell is overwritten by a\\nnew value˜ht\\nl,u (this happens in the third assignment from the top). Just like in standard\\nRNNs, g3 is usually softmax.\\nA gated unit takes an input and stores it for some time. This is equivalent to applying the\\nidentity function (f(x)= x) to the input. Because the derivative of the identity function is\\nconstant, when a network with gated units is trained with backpropagation through time,\\nthe gradient does not vanish.\\nOther important extensions to RNNs includebi-directional RNNs,\\nRNNs with attention and sequence-to-sequence RNN models.\\nSequence-to-sequence RNNs, in particular, are frequently used to build\\nneural machine translation models and other models for text to text\\ntransformations. A generalization of RNNs is a recursive neural\\nnetwork model.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 14'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 85, 'page_label': '86'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 86, 'page_label': '87'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 87, 'page_label': '88'}, page_content='7 Problems and Solutions\\n7.1 Kernel Regression\\nWe talked about linear regression, but what if our data doesn’t have the form of a straight\\nline? Polynomial regression could help. Let’s say we have a one-dimensional data{(xi,y i)}N\\ni=1.\\nWe could try to ﬁt a quadratic liney = w1xi + w2x2\\ni + b to our data. By deﬁning the mean\\nsquared error cost function, we could apply gradient descent and ﬁnd the values of parameters\\nw1, w2, and b that minimize this cost function. In one- or two-dimensional space, we can\\neasily see whether the function ﬁts the data. However, if our input is aD-dimensional feature\\nvector, withD> 3, ﬁnding the right polynomial would be hard.\\nKernel regression is a non-parametric method. That means that there are no parameters to\\nlearn. The model is based on the data itself (like in kNN). In its simplest form, in kernel\\nregression we look for a model like this:\\nf(x)= 1\\nN\\nNÿ\\ni=1\\nwiyi, where wi = Nk(xi≠x\\nb )\\nqN\\nk=1 k(xk≠x\\nb )\\n. (1)\\nThe functionk(· ) is a kernel. It can have di\\x00erent forms, the most frequently used one is the\\nGaussian kernel:\\nk(z)= 1Ô\\n2ﬁ exp\\n3≠z2\\n2\\n4\\n.\\nGood ﬁt\\n Slight overﬁt\\n Strong overﬁt\\nFigure 1: Example of kernel regression line with a Gaussian kernel for three values ofb.\\nThe valueb is a hyperparameter that we tune using the validation set (by running the model\\nbuilt with a speciﬁc value ofb on the validation set examples and calculating the mean\\nsquared error). You can see an illustration of the inﬂuenceb has on the shape of the regression\\nline in ﬁg. 1.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 88, 'page_label': '89'}, page_content='If your inputs are multi-dimensional feature vectors, the termsxi ≠ x and xk ≠ x in eq. 1\\nhave to be replaced by Euclidean distanceÎxi ≠ xÎ and Îxk ≠ xÎ respectively.\\n7.2 Multiclass Classiﬁcation\\nIn multiclass classiﬁcation, the label can be one of theC classes: y œ{ 1,...,C }. Many\\nmachine learning algorithms are binary; SVM is an example. Some algorithms can naturally\\nbe extended to handle multiclass problems. ID3 and other decision tree learning algorithms\\ncan be simply changed like this:\\nfS\\nID3\\ndef\\n=P r (yi = c|x)= 1\\n|S|\\nÿ\\n{y | (x,y)œS,y=c}\\ny,\\nfor allc œ{ 1,...,C }.\\nLogistic regression can be naturally extended to multiclass learning problems by replacing\\nthe sigmoid function with thesoftmax functionwhich we already saw in Chapter 6.\\nThe kNN algorithm is also straightforward to extend to the multiclass case: when we ﬁnd\\nthe k closest examples for the inputx and examine them, we return the class that we saw\\nthe most among thek examples.\\nSVM cannot be naturally extended to multiclass problems. Some algorithms can be imple-\\nmented more e\\x00ciently in the binary case. What should you do if you have a multiclass\\nproblem but a binary classiﬁcation learning algorithm? One common strategy is calledone\\nversus rest. The idea is to transform a multiclass problem intoC binary classiﬁcation\\nproblems and buildC binary classiﬁers. For example, if we have three classes,y œ{ 1, 2, 3},\\nwe create copies of the original datasets and modify them. In the ﬁrst copy, we replace all\\nlabels not equal to1 by 0. In the second copy, we replace all labels not equal to2 by 0.I n t h e\\nthird copy, we replace all labels not equal to3 by 0. Now we have three binary classiﬁcation\\nproblems where we have to learn to distinguish between labels1 and 0, 2 and 0, and between\\nlabels 3 and 0.\\nOnce we have the three models and we need to classify the new input feature vectorx,\\nwe apply the three models to the input, and we get three predictions. We then pick the\\nprediction of a non-zero class which isthe most certain. Remember that in logistic regression,\\nthe model returns not a label but a score(0, 1) that can be interpreted as the probability\\nthat the label is positive. We can also interpret this score as the certainty of prediction. In\\nSVM, the analog of certainty is the distance from the inputx to the decision boundary. This\\ndistance is given by,\\nd = wúx + bú\\nÎwÎ .\\nThe larger the distance, the more certain is the prediction. Most learning algorithm either\\ncan be naturally converted to a multiclass case, or they return a score we can use in the one\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 89, 'page_label': '90'}, page_content='versus rest strategy.\\n7.3 One-Class Classiﬁcation\\nOne-class classiﬁcation, also known asunary classiﬁcation or class modeling,t r i e st o\\nidentify objects of a speciﬁc class among all objects, by learning from a training set containing\\nonly the objects of that class. That is di\\x00erent from and more di\\x00cult than the traditional\\nclassiﬁcation problem, which tries to distinguish between two or more classes with the\\ntraining set containing objects from all classes. A typical one-class classiﬁcation problem is\\nthe classiﬁcation of the tra\\x00c in a secure network as normal. In this scenario, there are few,\\nif any, examples of the tra\\x00c under an attack or during an intrusion. However, the examples\\nof normal tra\\x00c are often in abundance. One-class classiﬁcation learning algorithms are used\\nfor outlier detection, anomaly detection, and novelty detection.\\nThere are several one-class learning algorithms. The most widely used in practice are\\none-class Gaussian, one-class kmeans, one-class kNN, andone-class SVM.\\nThe idea behind the one-class gaussian is that we model our data as if it came from a Gaussian\\ndistribution, more preciselymultivariate normal distribution(MND). The probability density\\nfunction (pdf) for MND is given by the following equation:\\nfµ,\\x00(x)= exp\\n!\\n≠1\\n2 (x ≠ µ)T\\x00≠1(x ≠ µ)\\n\"\\n\\uf8ff\\n(2ﬁ)D|\\x00|\\n,\\nwhere fµ,\\x00(x) returns the probability density corresponding to the input feature vectorx.\\nProbability density can be interpreted as the likelihood that examplex was drawn from the\\nprobability distribution we model as an MND. Valuesµ (a vector) and\\x00 (a matrix) are\\nthe parameters we have to learn. Themaximum likelihood criterion (similarly to how\\nwe solved the logistic regression learning problem) is optimized to ﬁnd the optimal values\\nfor these two parameters.|\\x00| = det \\x00 is thedeterminant of the matrix\\x00; the notationaT\\nmeans thetranspose of the vectora, and\\x00≠1 is theinverse of the matrix\\x00.\\nIf the termsdeterminant, transpose, and inverse are new to you, don’t worry. These are\\nstandard operations on vector and matrices from the branch of mathematics calledmatrix\\ntheory. If you feel the need to know what they are, Wikipedia explains these concepts very\\nwell.\\nIn practice, the numbers in the vectorµ determine the place where the curve of our Gaussian\\ndistribution is centered, while the numbers in\\x00 determine the shape of the curve. For\\na training set consisting of two-dimensional feature vectors, an example of the one-class\\nGaussian model is given in ﬁg 2.\\nOnce we have our model parametrized byµ and \\x00 learned from the data, we predict the\\nlikelihood of every inputx by using fµ,\\x00(x). Only if the likelihood is above a certain\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 90, 'page_label': '91'}, page_content='Figure 2: One-class classiﬁcation solved using the one-class gaussian method. Left: two-\\ndimensional feature vectors. Right: the MND curve that maximizes the likelihood of the\\nexamples on the left.\\nthreshold, we predict that the example belongs to our class; otherwise, it is classiﬁed as the\\noutlier. The value of the threshold is found experimentally or using an “educated guess. ”\\nWhen the data has a more complex shape, a more advanced algorithm can use a combination\\nof several Gaussians (called a mixture of Gaussians). In this case, there are more parameters\\nto learn from data: oneµ and one\\x00 for each Gaussian as well as the parameters that allow\\ncombining multiple Gaussians to form one pdf. In Chapter 9, we consider a mixture of\\nGaussians with an application to clustering.\\nOne-class kmeans and one-class kNN are based on a similar principle as that of one-class\\nGaussian: build some model of the data and then deﬁne a threshold to decide whether our\\nnew feature vector looks similar to other examples according to the model. In the former,\\nall training examples are clustered using thekmeans clustering algorithm and, when a new\\nexample x is observed, the distanced(x) is calculated as the minimum distance betweenx\\nand the center of each cluster. Ifd(x) is less than a particular threshold, thenx belongs to\\nthe class.\\nOne-class SVM, depending on formulation, tries either 1) to separate all\\ntraining examples from the origin (in the feature space) and maximize\\nthe distance from the hyperplane to the origin, or 2) to obtain a spherical\\nboundary around the data by minimizing the volume of this hypersphere.\\nI leave the description of the one-class kNN algorithm, as well as the\\ndetails of the one-class kmeans and one-class SVM for the complementary\\nreading.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 91, 'page_label': '92'}, page_content='Figure 3: A picture labeled as “people”, “concert”, and “nature” .\\n7.4 Multi-Label Classiﬁcation\\nIn multi-label classiﬁcation, each training example doesn’t just have one label, but several\\nof them. For instance, if we want to describe an image, we could assign several labels to it:\\n“people,” “concert,” “nature,” all three at the same time (ﬁg. 3).\\nIf the number of possible values for labels is high, but they are all of the same nature, like\\ntags, we can transform each labeled example into several labeled examples, one per label.\\nThese new examples all have the same feature vector and only one label. That becomes a\\nmulticlass classiﬁcation problem. We can solve it using the one versus rest strategy. The\\nonly di\\x00erence with the usual multiclass problem is that now we have a new hyperparameter:\\nthreshold. If the prediction score for some label is above the threshold, this label is predicted\\nfor the input feature vector. In this scenario, multiple labels can be predicted for one feature\\nvector. The value of the threshold is chosen using the validation set.\\nAnalogously, algorithms that naturally can be made multiclass (decision trees, logistic\\nregression and neural networks among others) can be applied to multi-label classiﬁcation\\nproblems. Because they return the score for each class, we can deﬁne a threshold and then\\nassign multiple labels to one feature vector if the threshold is above some value chosen\\nexperimentally using the validation set.\\nNeural networks algorithms can naturally train multi-label classiﬁcation models by using the\\nbinary cross-entropycost function. The output layer of the neural network, in this case,\\nhas one unit per label. Each unit of the output layer has the sigmoid activation function.\\nAccordingly, each labell is binary (yi,l œ{ 0, 1}), wherel =1 ,...,L and i =1 ,...,N .T h e\\nbinary cross-entropy of predicting the probabilityˆyi,l that examplexi has label l is deﬁned\\nas ≠(yi,l ln(ˆyi,l)+( 1 ≠ yi,l) ln(1 ≠ ˆyi,l)). The minimization criterion is simply the average of\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 92, 'page_label': '93'}, page_content='all binary cross-entropy terms across all training examples and all labels of those examples.\\nIn cases where the number of possible values each label can take is small, one can convert\\nmultilabel into a multiclass problem using a di\\x00erent approach. Imagine the following problem.\\nWe want to label images and labels can be of two types. The ﬁrst type of label can have\\ntwo possible values:{photo, painting}; the label of the second type can have three possible\\nvalues {portrait, paysage, other}. We can create a new fake class for each combination of\\nthe two original classes, like this:\\nFake Class Real Class 1 Real Class 2\\n1 photo portrait\\n2 photo paysage\\n3 photo other\\n4 painting portrait\\n5 painting paysage\\n6 painting other\\nNow we have the same labeled examples, but we replace real multi-labels with one fake label\\nwith values from1 to 6. This approach works well in practice when there are not too many\\npossible combinations of classes. Otherwise, you need to use much more training data to\\ncompensate for an increased set of classes.\\nThe primary advantage of this latter approach is that you keep your labels correlated,\\ncontrary to the previously seen methods that predict each label independently of one another.\\nCorrelation between labels can be an essential property in many problems. For example, if\\nyou want to predict for an email message whether it’sspam or not_spam at the same time\\nas you predict whether it’sordinary or priority email. You would like to avoid predictions\\nlike [spam, priority].\\n7.5 Ensemble Learning\\nEnsemble learningis a learning paradigm that, instead of trying to learn one super-accurate\\nmodel, focuses on training a large number of low-accuracy models and then combining the\\npredictions given by those weak models to obtain a high-accuracymeta-model.\\nLow-accuracy models are usually learned byweak learners, that is learning algorithms that\\ncannot learn complex models, and thus are typically fast at the training and at the prediction\\ntime. The most frequently used weak learner is a decision tree learning algorithm in which\\nwe often stop splitting the training set after just a few iterations. The obtained trees are\\nshallow and not particularly accurate, but the idea behind ensemble learning is that if the\\ntrees are not identical and each tree is at least slightly better than random guessing, then we\\ncan obtain high accuracy by combining a large number of such trees.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 93, 'page_label': '94'}, page_content='To obtain the prediction for inputx, the predictions of each weak model are combined using\\nsome sort of weighted voting. The speciﬁc form of vote weighting depends on the algorithm,\\nbut, independently of the algorithm, the idea is the same: if the council of weak models\\npredicts that the message is spam, then we assign the labelspam to x.\\nTwo most widely used and e\\x00ective ensemble learning algorithms arerandom forestand\\ngradient boosting.\\n7.5.1 Random Forest\\nThere are two ensemble learning paradigms:bagging and boosting. Bagging consists of\\ncreating many “copies” of the training data (each copy is slightly di\\x00erent from another) and\\nthen apply the weak learner to each copy to obtain multiple weak models and then combine\\nthem. The bagging paradigm is behind therandom forestlearning algorithm.\\nThe “vanilla” bagging algorithm works like follows. Given a training set, we createB random\\nsamples Sb (for each b =1 ,...,B ) of the training set and build a decision tree modelfb\\nusing each sampleSb as the training set. To sampleSb for someb,w ed ot h esampling with\\nreplacement. This means that we start with an empty set, and then pick at random an\\nexample from the training set and put its exact copy toSb by keeping the original example\\nin the original training set. We keep picking examples at random until the|Sb| = N.\\nAfter training, we haveB decision trees. The prediction for a new examplex is obtained as\\nthe average ofB predictions:\\ny Ω ˆf(x)\\ndef\\n= 1\\nB\\nBÿ\\nb=1\\nfb(x),\\nin the case of regression, or by taking the majority vote in the case of classiﬁcation.\\nThe random forest algorithm is di\\x00erent from the vanilla bagging in just one way. It uses\\na modiﬁed tree learning algorithm that inspects, at each split in the learning process, a\\nrandom subset of the features. The reason for doing this is to avoid the correlation of the\\ntrees: if one or a few features are very strong predictors for the target, these features will\\nbe selected to split examples in many trees. This would result in many correlated trees in\\nour “forest. ” Correlated predictors cannot help in improving the accuracy of prediction. The\\nmain reason behind a better performance of model ensembling is that models that are good\\nwill likely agree on the same prediction, while bad models will likely disagree on di\\x00erent\\nones. Correlation will make bad models more likely to agree, which will hamper the majority\\nvote or the average.\\nThe most important hyperparameters to tune are the number of trees,B, and the size of the\\nrandom subset of the features to consider at each split.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 94, 'page_label': '95'}, page_content='Random forest is one of the most widely used ensemble learning algorithms. Why is it so\\ne\\x00ective? The reason is that by using multiple samples of the original dataset, we reduce\\nthe variance of the ﬁnal model. Remember that the low variance means lowoverﬁtting.\\nOverﬁtting happens when our model tries to explain small variations in the dataset because our\\ndataset is just a small sample of the population of all possible examples of the phenomenon we\\ntry to model. If we were unlucky with how our training set was sampled, then it could contain\\nsome undesirable (but unavoidable) artifacts: noise, outliers and over- or underrepresented\\nexamples. By creating multiple random samples with replacement of our training set, we\\nreduce the e\\x00ect of these artifacts.\\n7.5.2 Gradient Boosting\\nAnother e\\x00ective ensemble learning algorithm is gradient boosting. Let’s ﬁrst look at gradient\\nboosting for regression. To build a strong regressor, we start with a constant modelf = f0\\n(just like we did in ID3):\\nf = f0(x)\\ndef\\n= 1\\nN\\nNÿ\\ni=1\\nyi.\\nThen we modify labels of each examplei =1 ,...,N in our training set like follows:\\nˆyi Ω yi ≠ f(xi), (2)\\nwhere ˆyi, called theresidual, is the new label for examplexi.\\nNow we use the modiﬁed training set, with residuals instead of original labels, to build a new\\ndecision tree model,f1. The boosting model is now deﬁned asf\\ndef\\n= f0 + –f1,w h e r e– is the\\nlearning rate (a hyperparameter).\\nThen we recompute the residuals using eq. 2 and replace the labels in the training data once\\nagain, train the new decision tree modelf2, redeﬁne the boosting model asf\\ndef\\n= f0 +–f1 +–f2\\nand the process continues until the maximum ofM (another hyperparameter) trees are\\ncombined.\\nIntuitively, what’s happening here? By computing the residuals, we ﬁnd how well (or poorly)\\nthe target of each training example is predicted by the current modelf. We then train\\nanother tree to ﬁx the errors of the current model (this is why we use residuals instead if\\nreal labels) and add this new tree to the existing model with some weight–. Therefore, each\\nadditional tree added to the model partially ﬁxes the errors made by the previous trees until\\nthe maximum number of trees are combined.\\nNow you should reasonably ask why the algorithm is calledgradient boosting? In gradient\\nboosting, we don’t calculate any gradient contrary to what we did in Chapter 4 for linear\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 95, 'page_label': '96'}, page_content='regression. To see the similarity between gradient boosting and gradient descent remember\\nwhy we calculated the gradient in linear regression: we did that to get an idea on where we\\nshould move the values of our parameters so that the MSE cost function reaches its minimum.\\nThe gradient showed the direction, but we didn’t know how far we should go in this direction,\\nso we used a small step– at each iteration and then reevaluated our direction. The same\\nhappens in gradient boosting. However, instead of getting the gradient directly, we use its\\nproxy in the form of residuals: they show us how the model has to be adjusted so that the\\nerror (the residual) is reduced.\\nThe three principal hyperparameters to tune in gradient boosting are the number of trees,\\nthe learning rate, and the depth of trees — all three a\\x00ect model accuracy. The depth of\\ntrees also a\\x00ects the speed of training and prediction: the shorter, the faster.\\nIt can be shown that training on residuals optimizes the overall modelf for the mean squared\\nerror criterion. You can see the di\\x00erence with bagging here: boosting reduces the bias (or\\nunderﬁtting) instead of the variance. As such, boosting can overﬁt. However, by tuning the\\ndepth and the number of trees, overﬁtting can be largely avoided.\\nThe gradient boosting algorithm for classiﬁcation is similar, but the steps are slightly di\\x00erent.\\nLet’s consider the binary case. Assume we haveM regression decision trees. Similarly to\\nlogistic regression, the prediction of the ensemble of decision trees is modeled using the\\nsigmoid function:\\nPr(y =1 |x,f )\\ndef\\n= 1\\n1+ e≠f(x) ,\\nwhere f(x)= qM\\nm=1 fm(x) and fm is a regression tree.\\nAgain, like in logistic regression, we apply the maximum likelihood principle by trying to\\nﬁnd such anf that maximizes Lf = qN\\ni=1 ln(Pr(yi =1 |xi,f )). Again, to avoid numerical\\noverﬂow, we maximize the sum of log-likelihoods rather than the product of likelihoods.\\nThe algorithm starts with the initial constant modelf = f0 = p\\n1≠p ,w h e r ep = 1\\nN\\nqN\\ni=1 yi.\\n(It can be shown that such initialization is optimal for the sigmoid function.) Then at each\\niteration m,an e wt r e efm is added to the model. To ﬁnd the bestfm, ﬁrst the partial\\nderivative gi of the current model is calculated for eachi =1 ,...,N :\\ngi = dLf\\ndf ,\\nwhere f is the ensemble classiﬁer model built at the previous iterationm ≠ 1. To calculategi\\nwe need to ﬁnd the derivatives ofln(Pr(yi =1 |xi,f )) with respect tof for alli. Notice that\\nln(Pr(yi =1 |xi,f ))\\ndef\\n=l n( 1\\n1+e≠f(xi) ). The derivative of the right-hand term in the previous\\nequation with respect tof equals to 1\\nef(xi)+1 .\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 96, 'page_label': '97'}, page_content='We then transform our training set by replacing the original labelyi with the corresponding\\npartial derivativegi, and we build a new treefm using the transformed training set. Then\\nwe ﬁnd the optimal update stepﬂm as:\\nﬂm = arg max\\nﬂ\\nLf+ﬂfm.\\nAt the end of iterationm, we update the ensemble modelf by adding the new treefm:\\nf Ω f + –ﬂmfm.\\nWe iterate untilm = M, then we stop and return the ensemble modelf.\\nGradient boosting is one of the most powerful machines learning algorithms. Not just because\\nit creates very accurate models, but also because it is capable of handling huge datasets with\\nmillions of examples and features. It usually outperforms random forest in accuracy but,\\nbecause of its sequential nature, can be signiﬁcantly slower in training.\\n7.6 Learning to Label Sequences\\nA sequence is one the most frequently observed types of structured data. We communicate\\nusing sequences of words and sentences, we execute tasks in sequences, our genes, the music\\nwe listen and videos we watch, our observations of a continuous process, such as a moving\\ncar or the price of a stock are all sequential.\\nIn sequence labeling, a labeled sequential example is a pair of lists(X, Y),w h e r eX is a list\\nof feature vectors, one per time step,Y is a list of the same length of labels. For example,X\\ncould represent words in a sentence such as [“big”, “beautiful”, “car”], andY would be the\\nlist of the corresponding parts of speech, such as [“adjective”, “adjective”, “noun”]). More\\nformally, in an examplei, Xi =[ x1\\ni , x2\\ni ,..., xsizei\\ni ],w h e r esizei is the length of the sequence\\nof the examplei, Yi =[ y1\\ni ,y 2\\ni ,...,y sizei\\ni ] and yi œ{ 1, 2,...,C }.\\nYou have already seen that an RNN can be used to annotate a sequence. At each time stept,\\nit reads an input feature vectorx(t)\\ni , and the last recurrent layer outputs a labely(t)\\nlast (in the\\ncase of binary labeling) ory(t)\\nlast (in the case of multiclass or multilabel labeling).\\nHowever, RNN is not the only possible model for sequence labeling. The model called\\nConditional Random Fields(CRF) is a very e\\x00ective alternative that often performs well\\nin practice for the feature vectors that have many informative features. For example, imagine\\nwe have the task ofnamed entity extractionand we want to build a model that would\\nlabel each word in the sentence such as “I go to San Francisco” with one of the following\\nclasses: {location, name, company_name, other}. If our feature vectors (which represent\\nwords) contain such binary features as “whether or not the word starts with a capital letter”\\nand “whether or not the word can be found in the list of locations,” such features would\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 12'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 97, 'page_label': '98'}, page_content='be very informative and help to classify the wordsSan and Francisco as location.B u i l d i n g\\nhandcrafted features is known to be a labor-intensive process that requires a signiﬁcant level\\nof domain expertise.\\nCRF is an interesting model and can be seen as a generalization of\\nlogistic regression to sequences. However, in practice, it has been\\noutperformed by bidirectional deep gated RNN for sequence labeling\\ntasks. CRFs are also signiﬁcantly slower in training which makes them\\ndi\\x00cult to apply to large training sets (with hundreds of thousands of\\nexamples). Additionally, a large training set is where a deep neural\\nnetwork thrives.\\n7.7 Sequence-to-Sequence Learning\\nSequence-to-sequence learning(often abbreviated as seq2seq learning) is a generalization\\nof the sequence labeling problem. In seq2seq,Xi and Yi can have di\\x00erent length. seq2seq\\nmodels have found application in machine translation (where, for example, the input is\\nan English sentence, and the output is the corresponding French sentence), conversational\\ninterfaces (where the input is a question typed by the user, and the output is the answer\\nfrom the machine), text summarization, spelling correction, and many others.\\nMany but not most sequence-to-sequence learning problems are currently best solved by\\nneural networks. Machine translation is a notorious example. There are multiple neural\\nnetwork architectures for seq2seq which perform better than others depending on the task.\\nAll those network architectures have one property in common: they have two parts, an\\nencoder and adecoder (for this reason they are also known asencoder-decoder neural\\nnetworks).\\nIn seq2seq learning, the encoder is a neural network that accepts sequential input. It can\\nbe an RNN, but also a CNN or some other architecture. The role of the encoder is to read\\nthe input and generate some sort of state (similar to the state in RNN) that can be seen\\nas a numerical representation of themeaning of the input the machine can work with. The\\nmeaning of some entity, whether it be an image, a text or a video, is usually a vector or a\\nmatrix that contains real numbers. This vector (or matrix) is called in the machine learning\\njargon theembedding of the input.\\nThe decoder in seq2seq learning is another neural network that takes an embedding as input\\nand is capable of generating a sequence of outputs. As you could have already guessed, that\\nembedding comes from the encoder. To produce a sequence of outputs, the decoder takes a\\nstart of sequenceinput feature vectorx(0) (typically all zeroes), produces the ﬁrst output\\ny(1), updates its state by combining the embedding and the inputx(0), and then uses the\\noutput y(1) as its next inputx(1). For simplicity, the dimensionality ofy(t) can be the same\\nas that ofx(t); however, it is not strictly necessary. As we saw in Chapter 6, each layer of an\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 13'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 98, 'page_label': '99'}, page_content='RNN can produce many simultaneous outputs: one can be used to generate the labely(t),\\nwhile another one, of di\\x00erent dimensionality, can be used as thex(t).\\nEncoder Decoder\\nThe weatheris fine <\\xa0start\\xa0>\\nIl fait beau\\nt\\xa0= 1 2 3 4 1 2 3\\nFigure 4: A traditional seq2seq architecture.\\nBoth encoder and decoder are trained simultaneously using the training data. The errors at\\nthe decoder output are propagated to the encoder via backpropagation.\\nA traditional seq2seq architecture is illustrated in ﬁg. 4. More accurate predictions can be\\nobtained using an architecture withattention. Attention mechanism is implemented by an\\nadditional set of parameters that combine some information from the encoder (in RNNs,\\nthis information is the list of state vectors of the last recurrent layer from all encoder time\\nsteps) and the current state of the decoder to generate the label. That allows for even better\\nretention of long-term dependencies than provided by gated units and bidirectional RNN. A\\nseq2seq architecture with attention is illustrated in ﬁg. 5.\\nSequence-to-sequence learning is a relatively new research domain. Novel\\nnetwork architectures are regularly discovered and published. Training\\nsuch architectures can be challenging as the number of hyperparame-\\nters to tune and other architectural decisions can be overwhelming. I\\nrecommend consulting the book’s wiki for the state of the art material,\\ntutorials and code samples.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 14'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 99, 'page_label': '100'}, page_content='The weatheris fine <\\xa0start\\xa0>\\nIl fait beau\\nt\\xa0= 1 2 3 4 1 2 3\\nAttention\\nFigure 5: A seq2seq architecture with attention.\\n7.8 Active Learning\\nActive learningis an interesting supervised learning paradigm. It is usually applied when\\nobtaining labeled examples is costly. That is often the case in the medical or ﬁnancial\\ndomains, where the opinion of an expert may be required to annotate patients’ or customers’\\ndata. The idea is that we start the learning with relatively few labeled examples, and a large\\nnumber of unlabeled ones, and then add labels only to those examples that contribute the\\nmost to the model quality.\\nThere are multiple strategies of active learning. Here, we discuss only the following two:\\n1) data density and uncertainty based, and\\n2) support vector-based.\\nThe former strategy applies the current modelf, trained using the existing labeled examples,\\nto each of the remaining unlabelled examples (or, to save the computing time, to some\\nrandom sample of them). For each unlabeled examplex, the following importance score is\\ncomputed: density(x) · uncertaintyf (x). Density reﬂects how many examples surroundx in\\nits close neighborhood, whileuncertaintyf (x) reﬂects how uncertain the prediction of the\\nmodel f is forx. In binary classiﬁcation with sigmoid, the closer the prediction score is to\\n0.5, the more uncertain is the prediction. In SVM, the closer the example is to the decision\\nboundary, the most uncertain is the prediction.\\nIn multiclass classiﬁcation,entropy can be used as a typical measure of uncertainty:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 15'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 100, 'page_label': '101'}, page_content='Hf (x)= ≠\\nCÿ\\nc=1\\nPr(y(c); f(x)) ln Pr(y(c); f(x)),\\nwhere Pr(y(c); f(x)) is the probability score the modelf assigns to classy(c) when classifying\\nx. You can see that if for eachy(c), f(y(c))= 1\\nC then the model is the most uncertain and\\nthe entropy is at its maximum of1; on the other hand, if for somey(c), f(y(c))=1 ,t h e nt h e\\nmodel is certain about the classy(c) and the entropy is at its minimum of0.\\nDensity for the examplex can be obtained by taking the average of the distance fromx to\\neach of itsk nearest neighbors (withk being a hyperparameter).\\nOnce we know the importance score of each unlabeled example, we pick the one with the\\nhighest importance score and ask the expert to annotate it. Then we add the new annotated\\nexample to the training set, rebuild the model and continue the process until some stopping\\ncriterion is satisﬁed. A stopping criterion can be chosen in advance (the maximum number\\nof requests to the expert based on the available budget) or depend on how well our model\\nperforms according to some metric.\\nThe support vector-based active learning strategy consists in building an SVM model using\\nthe labeled data. We then ask our expert to annotate the unlabeled example that lies the\\nclosest to the hyperplane that separates the two classes. The idea is that if the example lies\\nclosest to the hyperplane, then it is the least certain and would contribute the most to the\\nreduction of possible places where the true (the one we look for) hyperplane could lie.\\nSome active learning strategies can incorporate the cost of asking an\\nexpert for a label. Otherslearn to ask expert’s opinion. The “query by\\ncommittee” strategy consists of training multiple models using di\\x00erent\\nmethods and then asking an expert to label example on which those\\nmodels disagree the most. Some strategies try to select examples to\\nlabel so that the variance or the bias of the model are reduced the most.\\n7.9 Semi-Supervised Learning\\nIn semi-supervised learning(SSL) we also have labeled a small fraction of the dataset;\\nmost of the remaining examples are unlabeled. Our goal is to leverage a large number of\\nunlabeled examples to improve the model performance without asking an expert for additional\\nlabeled examples.\\nHistorically, there were multiple attempts at solving this problem. None of them could be\\ncalled universally acclaimed and frequently used in practice. For example, one frequently\\ncited SSL method is called “self-learning. ” In self-learning, we use a learning algorithm to\\nbuild the initial model using the labeled examples. Then we apply the model to all unlabeled\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 16'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 101, 'page_label': '102'}, page_content='examples and label them using the model. If the conﬁdence score of prediction for some\\nunlabeled examplex is higher than some threshold (chosen experimentally), then we add this\\nlabeled example to our training set, retrain the model and continue like this until a stopping\\ncriterion is satisﬁed. We could stop, for example, if the accuracy of the model has not been\\nimproved during the lastm iterations.\\nThe above method can bring some improvement to the model compared to just using the\\ninitially labeled dataset, but the increase in performance usually is not very impressive.\\nFurthermore, in practice, the quality of the model could even decrease. That depends on the\\nproperties of the statistical distribution the data was drawn from, which we usually do not\\nknow.\\nOn the other hand, the recent advancements in neural network learning brought some\\nimpressive results. For example, it was shown that for some datasets, such as MNIST (a\\nfrequent testbench in computer vision that consists of labeled images of handwritten digits\\nfrom 0 to 9) the model trained in a semi-supervised way has an almost perfect performance\\nwith just 10 labeled examples per class (100 labeled examples overall). For comparison,\\nMNIST contains 70,000 labeled examples (60,000 for training and 10,000 for test). The\\nneural network architecture that attained such a remarkable performance is called aladder\\nnetwork. To understand ladder networks you have to understand what anautoencoder is.\\nAn autoencoder is a feed-forward neural network with an encoder-decoder architecture. It\\nis trained to reconstruct its input. So the training example is a pair(x, x). We want the\\noutput ˆx of the modelf(x) to be as similar to the inputx as possible.\\nEmbedding\\nx x̂ \\nEncoder Decoder\\nFigure 6: Autoencoder.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 17'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 102, 'page_label': '103'}, page_content='An important detail here is that an autoencoder’s network looks like an hourglass with a\\nbottleneck layerin the middle that contains the embedding of theD-dimensional input\\nvector; the embedding layer usually has much fewer units thanD. The goal of the decoder is\\nto reconstruct the input feature vector from this embedding. Theoretically, it is su\\x00cient\\nto have10 units in the bottleneck layer to successfully encode MNIST images. In a typical\\nautoencoder schematically depicted in ﬁg. 6, the cost function is usually either the mean\\nsquared error (when features can be any number) or the negative log-likelihood (when features\\nare binary and the units of the last layer of the decoder have the sigmoid activation function).\\nIf the cost is the mean squared error, then it is given by:\\n1\\nN\\nNÿ\\ni=1\\nÎxi ≠ f(xi)Î2,\\nwhere Îxi ≠ f(xi)Î is the Euclidean distance between two vectors.\\nA denoising autoencodercorrupts the left-hand sidex in the training example(x, x) by\\nadding some random perturbation to the features. If our examples are grayscale images with\\npixels represented as values between0 and 1, usually anormal Gaussian noiseis added to\\neach feature. For each featurej of the input feature vectorx the noise valuen(j) is sampled\\nfrom the following distribution:\\nn(j) ≥ 1\\n‡\\nÔ\\n2ﬁ exp\\n3\\n≠(≠µ)2\\n2‡2\\n4\\n,\\nwhere the notation ≥ means “sampled from,” ﬁ is the constant 3.14159 ... and µ is a\\nhyperparameter that has to be tuned. The new, corrupted value of the featurex(j) is given\\nby x(j) + n(j).\\nA ladder network is a denoising autoencoder with an upgrade. The encoder and the decoder\\nhave the same number of layers. The bottleneck layer is used directly to predict the label\\n(using the softmax activation function). The network has several cost functions. For each\\nlayer l of the encoder and the corresponding layerl of the decoder, one costCl\\nd penalizes\\nthe di\\x00erence between the outputs of the two layers (using the squared Euclidean distance).\\nWhen a labeled example is used during training, another cost function,Cc, penalizes the error\\nin prediction of the label (the negative log-likelihood cost function is used). The combined\\ncost function,Cc + qL\\nl=1 ⁄lCl\\nd (averaged over all examples in the batch), is optimized by the\\nstochastic gradient descent with backpropagation. The hyperparameters⁄l for each layerl\\ndetermine the tradeo\\x00 between the classiﬁcation and encoding-decoding cost.\\nIn the ladder network, not just the input is corrupted with the noise, but also the output of\\neach encoder layer (during training). When we apply the trained model to the new inputx\\nto predict its label, we do not corrupt the input.\\nOther semi-supervised learning techniques, not related to training neural networks, exist.\\nOne of them implies building the model using the labeled data and then cluster the unlabeled\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 18'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 103, 'page_label': '104'}, page_content='and labeled examples together using any clustering technique (we consider some of them in\\nChapter 9).\\nFor each new example, we then output as a prediction the majority label\\nin the cluster it belongs to. Another technique, called S3VM, is based\\non using SVM. We build one SVM model for each possible labeling of\\nunlabeled examples and then we pick the model with the largest margin.\\nThe paper on S3VM describes an approach that allows solving this\\nproblem without actually enumerating all possible labelings.\\n7.10 One-Shot Learning\\nThis chapter would be incomplete without mentioning two other important supervised learning\\nparadigms. One of them isone-shot learning. In one-shot learning, typically applied in\\nface recognition, we want to build a model that can recognize that two photos of the same\\nperson represent that same person. If we present to the model two photos of two di\\x00erent\\npeople, we expect the model to recognize that the two people are di\\x00erent.\\nOne way to build such a model is to train asiamese neural network(SNN). An SNN can\\nbe implemented as any kind of neural network, a CNN, an RNN, or an MLP. What matters\\nis how we train the network.\\nTo train an SNN, we use thetriplet lossfunction. For example, let us have three images of\\na face: the imageA (for anchor), the imageP (for positive) and the imageN (for negative).\\nA and P are two di\\x00erent pictures of the same person;N is a picture of another person.\\nEach training examplei is now a triplet(Ai,P i,N i).\\nLet’s say we have a neural network modelf that can take a picture of a face as input and\\noutput an embedding of this picture. The triplet loss for one example is deﬁned as,\\nmax(Îf(Ai) ≠ f(Pi)Î2 ≠Î f(Ai) ≠ f(Ni)Î2 + –, 0). (3)\\nThe cost function is deﬁned as the average triplet loss:\\n1\\nN\\nNÿ\\ni=1\\nmax(Îf(Ai) ≠ f(Pi)Î2 ≠Î f(Ai) ≠ f(Ni)Î2 + –, 0),\\nwhere – is a positive hyperparameter. Intuitively,Îf(A) ≠ f(P)Î2 is low when our neural\\nnetwork outputs similar embedding vectors forA and P; Îf(Ai) ≠ f(Ni)Î2 is high when the\\nembedding for pictures of two di\\x00erent people are di\\x00erent. If our model works the way\\nwe want, then the termm = Îf(Ai) ≠ f(Pi)Î2 ≠Î f(Ai) ≠ f(Ni)Î2 will always be negative,\\nbecause we subtract a high value from a small value. By setting– higher, we force the term\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 19'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 104, 'page_label': '105'}, page_content='m to be even smaller, to make sure that the model learned to recognize the two same faces\\nand two di\\x00erent faces with a high margin. Ifm is not small enough, then because of– the\\ncost will be positive, and the model parameters will be adjusted in backpropagation.\\nRather than randomly choose an image forN, a better way to create triplets for training is\\nto use the current model after several epochs of learning and ﬁnd candidates forN that are\\nsimilar toA and P according to that model. Using random examples asN would signiﬁcantly\\nslow down the training because the neural network will easily see the di\\x00erence between\\npictures of two random people, so the average triplet loss will be low most of the time and\\nthe parameters will not be updated fast enough.\\nTo build an SNN, we ﬁrst decide on the architecture of our neural network. For example,\\nCNN is a typical choice if our inputs are images. Given an example, to calculate the average\\ntriplet loss, we apply, consecutively, the model toA,t h e nt oP,t h e nt oN, and then we\\ncompute the loss for that example using eq. 3. We repeat that for all triplets in the batch and\\nthen compute the cost; gradient descent with backpropagation propagates the cost through\\nthe network to update its parameters.\\nIt’s a common misconception that for one-shot learning we need only one example of each\\nentity for training. In practice, we need much more than one example of each person for the\\nperson identiﬁcation model to be accurate. It’s called one-shot because of the most frequent\\napplication of such a model: face-based authentication. For example, such a model could be\\nused to unlock your phone. If your model is good, then you only need to haveone picture\\nof you on your phone and it will recognize you, and also it will recognize that someone else\\nis not you. When we have the model, to decide whether two picturesA and ˆA belong to\\nthe same person, we check ifÎf(A) ≠ f( ˆA)Î2 is less than some threshold·, which is another\\nhyperparameter of the model.\\n7.11 Zero-Shot Learning\\nWe ﬁnish this chapter withzero-shot learning. It is a relatively new\\nresearch area, so there are no algorithms that proved to have a signiﬁcant\\npractical utility yet. Therefore, I only outline here the basic idea and\\nleave the details of various algorithms for further reading. In zero-shot\\nlearning (ZSL) we want to train a model to assign labels to objects. The\\nmost frequent application is to learn to assign labels to images.\\nHowever, we want the model to be able to predict labels that we didn’t have in the training\\ndata. How is that possible?\\nThe trick is to use embeddings not just to represent the inputx but also to represent the\\noutput y. Imagine that we have a model that for any word in English can generate an\\nembedding vector with the following property: if a wordyi has a similar meaning to the\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 20'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 105, 'page_label': '106'}, page_content='word yk, then the embedding vectors for these two words will be similar. For example, ifyi is\\nParis and yk is Rome, then they will have embeddings that are similar; on the other hand, if\\nyk is potato, then the embeddings ofyi and yk will be dissimilar. Such embedding vectors are\\ncalled “word embeddings,” and they are usually compared using cosine similarity metrics1.\\nWord embeddings have such a property that each dimension of the embedding represents a\\nspeciﬁc feature of the meaning of the word. For example, if our word embedding has four\\ndimensions (usually they are much wider, between 50 and 300 dimensions), then these four\\ndimensions could represent such features of the meaning asanimalness, abstractness, sourness,\\nand yellowness (yes, sounds funny, but it’s just an example). So the wordbee would have an\\nembedding like this[1, 0, 0, 1], the wordyellow like this[0, 1, 0, 1], the wordunicorn like this\\n[1, 1, 0, 0]. The values for each embedding are obtained using a speciﬁc training procedure\\napplied to a vast text corpus.\\nNow, in our classiﬁcation problem, we can replace the labelyi for each examplei in our\\ntraining set with its word embedding and train a multi-label model that predicts word\\nembeddings. To get the label for a new examplex, we apply our modelf to x, get the\\nembedding ˆy and then search among all English words those whose embeddings are the most\\nsimilar to ˆy using cosine similarity.\\nWhy does that work? Take a zebra for example. It is white, it is a mammal, and it has stripes.\\nTake a clownﬁsh: it is orange, not a mammal, and has stripes. Now take a tiger: it is orange,\\nit has stripes, and it is a mammal. If these three features are present in word embeddings,\\nthe CNN would learn to detect these same features in pictures. Even if the labeltiger was\\nabsent in the training data, but other objects including zebras and clownﬁsh were, then the\\nCNN will most likely learn the notion ofmammalness, orangeness, andstripeness to predict\\nlabels of those objects. Once we present the picture of a tiger to the model, those features\\nwill be correctly identiﬁed from the image and most likely the closest word embedding from\\nour English dictionary to the predicted embedding will be that oftiger.\\n1Iw i l ls h o wi nC h a p t e r1 0h o wt ol e a r nw o r d se m b e d d i n g sf r o md a t a .\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 21'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 106, 'page_label': '107'}, page_content=\"Andriy Burkov's\"),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 107, 'page_label': '108'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 108, 'page_label': '109'}, page_content='8 Advanced Practice\\nThis chapter contains the description of techniques that you could ﬁnd useful in your practice\\nin some contexts. It’s called “Advanced Practice” not because the presented techniques are\\nmore complex, but rather because they are applied in some very speciﬁc contexts. In many\\npractical situations, you will most likely not need to resort to using these techniques, but\\nsometimes they are very helpful.\\n8.1 Handling Imbalanced Datasets\\nIn many practical situations, your labeled dataset will have underrepresented the examples\\nof some class. This is the case, for example, when your classiﬁer has to distinguish between\\ngenuine and fraudulent e-commerce transactions: the examples of genuine transactions are\\nmuch more frequent. If you use SVM with soft margin, you can deﬁne a cost for misclassiﬁed\\nexamples. Because noise is always present in the training data, there are high chances that\\nmany examples of genuine transactions would end up on the wrong side of the decision\\nboundary by contributing to the cost.\\nx(2)\\nx(1)\\n(a)\\nx(2)\\nx(1)\\n(b)\\nFigure 1: An illustration of an imbalanced problem. (a) Both classes have the same weight;\\n(b) examples of the minority class have a higher weight.\\nThe SVM algorithm will try to move the hyperplane to avoid as much as possible misclassiﬁed\\nexamples. The “fraudulent” examples, which are in the minority, risk being misclassiﬁed in\\norder to classify more numerous examples of the majority class correctly. This situation is\\nillustrated in Figure 1a. This problem is observed for most learning algorithms applied to\\nimbalanced datasets.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 109, 'page_label': '110'}, page_content='If you set the cost of misclassiﬁcation of examples of the minority class higher, then the\\nmodel will try harder to avoid misclassifying those examples, obviously for the cost of\\nmisclassiﬁcation of some examples of the majority class, as illustrated in Figure 1b.\\nSome SVM implementations (including SVC in scikit-learn) allow you to provide weights for\\nevery class. The learning algorithm takes this information into account when looking for the\\nbest hyperplane.\\nIf your learning algorithm doesn’t allow weighting classes, you can try to increase the\\nimportance of examples of some class by making multiple copies of the examples of this class\\n(this is calledoversampling).\\nAn opposite approach is to randomly remove from the training set some examples of the\\nmajority class (undersampling).\\nYou might also try to create synthetic examples by randomly sampling feature values of\\nseveral examples of the minority class and combining them to obtain a new example of\\nthat class. There two popular algorithms that oversample the minority class by creating\\nsynthetic examples: thesynthetic minority oversampling technique(SMOTE) and the\\nadaptive synthetic sampling method(ADASYN).\\nSMOTE and ADASYN work similarly in many ways. For a given examplexi of the minority\\nclass, they pickk nearest neighbors of this example (let’s call this set ofk examples Sk) and\\nthen create a synthetic examplexnew as xi + ⁄(xzi ≠ xi),w h e r exzi is an example of the\\nminority class chosen randomly fromSk. The interpolation hyperparameter⁄ is a random\\nnumber in the range[0, 1].\\nBoth SMOTE and ADASYN randomly pick all possiblexi in the dataset. In ADASYN,\\nthe number of synthetic examples generated for eachxi is proportional to the number of\\nexamples inSk which are not from the minority class. Therefore, more synthetic examples\\nare generated in the area where the examples of the minority class are rare.\\nSome algorithms are less sensitive to the problem of an imbalanced dataset. Decision trees,\\nas well as random forest and gradient boosting, often perform well on imbalanced datasets.\\n8.2 Combining Models\\nEnsemble algorithms, like Random Forest, typically combine models of the same nature. They\\nboost performance by combining hundreds of weak models. In practice, we can sometimes\\nget an additional performance gain by combining strong models made with di\\x00erent learning\\nalgorithms. In this case, we usually use only two or three models.\\nThere are three typical ways to combine models:\\n1) averaging,\\n2) majority vote, and\\n3) stacking.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 110, 'page_label': '111'}, page_content='Averaging works for regression as well as those classiﬁcation models that return classiﬁcation\\nscores. You simply apply all your models, let’s call thembase models,t ot h ei n p u tx and\\nthen average the predictions. To see if the averaged model works better than each individual\\nalgorithm, you test it on the validation set using a metric of your choice.\\nMajority vote works for classiﬁcation models. You apply all your base models to the input\\nx and then return the majority class among all predictions. In the case of a tie, you either\\nrandomly pick one of the classes, or, you return an error message (if the fact of misclassifying\\nwould incur a signiﬁcant cost).\\nStacking consists of building a meta-model that takes the output of your base models as\\ninput. Let’s say you want to combine a classiﬁerf1 and a classiﬁerf2, both predicting the\\nsame set of classes. To create a training example(ˆxi, ˆyi) for the stacked model, you set\\nˆxi =[ f1(x),f 2(x)] and ˆyi = yi.\\nIf some of your base models return not just a class, but also a score for each class, you can\\nuse these values as features too.\\nTo train the stacked model, it is recommended to use examples from the training set and\\ntune the hyperparameters of the stacked model using cross-validation.\\nObviously, you have to make sure that your stacked model performs better on the validation\\nset than each of the base models you stacked.\\nThe reason that combining multiple models can bring better performance overall is the\\nobservation that when several uncorrelated strong models agree they are more likely to agree\\non the correct outcome. The keyword here is “uncorrelated. ” Ideally, di\\x00erent strong models\\nhave to be obtained using di\\x00erent features or using algorithms of a di\\x00erent nature — for\\nexample, SVMs and Random Forest. Combining di\\x00erent versions of decision tree learning\\nalgorithm, or several SVMs with di\\x00erent hyperparameters may not result in a signiﬁcant\\nperformance boosting.\\n8.3 Training Neural Networks\\nIn neural network training, one challenging aspect is to convert your data into the input the\\nnetwork can work with. If your input is images, ﬁrst of all, you have to resize all images so\\nthat they have the same dimensions. After that, pixels are usually ﬁrst standardized and\\nthen normalized to the range[0, 1].\\nTexts have to be tokenized (that is split into pieces, such as words, punctuation marks, and\\nother symbols). For CNN and RNN, each token is converted into a vector using the one-hot\\nencoding, so the text becomes a list of one-hot vectors. Another, often a better way to\\nrepresent tokens is by using word embeddings. For multilayer perceptron, to convert texts\\nto vectors the bag of words approach may work well, especially for larger texts (larger than\\nSMS messages and tweets).\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 111, 'page_label': '112'}, page_content='The choice of speciﬁc neural network architecture is a di\\x00cult one. For the same problem,\\nlike seq2seq learning, there is a variety of architectures, and new ones are proposed almost\\nevery year. I recommend making the research on the state of the art solutions for your\\nproblem using Google Scholar or Microsoft Academic search engines that allow searching for\\nscientiﬁc publications using keywords and time range. If you don’t mind working with less\\nmodern architecture, I recommend looking for implemented architectures on GitHub and\\nﬁnd one that could be applied to your data with minor modiﬁcations.\\nIn practice, the advantage of modern architecture over an older one becomes less signiﬁcant\\nas you preprocess, clean and normalize your data, and create a larger training set. Many\\nmodern neural network architectures are a result of the collaboration of several scientists\\nfrom several labs and companies; such models could be very complex to implement them on\\nyour own and usually require much computational power to train. The time spent on trying\\nto replicate the results from a recent scientiﬁc paper may not be worth it. This time could\\nbetter be spent on building the solution around a less modern but stable model and getting\\nmore training data.\\nOnce you decided on the architecture of your network, you have to decide on the number\\nof layers, their type, and size. It is recommended to start with one or two layers, train a\\nmodel and see if it ﬁts the training data well (has a low bias). If not, gradually increase the\\nsize of each layer and the number of layers until the model perfectly ﬁts the training data.\\nOnce this is the case, if the model doesn’t perform well on the validation data (has a high\\nvariance), you should add regularization to your model. If, after you added regularization,\\nthe model doesn’t ﬁt the training data anymore, you slightly increase the size of the network\\nonce again, and you continue to work iteratively like this until the model ﬁts both training\\nand validation data well enough according to your metric.\\n8.4 Advanced Regularization\\nIn neural networks, besides L1 and L2 regularization, you can use neural network speciﬁc\\nregularizers: dropout, batch normalization, andearly stopping. Batch normalization\\nis technically not a regularization technique, but it often has a regularization e\\x00ect on the\\nmodel.\\nThe concept of dropout is very simple. Each time you run a training example through the\\nnetwork, you temporarily exclude at random some units from the computation. The higher\\nthe percentage of units excluded the higher the regularization e\\x00ect. Neural network libraries\\nallow you to add a dropout layer between two successive layers, or you can specify the dropout\\nparameter for the layer. The dropout parameter is in the range[0, 1] and it has to be found\\nexperimentally by tuning it on the validation data.\\nBatch normalization (which rather has to be called batch standardization) is a technique that\\nconsists of standardizing the outputs of each layer before the units of the subsequent layer\\nreceive them as input. In practice, batch normalization results in a faster and more stable\\ntraining, as well as in some regularization e\\x00ect. So it’s always a good idea to try to use\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 112, 'page_label': '113'}, page_content='batch normalization. In neural network libraries, you can often insert a batch normalization\\nlayer between two layers.\\nEarly stopping is the way to train a neural network by saving the preliminary model after\\nevery epoch and assessing the performance of the preliminary model on the validation set. As\\nyou remember from the section about gradient descent in Chapter 4, as the number of epochs\\nincreases, the cost decreases. The decreased cost means that the model ﬁts the training data\\nwell. However, at some point, after some epoche, the model can start overﬁtting: the cost\\nkeeps decreasing, but the performance of the model on the validation data deteriorates. If\\nyou keep, in a ﬁle, the version of the model after each epoch, you can stop the training once\\nyou start observing a decreased performance on the validation set. Alternatively, you can\\nkeep running the training process for a ﬁxed number of epochs and then, in the end, you\\npick the best model. Models saved after each epoch are calledcheckpoints. Some machine\\nlearning practitioners rely on this technique very often; others try to properly regularize the\\nmodel to avoid such undesirable behavior.\\nAnother regularization technique that can be applied not just to neural networks, but to\\nvirtually any learning algorithm, is calleddata augmentation. This technique is often\\nused to regularize models that work with images. Once you have your original labeled\\ntraining set, you can create a synthetic example from an original example by applying various\\ntransformations to the original image: zooming it slightly, rotating, ﬂipping, darkening, and\\nso on. You keep the original label in these synthetic examples. In practice, this often results\\nin increased performance of the model.\\n8.5 Handling Multiple Inputs\\nIn many of your practical problems, you will work with multimodal data. For example, your\\ninput could be an image and text and the binary output could indicate whether the text\\ndescribes this image or not.\\nShallow learning algorithms are not particularly well suited to work with multimodal data.\\nHowever, it doesn’t mean that it is impossible. For example, you can train one model on the\\nimage and another one on the text. Then you can use a model combination technique we\\ndiscussed above.\\nIf you cannot divide your problem into two independent subproblems, you can try to vectorize\\neach input (by applying the corresponding feature engineering method) and then simply\\nconcatenate two feature vectors together to form one wider feature vector. For example,\\nif your image has features[i(1),i (2),i (3)] and your text has features[t(1),t (2),t (3),t (4)] your\\nconcatenated feature vector will be[i(1),i (2),i (3),t (1),t (2),t (3),t (4)].\\nWith neural networks, you have more ﬂexibility. You can build two subnetworks, one for\\neach type of input. For example, a CNN subnetwork would read the image while an RNN\\nsubnetwork would read the text. Both subnetworks have as their last layer an embedding:\\nCNN has an embedding for the image, while RNN has an embedding for the text. You can\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 113, 'page_label': '114'}, page_content='then concatenate two embeddings and then add a classiﬁcation layer, such as softmax or\\nsigmoid, on top of the concatenated embeddings. Neural network libraries provide simple to\\nuse tools that allow concatenating or averaging layers from several subnetworks.\\n8.6 Handling Multiple Outputs\\nIn some problems, you would like to predict multiple outputs for one input. We considered\\nmulti-label classiﬁcation in the previous chapter. Some problems with multiple outputs can\\nbe e\\x00ectively converted into a multi-label classiﬁcation problem. Especially those that have\\nlabels of the same nature (like tags) or fake labels can be created as a full enumeration of\\ncombinations of original labels.\\nHowever, in some cases the outputs are multimodal, and their combinations cannot be\\ne\\x00ectively enumerated. Consider the following example: you want to build a model that\\ndetects an object on an image and returns its coordinates. The same model has to also return\\nthe label of the object, such as “person,” “cat,” or “hamster. ” Your training examples will\\nhave an image as input and one vector with coordinates of an object and another vector with\\na one-hot encoded label.\\nTo handle a situation like this, you can create one subnetwork that would work as an\\nencoder. It will read the input image using, for example, one or several convolution layers.\\nThe encoder’s last layer would be the embedding of the image. Then you add two other\\nsubnetworks on top of the embedding layer: one that takes the embedding vector as input\\nand predicts the coordinates of an object. This ﬁrst subnetwork can have a ReLU as the last\\nlayer, which is a good choice for predicting positive real numbers, such as coordinates; this\\nsubnetwork could use the mean squared error costC1. The second subnetwork will take the\\nsame embedding vector as input and predict the probabilities for each label. This second\\nsubnetwork can have a softmax as the last layer, which is appropriate for the probabilistic\\noutput, and use the averaged negative log-likelihood costC2 (also called cross-entropy cost).\\nObviously, you are interested in both accurately predicted coordinates and the label. However,\\nit is impossible to optimize the two cost functions at the same time. By trying to optimize one,\\nyou risk hurting the second one and the other way around. What you can do is add another\\nhyperparameter “ in the range(0, 1) and deﬁne the combined cost function as“C1 +(1 ≠“)C2.\\nThen you tune the value for“ on the validation data just like any other hyperparameter.\\n8.7 Transfer Learning\\nTransfer learning is probably where neural networks have a unique advantage over the\\nshallow models. In transfer learning, you pick an existing model trained on some dataset,\\nand you adapt this model to predict examples from another dataset, di\\x00erent from the one\\nthe model was built on. This second dataset is not like hold-out sets you use for validation\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 114, 'page_label': '115'}, page_content='and test. It may represent some other phenomenon, or, as machine learning scientists say, it\\nmay come from another statistical distribution.\\nFor example, imagine you have trained your model to recognize (and label) wild animals on a\\nbig labeled dataset. After some time, you have another problem to solve: you need to build a\\nmodel that would recognize domestic animals. With shallow learning algorithms, you do not\\nhave many options: you have to build another big labeled dataset, now for domestic animals.\\nWith neural networks, the situation is much more favorable. Transfer learning in neural\\nnetworks works like this.\\n1. You build a deep model on the original big dataset (wild animals).\\n2. You compile a much smaller labeled dataset for your second model (domestic animals).\\n3. You remove the last one or several layers from the ﬁrst model. Usually, these are layers\\nresponsible for the classiﬁcation or regression; they usually follow the embedding layer.\\n4. You replace the removed layers with new layers adapted for your new problem.\\n5. You “freeze” the parameters of the layers remaining from the ﬁrst model.\\n6. You use your smaller labeled dataset and gradient descent to train the parameters of\\nonly the new layers.\\nUsually, there is an abundance of deep models for visual problems available online. You can\\nﬁnd one that has high chances to be of use for your problem, download that model, remove\\nseveral last layers (the quantity of layers to remove is a hyperparameter), put your own\\nprediction layers and train your model.\\nEven if you don’t have an existing model, transfer learning can still help you in situations when\\nyour problem requires a labeled dataset very costly to obtain, but you can get another dataset\\nfor which labels are more readily available. Let’s say you build a document classiﬁcation\\nmodel. You got the taxonomy of labels from your employer, and it contains a thousand\\ncategories. In this case, you would need to pay someone to a) read, understand and memorize\\nthe di\\x00erences between categories and b) read up to a million documents and annotate them.\\nThat doesn’t sound good.\\nTo save on labeling so many examples, you could consider using Wikipedia pages as the dataset\\nto build your ﬁrst model. The labels for a Wikipedia page can be obtained automatically by\\ntaking the category the Wikipedia page belongs to. Once your ﬁrst model has learned to\\npredict Wikipedia categories well, you can transfer this learning to predict the categories of\\nyour employer’s taxonomy. Usually, you will need much fewer annotated examples for your\\nemployer’s problem than you would need if you started solving your original problem from\\nscratch.\\n8.8 Algorithmic E\\x00ciency\\nNot all algorithms capable of solving a problem are practical. Some can be fast; some can be\\ntoo slow. Some problems can be solved by a fast algorithm, for others, no fast algorithms\\ncan exist.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 115, 'page_label': '116'}, page_content='The subﬁeld of computer science calledanalysis of algorithmsis concerned with determining\\nand comparing the complexity of algorithms. Thebig O notationis used to classify algorithms\\naccording to how their running time or space requirements grow as the input size grows.\\nFor example, let’s say we have the problem of ﬁnding the two most distant one-dimensional\\nexamples in the set of examplesS of size N. One algorithm we could craft to solve this\\nproblem would look like this (here and below, in Python):\\n1 def find_max_distance(S):\\n2 result = None\\n3 max_distance = 0\\n4 for x1 in S:\\n5 for x2 in S:\\n6 if abs(x1 - x2) >= max_distance:\\n7 max_distance = abs(x1 - x2)\\n8 result = (x1, x2)\\n9 return result\\nIn the above algorithm, we loop over all values inS, and at every iteration of the ﬁrst loop, we\\nloop over all values inS once again. Therefore, the above algorithm makesN2 comparisons\\nof numbers. If we take as a unit time the time the comparison (once), abs (twice) and\\nassignment (twice) operations take, then the time complexity (or, simply, complexity) of this\\nalgorithm is at most5N2. When the complexity of an algorithm is measured in the worst\\ncase, the big O notation is used. For the above algorithm, using the big O notation, we write\\nthat the algorithm’s complexity isO(N2) (the constants, like5, are ignored).\\nFor the same problem, we can craft another algorithm like this:\\n1 def find_max_distance(S):\\n2 result = None\\n3 min_x = float(\"inf\")\\n4 max_x = float(\"-inf\")\\n5 for x in S:\\n6 if x < min_x:\\n7 min_x = x\\n8 elif x > max_x:\\n9 max_x = x\\n10 result = (max_x, min_x)\\n11 return result\\nIn the above algorithm, we loop over all values inS only once, so the algorithm’s complexity\\nis O(N). In this case, we say that the latter algorithm ismore e\\x00cient than the former.\\nUsually, an algorithm is called e\\x00cient when its complexity in big O notation is polynomial\\nin the size of the input. Therefore bothO(N) and O(N2) are e\\x00cient. However, for very\\nlarge inputs anO(N2) algorithm can still be very slow. In the big data era, scientists often\\nlook for O(logN ) algorithms.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 116, 'page_label': '117'}, page_content='From a practical standpoint, when you implement your algorithm, you shouldavoid using\\nloops whenever possible. For example, you should use operations on matrices and vectors,\\ninstead of loops. In Python, to computewx, you should write\\n1 import numpy\\n2 wx = numpy.dot(w,x)\\nand not\\n1 wx = 0\\n2 for i in range(N):\\n3 wx += w[i]*x[i]\\nUse appropriate data structures. If the order of elements in a collection doesn’t matter, use\\nset instead oflist. In Python, the operation of verifying whether a speciﬁc examplex belongs\\nto S is e\\x00cient whenS is declared as aset and is ine\\x00cient whenS is declared as alist.\\nAnother important data structure, which you can use to make your Python code more e\\x00cient\\nis dict. It is called a dictionary or a hashmap in other languages. It allows you to deﬁne a\\ncollection of key-value pairs with very fast lookups for keys.\\nUnless you know exactly what you do, always prefer using popular libraries to writing your\\nown scientiﬁc code. Scientiﬁc Python packages like numpy, scipy, and scikit-learn were built\\nby experienced scientists and engineers with e\\x00ciency in mind. They have many methods\\nimplemented in the C programming language for maximum speed.\\nIf you need to iterate over a vast collection of elements, usegenerators that create a function\\nthat returns one element at a time rather than all the elements at once.\\nUse cProﬁle package in Python to ﬁnd ine\\x00ciencies in your code.\\nFinally, when nothing can be improved in your code from the algorithmic perspective, you\\ncan further boost the speed of your code by using:\\n• multiprocessing package to run computations in parallel, and\\n• PyPy, Numba or similar tools to compile your Python code into fast, optimized machine\\ncode.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 117, 'page_label': '118'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 118, 'page_label': '119'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 119, 'page_label': '120'}, page_content='9 Unsupervised Learning\\nUnsupervised learning deals with problems in which your dataset doesn’t have labels. This\\nproperty is what makes it very problematic for many practical applications. The absence\\nof labels which represent the desired behavior for your model means the absence of a solid\\nreference point to judge the quality of your model. In this book, I only present unsupervised\\nlearning methods that allow building models that can be evaluated based on data as opposed\\nto human judgment.\\n9.1 Density Estimation\\nDensity estimationis a problem of modeling the probability density function (pdf) of the\\nunknown probability distribution from which the dataset has been drawn. It can be useful for\\nmany applications, in particular for novelty or intrusion detection. In Chapter 7, we already\\nestimated the pdf to solve the one-class classiﬁcation problem. To do that, we decided that\\nour model would beparametric, more precisely a multivariate normal distribution (MVN).\\nThis decision was somewhat arbitrary because if the real distribution from which our dataset\\nwas drawn is di\\x00erent from the MVN, our model will be very likely far from perfect. We\\nalso know that models can be nonparametric. We used a nonparametric model in kernel\\nregression. It turns out that the same approach can work for density estimation.\\nLet {xi}N\\ni=1 be a one-dimensional dataset (a multi-dimensional case is similar) whose examples\\nwere drawn from a distribution with an unknown pdff with xi œ R for alli =1 ,...,N .W e\\nare interested in modeling the shape of this functionf. Our kernel model off, let’s denote it\\nas ˆf, is given by,\\nˆfb(x)= 1\\nNb\\nNÿ\\ni=1\\nk\\n3x ≠ xi\\nb\\n4\\n, (1)\\nwhere b is a hyperparameter that controls the tradeo\\x00 between bias and variance of our\\nmodel and k is a kernel. Again, like in Chapter 7, we use a Gaussian kernel:\\nk(z)= 1Ô\\n2ﬁ exp\\n3≠z2\\n2\\n4\\n.\\nWe look for such a value ofb that minimizes the di\\x00erence between the real shape off and\\nthe shape of our modelˆfb. A reasonable choice of measure of this di\\x00erence is called the\\nmean integrated squared error:\\nMISE(b)= E\\n5⁄\\nR\\n( ˆfb(x) ≠ f(x))2 dx\\n6\\n. (2)\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 120, 'page_label': '121'}, page_content='Intuitively, you see in eq. 2 that we square the di\\x00erence between the real pdff and our\\nmodel of it ˆf. The integral\\ns\\nR replaces the summationqN\\ni=1 we employed in the average\\nsquared error, while the expectation operatorE replaces the average1\\nN .\\n(a)\\n (b)\\n(c)\\n (d)\\nFigure 1: Kernel density estimation: (a) good ﬁt; (b) overﬁtting; (c) underﬁtting; (d) the\\ncurve of grid search for the best value forb.\\nIndeed, when our loss is a function with a continuous domain, such as( ˆfb(x) ≠ f(x))2,w e\\nhave to replace the summation with the integral. The expectation operationE means that\\nwe want b to be optimal for all possible realizations of our training set{xi}N\\ni=1. That is\\nimportant because ˆfb is deﬁned on aﬁnite sample of some probability distribution, while the\\nreal pdf f is deﬁned on an inﬁnite domain (the setR).\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 121, 'page_label': '122'}, page_content='Now, we can rewrite the right-hand side term in eq. 2 like this:\\nE\\n5⁄\\nR\\nˆf2\\nb (x)dx\\n6\\n≠ 2E\\n5⁄\\nR\\nˆfb(x)f(x)dx\\n6\\n+ E\\n5⁄\\nR\\nf(x)2dx\\n6\\n.\\nThe third term in the above summation is independent ofb and thus can be ignored. An\\nunbiased estimator of the ﬁrst term is given by\\ns\\nR\\nˆf2\\nb (x)dx while the unbiased estimator of\\nthe second term can be approximated by≠ 2\\nN\\nqN\\ni=1\\nˆf(i)\\nb (xi),w h e r eˆf(i)\\nb is a kernel model of\\nf computed on our training set with the examplexi excluded.\\nThe termqN\\ni=1\\nˆf(i)\\nb (xi) is known in statistics as theleave one out estimate, a form of cross-\\nvalidation in which each fold consists of one example. You could have noticed that the terms\\nR\\nˆfb(x)f(x)dx (let’s call ita) is the expected value of the functionˆfb, because f is a pdf. It\\ncan be demonstrated that the leave one out estimate is an unbiased estimator ofEa.\\nNow, to ﬁnd the optimal valuebú for b, we want to minimize the cost deﬁned as:\\n⁄\\nR\\nˆf2\\nb (x)dx ≠ 2\\nN\\nNÿ\\ni=1\\nˆf(i)\\nb (xi).\\nWe can ﬁndbú using grid search. ForD-dimensional feature vectorsx, the error termx ≠ xi\\nin eq. 1 can be replaced by the Euclidean distanceÎx ≠ xiÎ. In ﬁg. 1 you can see the\\nestimates for the same pdf obtained with three di\\x00erent values ofb from a dataset containing\\n100 examples, as well as the grid search curve. We pickbú at the minimum of the grid search\\ncurve.\\n9.2 Clustering\\nClustering is a problem of learning to assign a label to examples by leveraging an unlabeled\\ndataset. Because the dataset is completely unlabeled, deciding on whether the learned model\\nis optimal is much more complicated than in supervised learning.\\nThere is a variety of clustering algorithms, and, unfortunately, it’s hard to tell which one is\\nbetter in quality for your dataset. Usually, the performance of each algorithm depends on\\nthe unknown properties of the probability distribution the dataset was drawn from.\\n9.2.1 K-Means\\nThe k-means clustering algorithm works as follows. First, the analyst has to choosek —t h e\\nnumber of classes (or clusters). Then we randomly putk feature vectors, calledcentroids,\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 122, 'page_label': '123'}, page_content='to the feature space1. We then compute the distance from each examplex to each centroidc\\nusing some metric, like the Euclidean distance. Then we assign the closest centroid to each\\nexample (like if we labeled each example with a centroid id as the label). For each centroid,\\nwe calculate the average feature vector of the examples labeled with it. These average feature\\nvectors become the new locations of the centroids.\\n(a) original data\\n (b) iteration 1\\n(c) iteration 3\\n (d) iteration 5\\nFigure 2: The progress of the kmeans algorithm fork =3 . The circles are two-dimensional\\nfeature vectors; the squares are moving centroids.\\n1Some variants of k-means compute the initial positions of centroids based on some properties of the\\ndataset.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 123, 'page_label': '124'}, page_content='We recompute the distance from each example to each centroid, modify the assignment and\\nrepeat the procedure until the assignments don’t change after the centroid locations were\\nrecomputed. The model is the list of assignments of centroids IDs to the examples.\\nThe initial position of centroids inﬂuence the ﬁnal positions, so two runs of k-means can\\nresult in two di\\x00erent models. One run of the k-means algorithm is illustrated in ﬁg. 2.\\nDi\\x00erent background colors represent regions in which all points belong to the same cluster.\\nThe value ofk, the number of clusters, is a hyperparameter that has to be tuned by the data\\nanalyst. There are some techniques for selectingk. None of them is proven optimal. Most of\\nthem require from the analyst to make an “educated guess” by looking at some metrics or\\nby examining cluster assignments visually. Later in this chapter, we consider one technique\\nwhich allows choosing a reasonably good value fork without looking at the data and making\\nguesses.\\n9.2.2 DBSCAN and HDBSCAN\\nWhile k-means and similar algorithms are centroid-based,DBSCAN is a density-based\\nclustering algorithm. Instead of guessing how many clusters you need, by using DBSCAN,\\nyou deﬁne two hyperparameters:‘ and n. You start by picking an examplex from your\\ndataset at random and assign it to cluster1. Then you count how many examples have\\nthe distance fromx less than or equal to‘. If this quantity is greater than or equal ton,\\nthen you put all these‘-neighbors to the same cluster1. You then examine each member of\\ncluster 1 and ﬁnd their respective‘-neighbors. If some member of cluster1 has n or more\\n‘-neighbors, you expand cluster1 by putting those‘-neighbors to the cluster. You continue\\nexpanding cluster1 until there are no more examples to put in it. In the latter case, you pick\\nfrom the dataset another example not belonging to any cluster and put it to cluster2. You\\ncontinue like this until all examples either belong to some cluster or are marked as outliers.\\nAn outlier is an example whose‘-neighborhood contains less thann examples.\\nThe advantage of DBSCAN is that it can build clusters that have an arbitrary shape, while k-\\nmeans and other centroid-based algorithms create clusters that have a shape of a hypersphere.\\nAn obvious drawback of DBSCAN is that it has two hyperparameters and choosing good\\nvalues for them (especially‘) could be challenging. Furthermore, having‘ ﬁxed, the clustering\\nalgorithm cannot e\\x00ectively deal with clusters of varying density.\\nHDBSCAN is the clustering algorithm that keeps the advantages of DBSCAN, by removing\\nthe need to decide on the value of‘. The algorithm is capable of building clusters of\\nvarying density. HDBSCAN is an ingenious combination of multiple ideas and describing the\\nalgorithm in full is out of the scope of this book.\\nHDBSCAN only has one important hyperparameter:n, that is the minimum number of\\nexamples to put in a cluster. This hyperparameter is relatively simple to choose by intuition.\\nHDBSCAN has very fast implementations: it can deal with millions of examples e\\x00ectively.\\nModern implementations of k-means are much faster than HDBSCAN though, but the qualities\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 124, 'page_label': '125'}, page_content='of the latter may outweigh its drawbacks for many practical tasks. It is recommended to\\nalways try HDBSCAN on your data ﬁrst.\\n9.2.3 Determining the Number of Clusters\\nThe most important question is how many clusters does your dataset have? When the feature\\nvectors are one-, two- or three-dimensional, you can look at the data and see “clouds” of\\npoints in the feature space. Each cloud is a potential cluster. However, forD-dimensional\\ndata, withD> 3, looking at the data is problematic2.\\nThere’s one practically useful method of determining the reasonable number of clusters based\\non the concept ofprediction strength. The idea is to split the data into training and test\\nset, similarly to how we do in supervised learning. Once you have the training and test sets,\\nStr of sizeNtr and Ste of sizeNte respectively, you ﬁxk, the number of clusters, and run a\\nclustering algorithmC on setsStr and Ste and obtain the clustering resultsC(Str,k ) and\\nC(Ste,k ).\\nLet A be the clusteringC(Str,k ) built using the training set. Note that the clusters inA\\ncan be deﬁned by some regions. If an example falls within one of those regions, then this\\nexample belongs to some speciﬁc cluster. For example, if we apply the k-means algorithm to\\nsome dataset, it results in a partition of the feature space intok polygonal regions, as we saw\\nin ﬁg. 2.\\nDeﬁne the Nte ◊ Nte co-membership matrix D[A, Ste] as follows: D[A, Ste](i,iÕ) =1 if and\\nonly if examplesxi and xiÕ from the test set belong to the same cluster according to the\\nclustering A.O t h e r w i s eD[A, Ste](i,iÕ) =0 .\\nLet’s take a break and see what we have here. We have built,using the training set of\\nexamples, a clusteringA that hask clusters. Then we have built the co-membership matrix\\nthat indicates whether two examplesfrom the test setbelong to the same cluster inA.\\nIntuitively, if the quantityk is the reasonable number of clusters, then two examples that\\nbelong to the same cluster in clusteringC(Ste,k ) will most likely belong to the same cluster\\nin clusteringC(Str,k ). On the other hand, ifk is not reasonable (too high or too low), then\\ntraining data-based and test data-based clusterings will likely be less consistent.\\n2Some analysts look at multiple two-dimensional scatter plots, in which only a pair of features are present\\nat the same time. It might give an intuition about the number of clusters. However, such an approach su\\x00ers\\nfrom subjectivity, is prone to error and counts as an educated guess rather than a scientiﬁc method.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 125, 'page_label': '126'}, page_content='full dataset\\n training set\\n test set\\n(a)\\n (b)\\n (c)\\nFigure 3: The clustering fork =4 : (a) training data clustering; (b) test data clustering; (c)\\ntest data plotted over the training clustering.\\nThe idea is illustrated in ﬁg. 3. The plots in ﬁg. 3a and 3b show respectivelyC(Str, 4) and\\nC(Ste, 4) with their respective cluster regions. Fig. 3c shows the test examples plotted over\\nthe training data cluster regions. You can see in 3c that orange test examples don’t belong\\nanymore to the same cluster according to the clustering regions obtained from the training\\ndata. This will result in many zeroes in the matrixD[A, Ste] which, in turn, is an indicator\\nthat k =4 is likely not the best number of clusters.\\nMore formally, the prediction strength for the number of clustersk is given by,\\nps(k)\\ndef\\n=m i n\\nj=1,...,k\\n1\\n|Aj|(|Aj|≠ 1)\\nÿ\\ni,iÕœAj\\nD[A, Ste](i,iÕ),\\nwhere A\\ndef\\n= C(Str,k ), Aj is jth cluster from the clusteringC(Ste,k ) and |Aj| is the number\\nof examples in clusterAj.\\nGiven a clusteringC(Str,k ), for each test cluster, we compute the proportion of observation\\npairs in that cluster that are also assigned to the same cluster by the training set centroids.\\nThe prediction strength is the minimum of this quantity over thek test clusters.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 126, 'page_label': '127'}, page_content='Figure 4: Predictive strength for di\\x00erent values ofk for two-, three- and four-cluster data.\\nExperiments suggest that a reasonable number of clusters is the largestk such thatps(k) is\\nabove 0.8. You can see in ﬁg. examples of predictive strength for di\\x00erent values ofk for\\ntwo-, three- and four-cluster data.\\nFor non-deterministic clustering algorithms, such as k-means, which\\ncan generate di\\x00erent clusterings depending on the initial positions\\nof centroids, it is recommended to do multiple runs of the clustering\\nalgorithm for the samek and compute the average prediction strength\\n¯p s(k) over multiple runs. Another e\\x00ective method to estimate the\\nnumber of clusters is thegap statisticmethod. Other, less automatic\\nmethods, which some analysts still use, include theelbow method\\nand theaverage silhouette method.\\n9.2.4 Other Clustering Algorithms\\nDBSCAN and k-means compute so-calledhard clustering, in which each example can\\nbelong to only one cluster.Gaussian mixture model(GMM) allow each example to be a\\nmember of several clusters with di\\x00erentmembership score(HDBSCAN allows that too,\\nby the way). Computing a GMM is very similar to doing model-based density estimation.\\nIn GMM, instead of having just one multivariate normal distribution (MND), we have a\\nweighted sum of several MNDs:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 127, 'page_label': '128'}, page_content='fX =\\nkÿ\\nj=1\\n„jfµj,\\x00j ,\\nwhere fµj,\\x00j is a MNDj, and„j is its weight in the sum. The values of parametersµj, \\x00j,\\nand „j, for allj =1 ,...,k are obtained using theexpectation maximization algorithm\\n(EM) to optimize themaximum likelihoodcriterion.\\nAgain, for simplicity, let us look at the one-dimensional data. Also assume that there are two\\nclusters: k =2 . In this case, we have two Gaussian distributions,\\nf(x | µ1,‡ 2\\n1)= 1\\uf8ff\\n2ﬁ‡2\\n1\\ne\\n≠ (x≠µ1)2\\n2‡2\\n1 and f(x | µ2,‡ 2\\n2)= 1\\uf8ff\\n2ﬁ‡2\\n2\\ne\\n≠ (x≠µ2)2\\n2‡2\\n2 , (3)\\nwhere f(x | µ1,‡ 2\\n1) and f(x | µ2,‡ 2\\n2) are two parametrized pdf deﬁning the likelihood of\\nX = x.\\nWe use the EM algorithm to estimateµ1, ‡2\\n1, µ2, ‡2\\n2, „1, and„2. The parameters„1 and „2\\nof the GMM are useful for the density estimation task and less useful for the clustering task,\\nas we will see below.\\nEM works like follows. In the beginning, we guess the initial values forµ1, ‡2\\n1, µ2, and‡2\\n2,\\nand set„1 = „2 = 1\\n2 (in general, it’s1\\nk for each„k).\\nAt each iteration of EM, the following four steps are executed:\\n1. For alli =1 ,...,N , calculate the likelihood of eachxi using eq. 3:\\nf(xi | µ1,‡ 2\\n1) Ω 1\\uf8ff\\n2ﬁ‡2\\n1\\ne\\n≠ (xi≠µ1)2\\n2‡2\\n1 and f(xi | µ2,‡ 2) Ω 1\\uf8ff\\n2ﬁ‡2\\n2\\ne\\n≠ (xi≠µ2)2\\n2‡2\\n2 .\\n2. Using Bayes’ Rule, for each examplexi, calculate the likelihoodb(j)\\ni that the example\\nbelongs to clusterj œ{ 1, 2} (in other words, the likelihood that the example was drawn\\nfrom the Gaussianj):\\nb(j)\\ni Ω f(xi | µj,‡ 2\\nj )„j\\nf(xi | µ1,‡ 2\\n1)„1 + f(xi | µ2,‡ 2\\n2)„2\\n.\\nThe parameter„j reﬂects how likely is that our Gaussian distributionj with parametersµj\\nand “j may have produced our dataset. That is why in the beginning we set„1 = „2 = 1\\n2 :w e\\ndon’t know how each of the two Gaussians is likely, and we reﬂect our ignorance by setting\\nthe likelihood of both to one half.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 128, 'page_label': '129'}, page_content='iteration 1\\n iteration 2\\niteration 10\\n iteration 40\\nFigure 5: The progress of the Gaussian mixture model estimation using the EM algorithm\\nfor two clusters (k =2 ).\\n3. Compute the new values ofµj and ‡2\\nj , j œ{ 1, 2} as,\\nµj Ω\\nqN\\ni=1 b(j)\\ni xi\\nqN\\ni=1 b(j)\\ni\\nand ‡2\\nj Ω\\nqN\\ni=1 b(j)\\ni (xi ≠ µj)2\\nqN\\ni=1 b(j)\\ni\\n. (4)\\n4. Update „j, j œ{ 1, 2} as,\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 12'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 129, 'page_label': '130'}, page_content='„j Ω 1\\nN\\nNÿ\\ni=1\\nb(j)\\ni .\\nThe steps1 ≠ 4 are executed iteratively until the valuesµj and ‡2\\nj don’t change much: for\\nexample, the change is below some threshold‘. Fig. 5 illustrates this process.\\nYou may have noticed that the EM algorithm is very similar to the k-means algorithm: start\\nwith random clusters, then iteratively update each cluster’s parameters by averaging the\\ndata that is assigned to that cluster. The only di\\x00erence in the case of the GMM is that the\\nassignment of an examplexi to the clusterj is soft: xi belongs to clusterj with probability\\nb(j)\\ni . This is why we calculate the new values forµj and ‡2\\nj in eq. 4 not as an average (used\\nin k-means) but as aweighted average with weightsb(j)\\ni .\\nOnce we have learned the parametersµj and ‡2\\nj for each clusterj, the membership score of\\nexample x in clusterj is given byf(x | µj,‡ 2\\nj ).\\nThe extension toD-dimensional data (D> 1) is straightforward. The only di\\x00erence is\\nthat instead of the variance‡2, we now have the covariance matrix\\x00 that parametrizes the\\nmultinomial normal distribution (MND). The advantage of GMM over k-means is that the\\nclusters in GMM can have a form of an ellipse that can have an arbitrary elongation and\\nrotation. The values in the covariance matrix control these properties.\\nHow to choosek in GMM? Unfortunately, there’s no universally recognized method. What\\nis usually recommended to do is to split your dataset into training and test set. Then try\\ndi\\x00erent k and build a di\\x00erent modelfk\\ntr for eachk on the training data. Then choose the\\nmodel that maximizes the likelihood of examples in the test set:\\narg max\\nk\\nNteŸ\\ni=1\\nfk\\ntr(xi),\\nwhere Nte is the size of the test set.\\nThere is a variety of clustering algorithms described in the literature.\\nWorth mentioning arespectral clusteringand hierarchical cluster-\\ning. For some datasets, you may ﬁnd those more appropriate. However,\\nin most practical cases, kmeans, HDBSCAN and the Gaussian mixture\\nmodel would satisfy your needs.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 13'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 130, 'page_label': '131'}, page_content='9.3 Dimensionality Reduction\\nMany modern machine learning algorithms, such as ensemble algorithms and neural networks\\nhandle well very high-dimensional examples, up to millions of features. With modern\\ncomputers and graphical processing units (GPUs), dimensionality reduction techniques are\\nused much less in practice than in the past. The most frequent use case for dimensionality\\nreduction is data visualization: humans can only interpret on a plot the maximum of three\\ndimensions.\\nAnother situation in which you could beneﬁt from dimensionality reduction is when you\\nhave to build an interpretable model and to do so you are limited in your choice of learning\\nalgorithms. For example, you can only use decision tree learning or linear regression. By\\nreducing your data to lower dimensionality and by ﬁguring out which quality of the original\\nexample each new feature in the reduced feature space reﬂects, one can use simpler algorithms.\\nDimensionality reduction removes redundant or highly correlated features; it also reduces the\\nnoise in the data — all that contributes to the interpretability of the model.\\nThe three most widely used techniques of dimensionality reduction areprincipal com-\\nponent analysis(PCA), uniform manifold approximation and projection(UMAP),\\nand autoencoders.\\nI already explained autoencoders in Chapter 7. You can use the low-dimensional output of the\\nbottleneck layerof the autoencoder as the vector of reduced dimensionality that represents\\nthe high-dimensional input feature vector. You know that this low-dimensional vector\\nrepresents the essential information contained in the input vector because the autoencoder is\\ncapable of reconstructing the input feature vector based on the bottleneck layer output alone.\\n9.3.1 Principal Component Analysis\\nPrincipal component analysis or PCA is one of the oldest methods. The math behind it\\ninvolves operation on matrices that I didn’t explain in Chapter 2, so I leave the math of\\nPCA for your further reading. Here, I only provide intuition and illustrate the method on an\\nexample.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 14'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 131, 'page_label': '132'}, page_content='(a)\\n (b)\\n (c)\\nFigure 6: PCA: (a) the original data; (b) two principal components displayed as vectors; (c)\\nthe data projected on the ﬁrst principal component.\\nConsider a two-dimensional data as shown in ﬁg. 6a. Principal components are vectors that\\ndeﬁne a new coordinate system in which the ﬁrst axis goes in the direction of the highest\\nvariance in the data. The second axis is orthogonal to the ﬁrst one and goes in the direction\\nof the second highest variance in the data. If our data was three-dimensional, the third axis\\nwould be orthogonal to both the ﬁrst and the second axes and go in the direction of the third\\nhighest variance, and so on. In ﬁg. 6b, the two principal components are shown as arrows.\\nThe length of the arrow reﬂects the variance in this direction.\\nNow, if we want to reduce the dimensionality of our data toDnew <D ,w ep i c kDnew\\nlargest principal components and project our data points on them. For our two-dimensional\\nillustration, we can setDnew =1 and project our examples to the ﬁrst principal component\\nto obtain the orange points in ﬁg. 6c.\\nTo describe each orange point, we need only one coordinate instead\\nof two: the coordinate with respect to the ﬁrst principal component.\\nWhen our data is very high-dimensional, it often happens in practice\\nthat the ﬁrst two or three principal components account for most of the\\nvariation in the data, so by displaying the data on a 2D or 3D plot we\\ncan indeed see a very high-dimensional data and its properties.\\n9.3.2 UMAP\\nThe idea behind many of the modern dimensionality reduction algorithms, especially those\\ndesigned speciﬁcally for visualization purposes, such ast-SNE and UMAP, is basically\\nthe same. We ﬁrst design a similarity metric for two examples. For visualization purposes,\\nbesides the Euclidean distance between the two examples, this similarity metric often reﬂects\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 15'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 132, 'page_label': '133'}, page_content='some local properties of the two examples, such as the density of other examples around\\nthem.\\nIn UMAP, this similarity metricw is deﬁned as follows,\\nw(xi, xj)\\ndef\\n= wi(xi, xj)+ wj(xj, xi) ≠ wi(xi, xj)wj(xj, xi). (5)\\nThe functionwi(xi, xj) is deﬁned as,\\nwi(xi, xj)\\ndef\\n=e x p\\n3\\n≠d(xi, xj) ≠ ﬂi\\n‡i\\n4\\n,\\nwhere d(xi, xj) is the Euclidean distance between two examples,ﬂi is the distance fromxi\\nto its closest neighbor, and‡i is the distance fromxi to its kth closest neighbor (k is a\\nhyperparameter of the algorithm).\\nIt can be shown that the metric in eq. 5 varies in the range from0 to 1 and is symmetric,\\nwhich means thatw(xi, xj)= w(xj, xi).\\nLet w denote the similarity of two examples in the original high dimensional space and let\\nwÕ be the similarity given by the same eq. 5 in the new low-dimensional space. Because the\\nvalues ofw and wÕ lie in the range between0 and 1, we can see them as two probability\\ndistributions. A widely used metric of similarity between two probability distributions is\\ncross-entropy:\\nC(w, wÕ)=\\nNÿ\\ni=1\\nNÿ\\nj=1\\nw(xi, xj)l n\\nA\\nw(xi, xj)\\nwÕ(xÕ\\ni, xÕ\\nj)\\nB\\n+( 1≠ w(xi, xj)) ln\\nA\\n1 ≠ w(xi, xj)\\n1 ≠ wÕ(xÕ\\ni, xÕ\\nj)\\nB\\n, (6)\\nwhere xÕ is the low-dimensional “version” of the original high-dimensional examplex.\\nAs you can see from eq. 6, whenw(xi, xj) is similar towÕ(xÕ\\ni, xÕ\\nj), for all pairs(i, j),t h e n\\nC(w, wÕ) is minimized. And this is precisely what we want: for any two examplesxi and\\nxj, we want their similarity metric in the original and the lower-dimensional spaces to be as\\nsimilar as possible.\\nIn eq. 6 the unknown parameters arexÕ\\ni (for alli =1 ,...,N ) and we can compute them by\\ngradient descent by minimizingC(w, wÕ).\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 16'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 133, 'page_label': '134'}, page_content='PCA\\n UMAP\\n Autoencoder\\nFigure 7: Dimensionality reduction of the MNIST dataset using three di\\x00erent techniques.\\nIn ﬁg. 7, you can see the result of dimensionality reduction applied to the MNIST dataset of\\nhandwritten digits. MNIST is commonly used for benchmarking various image processing\\nsystems; it contains 70,000 labeled examples. Ten di\\x00erent colors on the plot correspond to\\nten classes. Each point on the plot corresponds a speciﬁc example in the dataset. As you can\\nsee, UMAP separates examples visually better (remember, it doesn’t have access to labels).\\nIn practice, UMAP is slightly slower than PCA but faster than autoencoder.\\n9.4 Outlier Detection\\nOutlier detectionis the problem of detecting in the dataset the examples that are very\\ndi\\x00erent from what a typical example in the dataset looks like. We have already seen several\\ntechniques that could help to solve this problem: autoencoder and one-class classiﬁer learning.\\nIf we use autoencoder, we train it on our dataset. Then, if we want to predict whether an\\nexample is an outlier, we can use the autoencoder model to reconstruct the example from\\nthe bottleneck layer. The model will unlikely be capable of reconstructing an outlier.\\nIn one-class classiﬁcation, the model either predicts that the input example belongs to the\\nclass, or it’s an outlier.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 17'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 134, 'page_label': '135'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 135, 'page_label': '136'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 136, 'page_label': '137'}, page_content='10 Other Forms of Learning\\n10.1 Metric Learning\\nI mentioned that the most frequently used metrics of similarity (or dissimilarity) between\\ntwo feature vectors areEuclidean distanceand cosine similarity. Such choices of metric\\nseem logical but arbitrary, just like the choice of the squared error in linear regression. The\\nfact that one metric can work better than another depending on the dataset is an indicator\\nthat none of them is perfect.\\nYou can create your metric that would work better for your dataset. It’s then possible to\\nintegrate your metric into any learning algorithm that needs a metric, like k-means or kNN.\\nHow can you know, without trying all possibilities, which equation would be a good metric?\\nYou can train your metric from data.\\nRemember the Euclidean distance between two feature vectorsx and xÕ:\\nd(x, xÕ)\\ndef\\n=\\n\\uf8ff\\n(x ≠ xÕ)2 =\\n\\uf8ff\\n(x ≠ xÕ)(x ≠ xÕ).\\nWe can slightly modify this metric to make it parametrizable and then learn these parameters\\nfrom data. Consider the following modiﬁcation:\\ndA(x, xÕ)= Îx ≠ xÕÎA\\ndef\\n=\\nÒ\\n(x ≠ xÕ)€A(x ≠ xÕ),\\nwhere A is aD ◊ D matrix. Let’s sayD =3 .I fw el e tA be the identity matrix,\\nA\\ndef\\n=\\nS\\nU\\n100\\n010\\n001\\nT\\nV,\\nthen dA becomes the Euclidean distance. If we have a general diagonal matrix, like this,\\nA\\ndef\\n=\\nS\\nU\\n200\\n080\\n001\\nT\\nV,\\nthen di\\x00erent dimensions have di\\x00erent importance in the metric. (In the above example,\\nthe second dimension is the most important in the metric calculation.) More generally, to be\\ncalled a metric a function of two variables has to satisfy three conditions:\\n1.d (x, xÕ) Ø 0 nonnegativity\\n2.d (x, xÕ) Æ d(x, xÕ)+ d(xÕ, z) triangle inequality\\n3.d (x, xÕ)= d(xÕ, x) symmetry\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 137, 'page_label': '138'}, page_content='To satisfy the ﬁrst two conditions, the matrixA has to bepositive semideﬁnite. You can\\nsee a positive semideﬁnite matrix as the generalization of the notion of a nonnegative real\\nnumber to matrices. Any positive semideﬁnite matrixM satisﬁes:\\nz€Mz Ø 0.\\nThe above property follows from the deﬁnition of a positive semideﬁnite matrix. The proof\\nthat the second condition is satisﬁed when the matrixA is positive semideﬁnite can be found\\non the book’s companion website.\\nTo satisfy the third condition, we can simply take(d(x, xÕ)+ d(xÕ, x))/2.\\nLet’s say we have an unannotated setX = {xi}N\\ni=1. To build the training data for our\\nmetric learning problem, we manually create two sets. The ﬁrst setS is such that a pair of\\nexamples (xi, xk) belongs to setS if xi and xk are similar (from our subjective perspective).\\nThe second setD is such that a pair of examples(xi, xk) belongs to setD if xi and xk are\\ndissimilar.\\nTo train the matrix of parametersA from the data, we want to ﬁnd a positive semideﬁnite\\nmatrix A that solves the following optimization problem:\\nmin\\nA\\nÿ\\n(xi,xk)œS\\nÎx ≠ xÕÎ2\\nA such that\\nÿ\\n(xi,xk)œD\\nÎx ≠ xÕÎA Ø c,\\nwhere c is a positive constant (can be any number).\\nThe solution to this optimization problem is found by gradient descent\\nwith a modiﬁcation that ensures that the found matrixA is positive\\nsemideﬁnite. We leave the description of the algorithm out of the scope\\nof this book for further reading. You should know that there are many\\nother ways to learn a metric, including non-linear and kernel-based.\\nHowever, the one presented in this book gives a good result for most\\npractical problems.\\n10.2 Learning to Rank\\nLearning to rankis a supervised learning problem. Among others, one frequent problem\\nsolved using learning to rank is the optimization of search results returned by a search engine\\nfor a query. In search result ranking optimization, a labeled exampleXi in the training set\\nof sizeN is a ranked collection of documents of sizeri (labels are ranks of documents). A\\nfeature vector represents each document in the collection. The goal of the learning is to ﬁnd\\na ranking functionf which outputs values that can be used to rank documents. For each\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 138, 'page_label': '139'}, page_content='training example, an ideal functionf would output values that induce the same ranking of\\ndocuments as given by labels.\\nEach example Xi, i =1 ,...,N , is a collection of feature vectors with labels: Xi =\\n{(xi,j,y i,j)}ri\\nj=1. Features in a feature vector xi,j represent the document j =1 ,...,r i.\\nFor example,x(1)\\ni,j could represent how recent is the document,x(2)\\ni,j would reﬂect whether the\\nwords of the query can be found in the document title,x(3)\\ni,j could represent the size of the\\ndocument, and so on. The labelyi,j could be the rank (1, 2,...,r i) or a score. For example,\\nthe lower the score, the higher the document should be ranked.\\nThere are three principal approaches to solve such a learning problem:pointwise, pairwise,\\nand listwise.\\nPointwise approach transforms each training example into multiple examples: one example\\nper document. The learning problem becomes a standard supervised learning problem, either\\nregression or logistic regression. In each example(x,y ) of the pointwise learning problem,\\nx is the feature vector of some document, andy is the original score (ifyi,j is a score) or a\\nsynthetic score obtained from the ranking (the higher the rank, the lower is the synthetic\\nscore). Any supervised learning algorithm can be used in this case. The solution is usually\\nfar from perfect. Principally, this is because each document is considered in isolation, while\\nthe original ranking (given by the labelsyi,j of the original training set) could optimize the\\npositions of the whole set of documents. For example, if we have already given a high rank to\\na Wikipedia page in some collection of documents, we would not give a high rank to another\\nWikipedia page for the same query.\\nIn the pairwise approach, the problem also considers documents in isolation, however, in this\\ncase, a pair of documents is considered at once. Given a pair of documents(xi, xk) we want\\nto build a modelf that, given(xi, xk) as input, outputs a value close to1 if xi has to be put\\nhigher than xk in the ranking. Otherwise,f outputs a value close to0.A t t h e t e s t t i m e ,\\ngiven a model, the ﬁnal ranking for an unlabeled exampleX is obtained by aggregating the\\npredictions for all pairs of documents inX . Such an approach works better than pointwise,\\nbut still far from perfect.\\nThe state of the art rank learning algorithms, such asLambdaMART,i m p l e m e n tt h e\\nlistwise approach. In the listwise approach, we try to optimize the model directly on some\\nmetric that reﬂects the quality of ranking. There are various metrics for assessing search\\nengine result ranking, including precision and recall. One popular metric that combines both\\nprecision and recall is calledmean average precision(MAP).\\nTo deﬁne MAP, let us ask judges (Google call those peoplerankers) to examine a collection\\nof search results for a query and assign relevancy labels to each search result. Labels could\\nbe binary (1 for “relevant” and0 for “irrelevant”) or on some scale, say from1 to 5:t h e\\nhigher the value, the more relevant the document is to the search query. Let our judges build\\nsuch relevancy labeling for a collection of100 queries. Now, let us test our ranking model on\\nthis collection. Theprecision of our model for some query is given by:\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 139, 'page_label': '140'}, page_content='precision = |{relevant documents}ﬂ{ retrieved documents}|\\n|{retrieved documents}| ,\\nwhere the notation|·| means “the number of. ” Theaverage precisionmetric, AveP, is\\ndeﬁned for a ranked collection of documents returned by a search engine for a queryq as,\\nAveP(q)=\\nqn\\nk=1(P (k) ◊ rel(k))\\n|{relevant documents}|,\\nwhere n is the number of retrieved documents,P (k) denotes the precision computed for\\nthe topk search results returned by our ranking model for the query,rel(k) is an indicator\\nfunction equaling1 if the item at rankk is a relevant document (according to judges) and\\nzero otherwise. Finally, the MAP for a collection of search queries of sizeQ is given by,\\nMAP =\\nqQ\\nq=1 AveP(q)\\nQ .\\nNow we get back to LambdaMART. This algorithm implements a pairwise approach, and it\\nuses gradient boosting to train the ranking functionh(x). Then the binary modelf(xi, xk)\\nthat predicts whether the documentxi should have a higher rank than the documentxk (for\\nthe same search query) is given by a sigmoid with a hyperparameter–,\\nf(xi, xk)\\ndef\\n= 1\\n1+e x p ( (h(xi) ≠ h(xk))–.\\nAgain, as with many models that predict probability, the cost function is cross-entropy\\ncomputed using the modelf. In our gradient boosting, we combine multiple regression trees\\nto build the functionh by trying to minimize the cost. Remember that in gradient boosting\\nwe add a tree to the model to reduce the error that the current model makes on the training\\ndata. For the classiﬁcation problem, we computed the derivative of the cost function to\\nreplace real labels of training examples with these derivatives. LambdaMART works similarly,\\nwith one exception. It replaces the real gradient with a combination of the gradient and\\nanother factor that depends on the metric, such as MAP. This factor modiﬁes the original\\ngradient by increasing or decreasing it so that the metric value is improved.\\nThat is a very bright idea and not many supervised learning algorithms can boast that they\\noptimize a metric directly. Optimizing a metric is what we really want, but what we do in a\\ntypical supervised learning algorithm is we optimize the cost instead of the metric. Usually,\\nin supervised learning, as soon as we have found a model that optimizes the cost function, we\\ntry to tweak hyperparameters to improve the value of the metric. LambdaMART optimizes\\nthe metric directly.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 140, 'page_label': '141'}, page_content='The remaining question is how do we build the ranked list of results based on the predictions\\nof the modelf which predicts whether its ﬁrst input has to be ranked higher than the second\\ninput. It’s generally a computationally hard problem, and there are multiple implementations\\nof rankers capable of transforming pairwise comparisons into a ranking list. The most\\nstraightforward approach is to use an existing sorting algorithm.\\nSorting algorithms sort a collection of numbers in increasing or decreas-\\ning order. (The simplest sorting algorithm is calledbubble sort.I t ’ s\\nusually taught in engineering schools.) Typically, sorting algorithms\\niteratively compare a pair of numbers in the collection and change their\\npositions in the list based on the result of that comparison. If we plug\\nour functionf into a sorting algorithm to execute this comparison, the\\nsorting algorithm will sort documents and not numbers.\\n10.3 Learning to Recommend\\nLeaning to recommend is an approach to build recommender systems. Usually, we have a\\nuser who consumes some content. We have the history of consumption, and we want to\\nsuggest this user new content that the user would like. It could be a movie on Netﬂix or a\\nbook on Amazon.\\nTraditionally, two approaches were used to give recommendations: content-based ﬁltering\\nand collaborative ﬁltering.\\nContent-based ﬁltering is based on learning what do users like based on the description of\\nthe content they consume. For example, if the user of a news site often reads news articles on\\nscience and technology, then we would suggest to this user more documents on science and\\ntechnology. More generally, we could create one training setper user and add news articles\\nto this dataset as a feature vectorx and whether the user recently read this news article as a\\nlabel y. Then we build the model of each user and can regularly examine each new piece of\\ncontent to determine whether a speciﬁc user would read it or not.\\nThe content-based approach has many limitations. For example, the user can be trapped in\\nthe so-called ﬁlter bubble: the system will always suggest to that user the information that\\nlooks very similar to what user already consumed. That could result in complete isolation of\\nthe user from information that disagrees with their viewpoints or expands them. On a more\\npractical side, the users might just get recommendations of items they already know about,\\nwhich is undesirable.\\nCollaborative ﬁltering has a signiﬁcant advantage over content-based ﬁltering: the recommen-\\ndations to one user are computed based on what other users consume or rate. For instance,\\nif two users gave high ratings to the same ten movies, then it’s more likely that user 1 will\\nappreciate new movies recommended based on the tastes of the user 2 and vice versa. The\\ndrawback of this approach is that the content of the recommended items is ignored.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 7'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 141, 'page_label': '142'}, page_content='In collaborative ﬁltering, the information on user preferences is organized in a matrix. Each\\nrow corresponds to a user, and each column corresponds to a piece of content that user rated\\nor consumed. Usually, this matrix is huge and extremely sparse, which means that most of\\nits cells aren’t ﬁlled (or ﬁlled with a zero). The reason for such a sparsity is that most users\\nconsume or rate just a tiny fraction of available content items. It’s is very hard to make\\nmeaningful recommendations based on such sparse data.\\nMost real-world recommender systems use a hybrid approach: they combine recommendations\\nobtained by the content-based and collaborative ﬁltering models.\\nI already mentioned that content-based recommender model could be built using a classiﬁca-\\ntion or regression model that predicts whether a user will like the content based on content’s\\nfeatures. Examples of features could include the words in books or news articles the user\\nliked, the price, the recency of the content, the identity of the content author and so on.\\nTwo e\\x00ective collaborative-ﬁltering learning algorithms arefactorization machines(FM)\\nand denoising autoencoders (DAE).\\n10.3.1 Factorization Machines\\nFactorization machines is a relatively new kind of algorithm. It was explicitly designed for\\nsparse datasets. Let’s illustrate the problem.\\nx(1)\\nx(2)\\nx(3)\\nx(4)\\nx(5)\\nx(6)\\n...\\nx(D)\\n1\\n1\\n1\\n1\\n1\\n1\\n000\\n... ... ... ...\\n0 0\\n00\\n0 0\\n0 0\\n0 0\\n0 0 ...\\n...\\n...\\n...\\n...\\n...\\n...\\nuser\\nEdAlZak...\\n1\\n0\\n0\\n0\\n0\\n0\\n100\\n... ... ... ...\\n0 0\\n01\\n0 1\\n0 1\\n0 0\\n1 0 ...\\n...\\n...\\n...\\n...\\n...\\n...\\n0\\n0\\n...\\n0\\n0\\n0\\n0\\n1\\nIt UpJawsHer\\nmovie\\n0.2\\n0.2\\n0.2\\n0\\n0\\n0\\n100\\n... ... ... ...\\n0.80.4\\n0.40.8\\n0.8\\xa00.4\\n0 0.7\\n0 0.7\\n0.80 ...\\n...\\n...\\n...\\n...\\n...\\n...\\n0.6\\n0\\n...\\n0\\n0\\n0.7\\n0.1\\n0.1\\nIt UpJawsHer\\nrated\\xa0movies\\nx99x100\\n0.3\\n0.3\\n0.3\\n0.35\\n0.35\\n0.5\\n0.95\\n...\\n0.8\\n0.8\\n0.8\\xa0\\n0.78\\n0.78\\n0.77\\n...\\n0.85\\n1\\n3\\n2\\n3\\n1\\n4\\n5\\n...\\ny \\ny(1)\\ny(2)\\ny(3)\\ny(4)\\ny(5)\\ny(6)\\ny(D)\\n...\\nx1 x2 x3 x21x22x23x24... ... x40x41x42x43 ...\\nFigure 1: Example for sparse feature vectorsx and their respective labelsy.\\nIn ﬁg. 1 you see an example of sparse feature vectors with labels. Each feature vector\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 8'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 142, 'page_label': '143'}, page_content='represents information about one speciﬁc user and one speciﬁc movie. Features in the blue\\nsection represent a user. Users are encoded as one-hot vectors. Features in the green section\\nrepresent a movie. Movies are also encoded as one-hot vectors. Features in the yellow section\\nrepresent scores the user in green gave to each movie they rated. Featurex99 represents\\nthe ratio of movies with an Oscar among those the speciﬁc user has watched. Featurex100\\nrepresents the percentage of the movie watched by the user in blue before they scored the\\nmovie in green. The targety represents the score given by the user in blue to the movie in\\ngreen.\\nIn real recommender systems, the number of users can count in millions, so the matrix in\\nﬁg. 1 would count hundreds of millions of rows. The number of features could be hundreds\\nof thousands, depending on how reach is the choice of content and how creative you, as a\\ndata analyst, are in feature engineering. Featuresx99 and x100 were handcrafted during the\\nfeature engineering process, and I only show two features for the illustration purposes.\\nTrying to ﬁt a regression or classiﬁcation model to such an extremely sparse dataset would in\\npractice result in very poor generalization. Factorization machines approach this problem in\\nad i \\x00 e r e n tw a y .\\nThe factorization machine model is deﬁned as follows:\\nf(x)\\ndef\\n= b +\\nDÿ\\ni=1\\nwixi +\\nDÿ\\ni=1\\nDÿ\\nj=i+1\\n(vivj)xixj,\\nwhere b and wi, i =1 ,...,D are scalar parameters similar to those used in linear regression.\\nVectors vi, i =1 ,...,D , are k-dimensional vectors of factors.k is a hyperparameter and\\nis usually much smaller thanD. The expression (vivj) is a dot-product of theith and\\njth vectors of factors. As you can see, instead of trying to ﬁnd just one wide vector of\\nparameters which can reﬂect poorly interactions between features because of sparsity, we\\ncomplete it by additional parameters that apply to pairwise interactionsxixj between\\nfeatures. However, instead of having a parameterwi,j for each interaction, which would add\\nan enormous1 quantity of new parameters to the model, we factorizewi,j into vivj by adding\\nonly Dk π D(D ≠ 1) parameters to the model2.\\nDepending on the problem, the loss function could be squared error loss (for regression) or\\nhinge loss. For classiﬁcation withy œ {≠1, +1}, with hinge loss or logistic loss the prediction\\nis made asy = sign(f(x)). The logistic loss is deﬁned as,\\nloss(f(x),y )= 1\\nln 2ln(1 +e≠yf(x)).\\nGradient descent can be used to optimize the average loss. In the example in ﬁg. 1, the\\nlabels are in{1, 2, 3, 4, 5}, so it’s a multiclass problem. We can useone versus reststrategy\\n1To be more precise we would addD(D ≠ 1) parameters wi,j .\\n2The notation π means “much less than. ”\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 9'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 143, 'page_label': '144'}, page_content='to convert this multiclass problem into ﬁve binary classiﬁcation problems.\\n10.3.2 Denoising Autoencoders\\nFrom Chapter 7, you know what a denoising autoencoder is: it’s a neural network that\\nreconstructs its input from the bottleneck layer. The fact that the input is corrupted by\\nnoise while the output shouldn’t be, makes denoising autoencoders an ideal tool to build a\\nrecommender model.\\nThe idea is very straightforward: new movies a user could like are seen as if they were\\nremoved from the complete set of preferred movies by some corruption process. The goal of\\nthe denoising autoencoder is to reconstruct those removed items.\\nTo prepare the training set for our denoising autoencoder, remove the blue and green features\\nfrom the training set in ﬁg. 1. Because now some examples become duplicates, keep only the\\nunique ones.\\nAt the training time, randomly replace some of the non-zero yellow features in the input\\nfeature vectors with zeros. Train the autoencoder to reconstruct the uncorrupted input.\\nAt the prediction time, build a feature vector for the user. The feature vector will include\\nuncorrupted yellow features as well as the handcrafted features likex99 and x100. Use the\\ntrained DAE model to reconstruct the uncorrupted input. Recommend to the user movies\\nthat have the highest scores at the model’s output.\\nAnother e\\x00ective collaborative-ﬁltering model is a feed-forward neural\\nnetwork with two inputs and one output. Remember from Chapter 8\\nthat neural networks are good at handling multiple simultaneous inputs.\\nA training example here is a triplet(u, m,r ). The input vectoru is a\\none-hot encodingof a user. The second input vectorm is a one-hot\\nencoding of a movie. The output layer could be either a sigmoid (in\\nwhich case the labelr is in[0, 1]) or ReLU, in which caser can be in\\nsome typical range,[1, 5] for example.\\n10.4 Self-Supervised Learning: Word Embeddings\\nWe have already discussed word embeddings in Chapter 7. Recall that word embeddings are\\nfeature vectors that represent words. They have the property that similar words have similar\\nword vectors. The question that you probably want to ask is where these word embedding\\ncome from. The answer is: they are learned from data.\\nThere are many algorithms to learn word embeddings. Here, we consider in detail only one of\\nthem: word2vec, and only one version of word2vec calledskip-gram, which works very well\\nin practice. Pretrained word2vec embeddings for many languages are available to download\\nonline.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 10'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 144, 'page_label': '145'}, page_content='In word embedding learning, our goal is to build a model which we can use to convert a\\none-hot encoding of a word into a word embedding. Let our dictionary contain 10000 words.\\nThe one-hot vector for each word is a 10000-dimensional vector of all zeroes except for one\\ndimension that contains a1. Di\\x00erent words have1 in di\\x00erent dimensions.\\nConsider a sentence: “I almost ﬁnished reading the book on machine learning. ” Now, consider\\nthe same sentence from which we have removed some word, say “book. ” Our sentence becomes:\\n“I almost ﬁnished reading the· on machine learning. ” Now let’s only keep the three words\\nbefore the · and three words after it: “ﬁnished reading the· on machine learning. ” Looking\\nat this seven-word window around the· , if I ask you to guess what· stands for, you would\\nprobably say: “book,” “article,” or “paper. ” That is how the context words let you predict\\nthe word they surround. It’s also how the machine can discover that words “book,” “paper,”\\nand “article” have a similar meaning: because they share similar contexts in multiple texts.\\nIt turns out that it works the other way around too: a word can predict the context that\\nsurrounds it. The piece “ﬁnished reading the· on machine learning” is called a skip-gram\\nwith window size 7 (3 + 1 + 3). By using the documents available on the Web, we can easily\\ncreate hundreds of millions of skip-grams.\\nLet’s denote words in a skip-gram like this:[x≠3, x≠2, x≠1, x, x+1, x+2, x+3]. In our above\\nexample of the sentence,x≠3 is the one-hot vector for “ﬁnished,”x≠2 corresponds to “reading,”\\nx is the skipped word (· ), x+1 is “on” and so on. A skip-gram with window size 5 will look\\nlike this: [x≠2, x≠1, x, x+1, x+2].\\nThe skip-gram model with window size5 is schematically depicted in ﬁg. 2. It is a fully-\\nconnected network, like the multilayer perceptron. The input word is the one denoted as· in\\nour skip-gram. The neural network has to learn to predict the context words of the skip-gram\\ngiven the central word.\\nYou can see now why the learning of this kind is called self-supervised: the labeled examples\\nget extracted from the unlabeled data such as text.\\nThe activation function used in the output layer is softmax. The cost function is the negative\\nlog-likelihood. The embedding for a word is obtained as the output of the embedding layer\\nwhen the one-hot encoding of this word is given as the input to the model.\\nBecause of the large number of parameters in the word2vec models, two\\ntechniques are used to make the computation more e\\x00cient:hierarchical\\nsoftmax (an e\\x00cient way of computing softmax that consists in repre-\\nsenting the outputs of softmax as leaves of a binary tree) andnegative\\nsampling (essentially, the idea is only to update a random sample of all\\noutputs per iteration of gradient descent). We leave these for further\\nreading.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 11'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 145, 'page_label': '146'}, page_content='x\\n1\\n10000\\n0\\n0\\n...\\n1\\n...\\n0\\n0\\n0\\n...\\n...\\n1\\n10000\\n...\\n1\\n300\\n1\\n10000\\n...\\n1\\n10000\\n1\\n10000\\n1\\n10000\\n...\\n...\\n...\\n............\\nx\\xad2\\nx\\xad1\\nx+1\\nx+2\\ninputword\\ninputlayer\\nembeddinglayer\\noutputlayer\\nFigure 2: The skip-gram model with window size5 and the embedding layer of300 units.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 12'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 146, 'page_label': '147'}, page_content='TheHundred-Page\\nMachineLearning\\nBook\\nAndriy Burkov'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 147, 'page_label': '148'}, page_content='“All models are wrong, but some are useful. ”\\n— George Box\\nThe book is distributed on the “read ﬁrst, buy later” principle.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 148, 'page_label': '149'}, page_content='11 Conclusion\\nWow, that was fast! You are really good if you got here and managed to understand most of\\nthe book’s material.\\nIf you look at the number at the bottom of this page, you see that we have overspent paper,\\nwhich means that the title of the book was slightly misleading. I hope that you forgive me\\nthis little marketing trick. After all, if I wanted to make this book exactly a hundred pages, I\\ncould reduce font size, white margins, and line spacing, or remove the section on UMAP and\\nleave you on your own with the original paper. Believe me: you would not want to be left\\nalone with the original paper on UMAP!\\nHowever, by stopping now, I feel conﬁdent that you have got everything you need to become\\na great modern data analyst or machine learning engineer. That doesn’t mean that I covered\\neverything, but what I covered in a hundred pages you would ﬁnd in a bunch of books, each\\nthousand-page thick. Much of what I covered is not in the books at all: typical machine\\nlearning books are conservative and academic, while I emphasize those algorithms and\\nmethods that you will ﬁnd useful in your day to day work.\\nWhat exactly I didn’t cover, but would have covered if it was a thousand-page machine\\nlearning book?\\n11.1 Topic Modeling\\nIn text analysis, topic modeling is a prevalent unsupervised learning problem. You have a\\ncollection of text documents, and you would like to discover topics present in each document.\\nLatent Dirichlet Allocation(LDA) is a very e\\x00ective algorithm of topic discovery. You\\ndecide how many topics are present in your collection of documents and the algorithm assigns\\na topic to each word in this collection. Then, to extract the topics from a document, you\\nsimply count how many words of each topic are present in that document.\\n11.2 Gaussian Processes\\nGaussian processes (GP) is a supervised learning method that competes with kernel\\nregression. It has some advantages over the latter. For example, it provides conﬁdence\\nintervals for the regression line in each point. I decided not to explain GP because I could\\nnot ﬁgure out a simple way to explain them, but you deﬁnitely could spend some time to\\nlearn about GP. It will be time well spent.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 3'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 149, 'page_label': '150'}, page_content='11.3 Generalized Linear Models\\nGeneralized linear model(GLM) is a generalization of the linear regression to modeling\\nvarious forms of dependency between the input feature vector and the target. Logistic\\nregression, for instance, is one form of GLMs. If you are interested in regression and you\\nlook for simple and explainable models, you should deﬁnitely read more on GLM.\\n11.4 Probabilistic Graphical Models\\nWe have mentioned one example ofprobabilistic graphical models(PGMs) in Chapter 7:\\nconditional random ﬁelds(CRF). With CRF we can model the input sequence of words\\nand relationships between the features and labels in this sequence as a sequentialdependency\\ngraph. More generally, a PGM can be any graph. A graph is a structure consisting of a\\ncollection of nodes and edges that join a pair of nodes. Each node in PGM represents some\\nrandom variable (values of which can be observed or unobserved), and edges represent the\\nconditional dependence of one random variable on another random variable. For example,\\nthe random variable “sidewalk wetness” depends on the random variable “weather condition. ”\\nBy observing values of some random variables, an optimization algorithm can learn from\\ndata the dependency between observed and unobserved variables.\\nPGMs allow the data analyst to see how the values of one feature depend on the values of\\nother features. If the edges of the dependency graph are directed, it becomes possible to infer\\ncausality. Unfortunately, constructing such models by hand require a substantial amount of\\ndomain expertise and a strong understanding of probability theory and statistics. The latter\\nis often a problem for many domain experts. Some algorithms allow learning the structure\\nof dependency graphs from data, but the learned models are often hard to interpret by a\\nhuman and thus they aren’t beneﬁcial for understanding complex probabilistic processes that\\ngenerated the data. CRF is by far the most used PGM with applications mostly in text and\\nimage processing. However, in these two domains, they were surpassed by neural networks.\\nAnother graphical model,hidden Markov modelor HMM, in the past was frequently used\\nin speech recognition, time series analysis, and other temporal inference tasks, but, again\\nHMM lost to neural networks.\\nPGMs are also known under names of Bayesian networks, belief networks, and probabilistic\\nindependence networks.\\n11.5 Markov Chain Monte Carlo\\nIf you work with graphical models and want to sample examples from a very complex\\ndistribution deﬁned by the dependency graph, you could useMarkov chain Monte Carlo\\n(MCMC) algorithms. MCMC is a class of algorithms for sampling from any probability\\ndistribution deﬁned mathematically. Remember that when we talked about the denoising\\nautoencoder, we sampled the noise from the normal distribution. Sampling from standard\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 4'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 150, 'page_label': '151'}, page_content='distributions, such as normal or uniform, is relatively easy because their properties are well\\nknown. However, the task of sampling becomes signiﬁcantly more complicated when the\\nprobability distribution can have an arbitrary form deﬁned by a dependency graph learned\\nfrom data.\\n11.6 Genetic Algorithms\\nGenetic algorithms(GA) are a numerical optimization technique used to optimize undif-\\nferentiable optimization objective functions. They use concepts from evolutionary biology\\nto search for a global optimum (minimum or maximum) of an optimization problem, by\\nmimicking evolutionary biological processes.\\nGA work by starting with an initial generation of candidate solutions. If we look for optimal\\nvalues of the parameters of our model, we ﬁrst randomly generate multiple combinations of\\nparameter values. We then test each combination of parameter values against the objective\\nfunction. Imagine each combination of parameter values as a point in a multi-dimensional\\nspace. We then generate a subsequent generation of points from the previous generation by\\napplying such concepts as “selection,” “crossover,” and “mutation. ”\\nIn a nutshell, this results in each new generation keeping more points similar to those points\\nfrom the previous generation that performed the best against the objective. In the new\\ngeneration, the points that performed the worst in the previous generation are replaced by\\n“mutations” and “crossovers” of the points that performed the best. A mutation of a point is\\nobtained by a random distortion of some attributes of the original point. A crossover is a\\ncertain combination of several points (for example, an average).\\nGenetic algorithms allow ﬁnding solutions to any measurable optimization criteria. For\\nexample, GA can be used to optimize the hyperparameters of a learning algorithm. They are\\ntypically much slower than gradient-based optimization techniques.\\n11.7 Reinforcement Learning\\nAs we already discussed, reinforcement learning (RL) solves a very speciﬁc kind of problems\\nwhere the decision making is sequential. Usually, there’s an agent acting in an unknown\\nenvironment. Each action brings a reward and moves the agent to another state of the\\nenvironment (usually, as a result of some random process with unknown properties). The\\ngoal of the agent is to optimize its long-term reward.\\nReinforcement learning algorithms, such as Q-learning, as well as its neural network based\\ncounterparts, are used in learning to play video games, robotic navigation and coordination,\\ninventory and supply chain management, optimization of complex electric power systems\\n(power grids), and learning ﬁnancial trading strategies.\\núúú\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 5'),\n",
       " Document(metadata={'producer': '3-Heights(TM) PDF Optimization Shell 4.8.25.2 (http://www.pdf-tools.com)', 'creator': 'PyPDF', 'creationdate': '2018-12-18T05:07:46+00:00', 'moddate': '2019-01-22T19:51:34+00:00', 'source': 'project/data/MachineLearning.pdf', 'total_pages': 152, 'page': 151, 'page_label': '152'}, page_content='The book stops here. Don’t forget to occasionally visit the book’s companion wiki to stay\\nupdated on new developments in each machine learning area considered in the book. As I\\nsaid in Preface, this book, thanks to the constantly updated wiki, like a good wine keeps\\ngetting better after you buy it. Oh, and don’t forget that the book is distributed on theread\\nﬁrst, buy later principle. That means that if while reading these words you look at a digital\\nscreen, you are probably the right person for buying this book.\\nAndriy Burkov The Hundred-Page Machine Learning Book - Draft 6')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a53ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_text_splitters.character.RecursiveCharacterTextSplitter at 0x7980f44cd1f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_spliter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "text_spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c7c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for doc in docs:\n",
    "    chunks = text_spliter.split_text(doc.page_content)\n",
    "\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        chunk_doc = Document(\n",
    "            page_content= chunk,\n",
    "            metadata = {'source':doc.metadata['source'],'chunk':i}\n",
    "        )\n",
    "        all_chunks.append(chunk_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caddc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 404 chunks\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created {len(all_chunks)} chunks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4e04c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8519/2373350834.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-l6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=model_name)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vector_store = FAISS.from_documents(all_chunks,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f315a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"ml_faiss_index\")\n",
    "\n",
    "#ret = FAISS.load_local(\"ml_faiss_index/index.pkl\",embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deb0b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Score: 0.93872815\n",
      "Metadata: {'source': 'project/data/MachineLearning.pdf', 'chunk': 3}\n",
      "or regression, but not both.\n",
      "Usually, each library provides the documentation that explains what kind of problem each\n",
      "algorithm solves, what input values are allowed and what kind of output the model produces.\n",
      "The documentation also provides information on hyperparameters.\n",
      "3If it’s really necessary, the score for SVM and kNN predictions could be synthetically created using some\n",
      "simple techniques.\n",
      "\n",
      "--------\n",
      "Score: 0.9656693\n",
      "Metadata: {'source': 'project/data/MachineLearning.pdf', 'chunk': 1}\n",
      "example to the training set, rebuild the model and continue the process until some stopping\n",
      "criterion is satisﬁed. A stopping criterion can be chosen in advance (the maximum number\n",
      "of requests to the expert based on the available budget) or depend on how well our model\n",
      "performs according to some metric.\n",
      "The support vector-based active learning strategy consists in building an SVM model using\n",
      "the l\n",
      "--------\n",
      "Score: 0.9838127\n",
      "Metadata: {'source': 'project/data/MachineLearning.pdf', 'chunk': 0}\n",
      "the normÎwÎ, the larger the distance between these two hyperplanes.\n",
      "That’s how Support Vector Machines work. This particular version of the algorithm builds\n",
      "the so-calledlinear model. It’s called linear because the decision boundary is a straight line\n",
      "(or a plane, or a hyperplane). SVM can also incorporatekernels that can make the decision\n",
      "boundary arbitrarily non-linear. In some cases, it could b\n",
      "--------\n",
      "Score: 0.99213743\n",
      "Metadata: {'source': 'project/data/MachineLearning.pdf', 'chunk': 2}\n",
      "be either an element belonging to a ﬁnite set ofclasses {1, 2,...,C }, or a real number, or a\n",
      "more complex structure, like a vector, a matrix, a tree, or a graph. Unless otherwise stated,\n",
      "in this bookyi is either one of a ﬁnite set of classes or a real number. You can see a class as\n",
      "a category to which an example belongs. For instance, if your examples are email messages\n",
      "and your problem is spam d\n"
     ]
    }
   ],
   "source": [
    "query = \"Support Vector Machine?\"\n",
    "\n",
    "docs_and_scores = retriver.vectorstore.similarity_search_with_score(query, k=4)\n",
    "\n",
    "for doc, score in docs_and_scores:\n",
    "    print(\"--------\")\n",
    "    print(\"Score:\", score)\n",
    "    print(\"Metadata:\", doc.metadata)\n",
    "    print(doc.page_content[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6417d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'input'] input_types={} partial_variables={} template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nQuestion: {input}\\nContext: {context}\\nAnswer:\\n\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Question: {input}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00dc51c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8 Advanced Practice\\nThis chapter contains the description of techniques that you could ﬁnd useful in your practice\\nin some contexts. It’s called “Advanced Practice” not because the presented techniques are\\nmore complex, but rather because they are applied in some very speciﬁc contexts. In many\\npractical situations, you will most likely not need to resort to using these techniques, but\\nsometimes they are very helpful.\\n8.1 Handling Imbalanced Datasets\\nIn many practical situations, your labeled dataset will have underrepresented the examples\\nof some class. This is the case, for example, when your classiﬁer has to distinguish between\\ngenuine and fraudulent e-commerce transactions: the examples of genuine transactions are\\nmuch more frequent. If you use SVM with soft margin, you can deﬁne a cost for misclassiﬁed\\nexamples. Because noise is always present in the training data, there are high chances that\\nmany examples of genuine transactions would end up on the wrong side of the decision'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_context(question):\n",
    "    docs = retriver.invoke(question)\n",
    "\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "context = get_context(\"whats SVM?\")\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SVM stands for Support Vector Machine, a classification technique used in machine learning. It can handle imbalanced datasets by allowing a soft margin, where a cost can be defined for misclassified examples. This helps to avoid noise in the training data and improve accuracy.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel,RunnablePassthrough,RunnableLambda\n",
    "\n",
    "runable = (RunnableParallel(\n",
    "    {'context':RunnableLambda(get_context),\n",
    "    'question':RunnablePassthrough()\n",
    "    }\n",
    "))\n",
    "\n",
    "\n",
    "chain = runable | prompt | llm\n",
    "\n",
    "response = chain.invoke('whats SVM?')\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4c2c45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'whats SVM?',\n",
       " 'context': [Document(id='8a82739e-ad5c-4591-b966-f1dad3be7e06', metadata={'source': 'project/data/MachineLearning.pdf', 'chunk': 0}, page_content='8 Advanced Practice\\nThis chapter contains the description of techniques that you could ﬁnd useful in your practice\\nin some contexts. It’s called “Advanced Practice” not because the presented techniques are\\nmore complex, but rather because they are applied in some very speciﬁc contexts. In many\\npractical situations, you will most likely not need to resort to using these techniques, but\\nsometimes they are very helpful.\\n8.1 Handling Imbalanced Datasets\\nIn many practical situations, your labeled dataset will have underrepresented the examples\\nof some class. This is the case, for example, when your classiﬁer has to distinguish between\\ngenuine and fraudulent e-commerce transactions: the examples of genuine transactions are\\nmuch more frequent. If you use SVM with soft margin, you can deﬁne a cost for misclassiﬁed\\nexamples. Because noise is always present in the training data, there are high chances that\\nmany examples of genuine transactions would end up on the wrong side of the decision')],\n",
       " 'answer': \"SVM stands for Support Vector Machine, a machine learning technique used for classification and regression tasks. It's mentioned in the context of handling imbalanced datasets, particularly when dealing with genuine and fraudulent transactions. SVM with a soft margin allows for the definition of a cost for misclassified examples.\"}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a0fb49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: RunnableLambda(get_context),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\")\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7981298fee40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79812961fec0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7980d5ac9640>, search_kwargs={'k': 1}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nQuestion: {input}\\nContext: {context}\\nAnswer:\\n\")\n",
       "            | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7981298fee40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79812961fec0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'), max_tokens=500)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_classic.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "result = create_retrieval_chain(retriver, combine_docs_chain)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6f94dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'input': {'title': 'Input'}}, 'required': ['input'], 'title': 'RunnableParallel<context>Input', 'type': 'object'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8519/2134537224.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  print(result.input_schema.schema())\n"
     ]
    }
   ],
   "source": [
    "print(result.input_schema.schema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "222c4234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM stands for Support Vector Machine, a machine learning technique used for classification and regression tasks. It's mentioned in the context of handling imbalanced datasets, particularly when dealing with genuine and fraudulent transactions. SVM with a soft margin allows for the definition of a cost for misclassified examples.\n"
     ]
    }
   ],
   "source": [
    "response = result.invoke({\n",
    "    \"input\": \"whats SVM?\"\n",
    "})\n",
    "\n",
    "print(response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bce8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f98bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
